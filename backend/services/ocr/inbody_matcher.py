"""
ì¸ë°”ë”” ê²°ê³¼ì§€ ì´ˆì •ë°€ ë§¤ì¹­ - ì›ê·¼ ë³€í™˜ ì¶”ê°€
- 4ê°œ ê¼­ì§€ì  ê²€ì¶œ ë° ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ê¸°ìš¸ì–´ì§„ ë¬¸ì„œ ì •ë ¬
"""

import os
# DEBUG_START
import random
# DEBUG_END
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from contextlib import contextmanager
import tempfile

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['FLAGS_use_mkldnn'] = '0'
os.environ['FLAGS_enable_pir_api'] = '0'
os.environ['FLAGS_enable_executor_v2'] = '0'
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

import cv2
import json
import re
import numpy as np
import difflib
from paddleocr import PaddleOCR


@dataclass
class MatchConfig:
    """ë§¤ì¹­ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤"""
    regex: str
    y_range: Tuple[int, int]
    direction: str
    x_tolerance: int = 800
    y_tolerance: int = 50
    allow_zero: bool = False


class Scaler:
    """í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ ë‹´ë‹¹ í´ë˜ìŠ¤"""
    def __init__(self, target_height: int, base_height: int = 2400):
        self.target_height = target_height
        self.base_height = base_height
        self.scale_factor = target_height / base_height
        
    def scale(self, value: float) -> int:
        """ë‹¨ì¼ ê°’ ìŠ¤ì¼€ì¼ë§"""
        return int(value * self.scale_factor)
        
    def scale_range(self, value_range: Tuple[int, int]) -> Tuple[int, int]:
        """ë²”ìœ„ íŠœí”Œ ìŠ¤ì¼€ì¼ë§"""
        return (self.scale(value_range[0]), self.scale(value_range[1]))
    
    def scale_config(self, config: MatchConfig) -> MatchConfig:
        """MatchConfig ê°ì²´ ì „ì²´ ìŠ¤ì¼€ì¼ë§"""
        return MatchConfig(
            regex=config.regex,
            y_range=self.scale_range(config.y_range),
            direction=config.direction,
            x_tolerance=self.scale(config.x_tolerance),
            y_tolerance=self.scale(config.y_tolerance),
            allow_zero=config.allow_zero
        )


class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_default_targets() -> Dict[str, MatchConfig]:
        """ê¸°ë³¸ íƒ€ê²Ÿ ì„¤ì • ë°˜í™˜ (2400px ê¸°ì¤€ ì¢Œí‘œ)"""
        return {
            "ì‹ ì¥": MatchConfig(r"(\d{3})", (130, 220), "down"),
            "ì—°ë ¹": MatchConfig(r"(\d{2})", (130, 220), "down"),
            "ì„±ë³„": MatchConfig(r"(ë‚¨ì„±|ì—¬ì„±|ë‚¨|ì—¬)$", (130, 220), "down"),
            "ì²´ìˆ˜ë¶„": MatchConfig(r"(\d+\.\d+)", (300, 380), "right"),
            "ë‹¨ë°±ì§ˆ": MatchConfig(r"(\d+\.\d+)", (370, 440), "right"),
            "ë¬´ê¸°ì§ˆ": MatchConfig(r"(\d+\.\d+)", (430, 490), "right"),
            "ì²´ì§€ë°©": MatchConfig(r"(\d+\.\d+)", (480, 550), "right", x_tolerance=2000),
            "ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (740, 830), "right", x_tolerance=2000),
            "ê³¨ê²©ê·¼ëŸ‰": MatchConfig(r"(\d+\.\d+)", (830, 910), "right", x_tolerance=2000),
            "ì²´ì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.\d+)", (910, 980), "right", x_tolerance=2000),
            "ì ì •ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (550, 650), "right"),
            "ì²´ì¤‘ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (550, 750), "right", allow_zero=True, x_tolerance=1000),
            "ì§€ë°©ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (600, 800), "right", allow_zero=True, x_tolerance=1000),
            "ê·¼ìœ¡ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (650, 850), "right", allow_zero=True, x_tolerance=1000),
            "ë³µë¶€ì§€ë°©ë¥ ": MatchConfig(r"(\d\.\d{2})", (850, 1050), "down"),
            "ë‚´ì¥ì§€ë°©ë ˆë²¨": MatchConfig(r"(\d+)", (950, 1150), "down"),
            "BMI": MatchConfig(r"(\d+\.\d+)", (1120, 1180), "right", x_tolerance=2000),
            "ì²´ì§€ë°©ë¥ ": MatchConfig(r"(\d+\.\d+)", (1200, 1260), "right", x_tolerance=2000),
            "ì œì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.?\d*)", (1140, 1210), "right"),
            "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": MatchConfig(r"(\d{4})", (1210, 1260), "right"),
            "ë¹„ë§Œë„": MatchConfig(r"(\d+)", (1250, 1300), "right"),
            "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": MatchConfig(r"(\d{4})", (1290, 1350), "right"),
        }
    
    @staticmethod
    def get_correction_map() -> Dict[str, str]:
        """ì˜¤íƒ€ êµì • ë§µ ë°˜í™˜"""
        return {
            "ì²™ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘", "ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘",
            "ì²´ì§€ë°©ë¥¨": "ì²´ì§€ë°©ë¥ ", "ì²´ì§€ë°©ìœ¨": "ì²´ì§€ë°©ë¥ ",
            "ê³¨ê²©ê·¹ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ê·¹ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰",
            "ë¬´ê¸°ì‹¤": "ë¬´ê¸°ì§ˆ", "ë³´ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ",
            "ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ", "ë‚´ì¥ì§€ë°©ë ˆë¹Œ": "ë‚´ì¥ì§€ë°©ë ˆë²¨",
            "ì œì§€ë°©ë¥¨": "ì œì§€ë°©ëŸ‰", "ì œì§€ë°©ë¥ ": "ì œì§€ë°©ëŸ‰",
            "ìœ¨ê·¼ë¡ ": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ë¥œ": "ê³¨ê²©ê·¼ëŸ‰",
            "ê·¼ìœ¡ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "Skeletal": "ê³¨ê²©ê·¼ëŸ‰",
            "MuscleMass": "ê³¨ê²©ê·¼ëŸ‰", "SkeletalMtiscleMass": "ê³¨ê²©ê·¼ëŸ‰",
            "ë‹¨ë°±ì¹ ": "ë‹¨ë°±ì§ˆ", "ë¬´ê¸°ì¹ ": "ë¬´ê¸°ì§ˆ", 
            "ë‹¨ë°±ì ˆ": "ë‹¨ë°±ì§ˆ", "ê³¨ê²©ê·¼": "ê³¨ê²©ê·¼ëŸ‰"
        }


@contextmanager
def temporary_file(suffix='.jpg'):
    """ì„ì‹œ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_path = temp_file.name
    temp_file.close()
    
    try:
        yield temp_path
    finally:
        try:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        except:
            pass


class DocumentRectifier:
    """ë¬¸ì„œ 4ì  ì›ê·¼ ë³€í™˜ í´ë˜ìŠ¤"""
    
    @staticmethod
    def order_points(pts: np.ndarray) -> np.ndarray:
        """4ê°œì˜ ì ì„ [ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜] ìˆœì„œë¡œ ì •ë ¬"""
        rect = np.zeros((4, 2), dtype="float32")
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        return rect
    
    @staticmethod
    def calculate_skew_score(corners: np.ndarray, img_shape: tuple) -> float:
        """
        ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚° (0~100, ë†’ì„ìˆ˜ë¡ ê¸°ìš¸ì–´ì§)
        
        Returns:
            0-20: ê±°ì˜ ì •ë©´ (ì›ê·¼ ë³€í™˜ ë¶ˆí•„ìš”)
            20-50: ì•½ê°„ ê¸°ìš¸ì–´ì§ (ì„ íƒì )
            50+: ì‹¬í•˜ê²Œ ê¸°ìš¸ì–´ì§ (ì›ê·¼ ë³€í™˜ í•„ìš”)
        """
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        h, w = img_shape[:2]
        
        # 1. ë©´ì  ë¹„ìœ¨
        detected_area = cv2.contourArea(corners)
        image_area = h * w
        area_ratio = detected_area / image_area
        area_score = (1 - area_ratio) * 100
        
        # 2. ê°ë„ ì™œê³¡
        def angle_between(p1, p2, p3):
            v1 = p1 - p2
            v2 = p3 - p2
            angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))
            return np.degrees(angle)
        
        angles = [
            angle_between(tl, tr, br),
            angle_between(tr, br, bl),
            angle_between(br, bl, tl),
            angle_between(bl, tl, tr)
        ]
        
        angle_deviation = np.mean([abs(angle - 90) for angle in angles])
        angle_score = angle_deviation * 2
        
        # 3. ë³€ ê¸¸ì´ ë¹„ìœ¨
        top_width = np.linalg.norm(tr - tl)
        bottom_width = np.linalg.norm(br - bl)
        left_height = np.linalg.norm(bl - tl)
        right_height = np.linalg.norm(br - tr)
        
        width_ratio = abs(top_width - bottom_width) / max(top_width, bottom_width)
        height_ratio = abs(left_height - right_height) / max(left_height, right_height)
        ratio_score = (width_ratio + height_ratio) * 50
        
        total_score = (area_score * 0.3 + angle_score * 0.5 + ratio_score * 0.2)
        
        return min(100, total_score)
    
    @staticmethod
    def find_document_corners(img: np.ndarray) -> Optional[np.ndarray]:
        """ìœ¤ê³½ì„  ê²€ì¶œë¡œ ë¬¸ì„œ 4ê°œ ê¼­ì§€ì  ì°¾ê¸°"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
            
            for contour in contours:
                peri = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
                if len(approx) == 4:
                    return approx.reshape(4, 2)
            return None
        except:
            return None
    
    @staticmethod
    def apply_perspective_transform(img: np.ndarray, corners: np.ndarray) -> np.ndarray:
        """ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì •ë©´ìœ¼ë¡œ í¼ì¹˜ê¸°"""
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        
        widthA = np.sqrt((br[0] - bl[0]) ** 2 + (br[1] - bl[1]) ** 2)
        widthB = np.sqrt((tr[0] - tl[0]) ** 2 + (tr[1] - tl[1]) ** 2)
        maxWidth = max(int(widthA), int(widthB))
        
        heightA = np.sqrt((tr[0] - br[0]) ** 2 + (tr[1] - br[1]) ** 2)
        heightB = np.sqrt((tl[0] - bl[0]) ** 2 + (tl[1] - bl[1]) ** 2)
        maxHeight = max(int(heightA), int(heightB))
        
        dst = np.array([
            [0, 0],
            [maxWidth - 1, 0],
            [maxWidth - 1, maxHeight - 1],
            [0, maxHeight - 1]
        ], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect, dst)
        warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))
        return warped
    
    @staticmethod
    def rectify_auto(img: np.ndarray, threshold: float = 15.0) -> Tuple[np.ndarray, bool, float]:
        """
        ìë™ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ íŒë‹¨í•˜ì—¬ ì›ê·¼ ë³€í™˜ ì ìš©
        
        Args:
            img: ì…ë ¥ ì´ë¯¸ì§€
            threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ ë³€í™˜ ì ìš©)
        
        Returns:
            (ë³€í™˜ëœ ì´ë¯¸ì§€, ë³€í™˜ ì ìš© ì—¬ë¶€, ê¸°ìš¸ê¸° ì ìˆ˜)
        """
        try:
            corners = DocumentRectifier.find_document_corners(img)
            
            if corners is None:
                return img, False, 0.0
            
            h, w = img.shape[:2]
            detected_area = cv2.contourArea(corners)
            image_area = h * w
            area_ratio = detected_area / image_area
            
            if area_ratio < 0.3:
                return img, False, 0.0
            
            skew_score = DocumentRectifier.calculate_skew_score(corners, img.shape)
            
            if skew_score >= threshold:
                warped = DocumentRectifier.apply_perspective_transform(img, corners)
                # DEBUG_START
                if True: # ë””ë²„ê¹… ê°•ì œ
                    debug_img = img.copy()
                    cv2.drawContours(debug_img, [corners.astype(int)], -1, (0, 0, 255), 3)
                    cv2.putText(debug_img, f"Skew: {skew_score:.1f} (Threshold: {threshold}) - WARPED", 
                                (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    cv2.imwrite("debug_rectification.jpg", debug_img)
                # DEBUG_END
                return warped, True, skew_score
            else:
                # DEBUG_START
                if True:
                    debug_img = img.copy()
                    cv2.drawContours(debug_img, [corners.astype(int)], -1, (0, 255, 0), 3)
                    cv2.putText(debug_img, f"Skew: {skew_score:.1f} (Threshold: {threshold}) - SKIPPED", 
                                (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.imwrite("debug_rectification.jpg", debug_img)
                # DEBUG_END
                return img, False, skew_score
                
        except:
            return img, False, 0.0


class InBodyMatcher:
    """ì¸ë°”ë”” ê²°ê³¼ì§€ ë§¤ì¹­ í´ë˜ìŠ¤"""
    
    # í•´ìƒë„ ì„¤ì • (ì„±ëŠ¥ ìµœì í™”)
    TARGET_HEIGHT = 1200 # 1200 â†’ 960 (ì‚¬ìš©ì ìš”ì²­, ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
    
    def __init__(self, config_path: Optional[str] = None, 
                 auto_perspective: bool = True,
                 skew_threshold: float = 15.0):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)
            auto_perspective: ìë™ ì›ê·¼ ë³€í™˜ í™œì„±í™” (ê¸°ë³¸: True)
            skew_threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (0-100, ê¸°ë³¸: 15.0)
        """
        try:
            import logging
            logging.getLogger('ppocr').setLevel(logging.ERROR)
            
            self.ocr = PaddleOCR(
                lang='korean',
                ocr_version='PP-OCRv5',
                text_det_limit_side_len=960,      # 960 
                text_det_unclip_ratio=1.5,        # 2.0 â†’ 1.6 (ì†ë„ í–¥ìƒ)
                use_textline_orientation=False,   # ì¸ë°”ë””ëŠ” ìˆ˜í‰ ë¬¸ì„œ
                det_db_thresh=0.3,                # ê²€ì¶œ ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë§ì€ í…ìŠ¤íŠ¸)
                det_db_box_thresh=0.5             # ë°•ìŠ¤ ì„ê³„ê°’ ë‚®ì¶¤
            )
        except Exception as e:
            raise Exception(f"PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        self.correction_map = ConfigManager.get_correction_map()
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        self.scaler = Scaler(self.TARGET_HEIGHT)
        
        # íƒ€ê²Ÿ ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ (2400px ê¸°ì¤€ â†’ TARGET_HEIGHT ê¸°ì¤€)
        base_targets = ConfigManager.get_default_targets()
        self.targets = {
            k: self.scaler.scale_config(v) for k, v in base_targets.items()
        }
        
        self.auto_perspective = auto_perspective
        self.skew_threshold = skew_threshold
        
        print(f"âœ… OCR ì„¤ì •: í•´ìƒë„={self.TARGET_HEIGHT}px, ìŠ¤ì¼€ì¼={self.scaler.scale_factor:.3f}")
        
        if config_path and os.path.exists(config_path):
            self._load_config(config_path)

        # DEBUG_START
        self.debug_info = {}
        # DEBUG_END

    
    def _load_config(self, config_path: str):
        """ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            pass
    
    def _deskew(self, img: np.ndarray) -> np.ndarray:
        """Hough Transformì„ ì´ìš©í•œ ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì •"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            
            # í•´ìƒë„ì— ë§ì¶° íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§
            min_line_len = self.scaler.scale(100)
            max_line_gap = self.scaler.scale(10)
            
            # accumulator thresholdë„ ìŠ¤ì¼€ì¼ë§ (2400px ê¸°ì¤€ 100 -> 960px ê¸°ì¤€ ì•½ 40)
            hough_thresh = self.scaler.scale(100)
            
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, hough_thresh, minLineLength=min_line_len, maxLineGap=max_line_gap)
            
            if lines is not None:
                angles = []
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))
                    if -10 < angle < 10:
                        angles.append(angle)
                
                if angles:
                    median_angle = np.median(angles)
                    (h, w) = img.shape[:2]
                    center = (w // 2, h // 2)
                    M = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
            
            return img
        except:
            return img
    
    def _preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            img = self._deskew(img)
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            enhanced = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)
            return enhanced
        except:
            return img
    
    def _extract_nodes(self, image_path: str) -> List[Dict[str, Any]]:
        """OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ"""
        try:
            result = self.ocr.predict(input=image_path)
            all_nodes = []
            
            if result:
                for res in result:
                    dt_polys = res.get('dt_polys', [])
                    rec_texts = res.get('rec_texts', [])
                    rec_scores = res.get('rec_scores', [])
                    
                    for poly, text, conf in zip(dt_polys, rec_texts, rec_scores):
                        pts = np.array(poly)
                        x_min, y_min = pts.min(axis=0)
                        x_max, y_max = pts.max(axis=0)
                        
                        node = {
                            'text': text.strip().replace(" ", "").replace("|", ""),
                            'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],
                            'h': int(y_max - y_min),
                            'center': [(x_min + x_max) / 2, (y_min + y_max) / 2],
                            'conf': float(conf),
                            'poly': pts.astype(int).tolist() # ë‹¤ê°í˜• ì¢Œí‘œ ì €ì¥
                        }
                        all_nodes.append(node)
            
            return all_nodes
        except:
            return []
    
    def _correct_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì˜¤íƒ€ êµì •"""
        return self.correction_map.get(text, text)
    
    def _find_key_node(self, key: str, nodes: List[Dict], y_range: Tuple[int, int]) -> Optional[Dict]:
        """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        yr_min, yr_max = y_range
        
        candidates = []
        for node in nodes:
            # ìƒí•˜ ì—¬ë°± ìŠ¤ì¼€ì¼ë§ (50px -> 25px at 0.5 scale)
            y_buffer = self.scaler.scale(50)
            if not (yr_min - y_buffer <= node['center'][1] <= yr_max + y_buffer):
                continue
            
            text_without_parens = re.sub(r'\([^)]*\)', '', node['text'])
            corrected_text = self._correct_text(text_without_parens)
            original_corrected = self._correct_text(node['text'])
            
            if key in corrected_text or key in original_corrected:
                candidates.append(node)
            else:
                ratio1 = difflib.SequenceMatcher(None, key, corrected_text).ratio()
                ratio2 = difflib.SequenceMatcher(None, key, original_corrected).ratio()
                max_ratio = max(ratio1, ratio2)
                
                if max_ratio > 0.5:
                    candidates.append(node)
        
        if not candidates:
            return None
            
        # ìš°ì„ ìˆœìœ„ ì •ë ¬: 
        # 1. ì™„ì „ ì¼ì¹˜ (ì²´ì¤‘ == ì²´ì¤‘)
        # 2. ì‹œì‘ ì¼ì¹˜ (ì²´ì¤‘... == ì²´ì¤‘) -> ì ‘ë‘ì–´
        # 3. í¬í•¨ (ì €ì²´ì¤‘ contains ì²´ì¤‘) -> ì´ê±´ ìµœí•˜ìœ„ì—¬ì•¼ í•¨
        # 4. Fuzzy ì ìˆ˜
        
        def sort_key(node):
            text = self._correct_text(re.sub(r'\([^)]*\)', '', node['text']))
            
            # 1ìˆœìœ„: ì™„ì „ ì¼ì¹˜
            if text == key:
                return (0, -node['conf']) # ì ìˆ˜ ë‚®ì„ìˆ˜ë¡ ìš°ì„  (0 < 1 < 2)
            
            # 2ìˆœìœ„: ì›ë˜ í…ìŠ¤íŠ¸ ì™„ì „ ì¼ì¹˜
            if node['text'] == key:
                return (1, -node['conf'])
                
            # 3ìˆœìœ„: ì ‘ë‘ì–´ë¡œ ì‹œì‘ (ì˜ˆ: "ì²´ì¤‘ :" vs "ì €ì²´ì¤‘")
            if text.startswith(key):
                return (2, -node['conf'])
                
            # 4ìˆœìœ„: í¬í•¨ (Fuzzy í¬í•¨)
            return (3, -node['conf'])

        candidates.sort(key=sort_key)
        
        # ë””ë²„ê·¸: í‚¤ì›Œë“œ í›„ë³´ê°€ ì—¬ëŸ¬ ê°œì¼ ë•Œ ì„ íƒëœ ê²ƒ ì¶œë ¥
        # if len(candidates) > 1:
        #    print(f"[Key Select] '{key}' -> '{candidates[0]['text']}' (from {len(candidates)})")
            
        return candidates[0]
    
    def _match_value(self, key: str, key_node: Dict, config: MatchConfig, 
                     nodes: List[Dict], used_node_ids: Optional[set] = None) -> Optional[str]:
        """ê°’ ë…¸ë“œ ë§¤ì¹­ (ë™ì  í—ˆìš©ì˜¤ì°¨ ì ìš©)"""
        yr_min, yr_max = config.y_range
        candidates = []
        
        # ë””ë²„ê·¸ ëª¨ë“œ
        debug = key in ["ì²´ì¤‘ì¡°ì ˆ", "ì§€ë°©ì¡°ì ˆ", "ê·¼ìœ¡ì¡°ì ˆ", "ì²´ì¤‘", "ì ì •ì²´ì¤‘", "ë¹„ë§Œë„", 
                       "BMI", "ì²´ì§€ë°©ë¥ ", "ê³¨ê²©ê·¼ëŸ‰", "ì²´ì§€ë°©ëŸ‰"]
        
        # ê¸°ì¤€ ë†’ì´
        ref_h = key_node.get('h', self.scaler.scale(30))
        if ref_h < 1: ref_h = self.scaler.scale(30)

        # ë™ì  í—ˆìš©ì˜¤ì°¨ (í…ìŠ¤íŠ¸ ë†’ì´ ê¸°ë°˜)
        base_dy = self.scaler.scale(40)
        dynamic_dy = int(ref_h * 1.7)
        dy_max_limit = max(base_dy, dynamic_dy) 
        
        roi_buffer = max(self.scaler.scale(100), int(ref_h * 3.0))

        if debug:
            y_buffer_debug = self.scaler.scale(50)
            print(f"\n{'='*60}")
            print(f"[{key}] ë§¤ì¹­ ì‹œì‘ (Dynamic Tolerance)")
            print(f"  í‚¤ì›Œë“œ: '{key_node['text']}' (h={ref_h})")
            print(f"  ìœ„ì¹˜: y={key_node['center'][1]:.0f}, bbox={key_node['bbox']}")
            print(f"  í—ˆìš©ì˜¤ì°¨ dy_max: {dy_max_limit} (Base: {base_dy}, Dynamic: {dynamic_dy})")
            print(f"  ROI Yë²”ìœ„: {yr_min} ~ {yr_max} (Buffer: {roi_buffer})")
            print(f"{'='*60}")
        
        for node in nodes:
            if node == key_node:
                continue
            
            # ì´ë¯¸ ì‚¬ìš©ëœ ë…¸ë“œëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
            if used_node_ids is not None and id(node) in used_node_ids:
                if debug:
                    pass
                    # print(f"      [SKIP] ì´ë¯¸ ì‚¬ìš©ëœ ë…¸ë“œ: '{node['text']}'")
                continue
            
            # í…ìŠ¤íŠ¸ ì •ê·œí™”
            clean_text = re.sub(r'\(.*?\)', '', node['text'])
            clean_text = clean_text.replace('I', '1').replace('l', '1').replace(',', '.').strip()
            
            # ë””ë²„ê·¸: Y ë²”ìœ„ ë‚´ì˜ ëª¨ë“  ë…¸ë“œ ì¶œë ¥
            y_buffer_debug_wide = self.scaler.scale(100)
            if debug and (yr_min - y_buffer_debug_wide <= node['center'][1] <= yr_max + y_buffer_debug_wide):
                 # print(f"  ë…¸ë“œ: '{node['text']}' (ì •ê·œí™”: '{clean_text}') at y={node['center'][1]:.0f}")
                 pass

            # ì •ê·œì‹ ë§¤ì¹­
            match = re.search(config.regex, clean_text)
            if not match:
                continue
            
            val = match.group(1)
            
            # 1. ROI ì²´í¬
            in_roi = (yr_min - roi_buffer <= node['center'][1] <= yr_max + roi_buffer)
            
            if not in_roi:
                # ROI ë°–ì´ë©´ ê³¼ê°íˆ ì œì™¸ (ì‚¬ìš©ì ìš”ì²­: Relaxed ROI ì œê±°)
                # if debug: print(f"      [SKIP] ROI ë°–: '{val}' at y={node['center'][1]:.0f}")
                continue
            
            # 2. ìœ„ì¹˜ ê´€ê³„ ë° ë°©í–¥ ì²´í¬
            is_dir_match = False
            fail_reason = ""

            if config.direction == "right":
                key_right = key_node['bbox'][2]
                node_center_x = node['center'][0]
                
                # dx: í‚¤ì›Œë“œ ìš°ì¸¡ ë ~ ê°’ ì¤‘ì‹¬ (ì–‘ìˆ˜ì—¬ì•¼ ì˜¤ë¥¸ìª½)
                dx = node_center_x - key_right
                
                # dy ê³„ì‚°: Center-to-Centerì™€ Top-to-Top ì¤‘ ë” ì‘ì€ ê°’ ì‚¬ìš©
                # ì´ìœ : í°íŠ¸ í¬ê¸° ì°¨ì´ê°€ í´ ë•Œ CenterëŠ” ì•ˆ ë§ì•„ë„ Topì€ ë§ëŠ” ê²½ìš°ê°€ ìˆìŒ (ë˜ëŠ” ê·¸ ë°˜ëŒ€)
                dy_center = abs(node['center'][1] - key_node['center'][1])
                dy_top = abs(node['bbox'][1] - key_node['bbox'][1])
                dy = min(dy_center, dy_top)
                
                max_dist_x = config.x_tolerance
                # ê²¹ì¹¨ í—ˆìš©: í‚¤ì›Œë“œ ì•ˆìª½ìœ¼ë¡œ ì¡°ê¸ˆ ë“¤ì–´ì˜¨ ê²ƒë„ í—ˆìš© (ê¸°ì¡´ -0.5 -> 0ìœ¼ë¡œ ìˆ˜ì •)
                # ì‚¬ìš©ì í”¼ë“œë°±: "ì ì •ì²´ì¤‘" ë“±ì´ ì™¼ìª½ ë…¸ë“œë¥¼ ì¡ëŠ” ë¬¸ì œ ë°œìƒ -> ì—„ê²©í•˜ê²Œ Rightë§Œ í—ˆìš©
                min_dx = 0 # -int(ref_h * 0.5) 
                
                # ìƒì„¸ ì¡°ê±´ ì²´í¬
                cond_dx = (min_dx < dx < max_dist_x)
                cond_vertical = (dy < dy_max_limit)
                
                is_dir_match = cond_dx and cond_vertical
                
                if not is_dir_match:
                    if not cond_dx: fail_reason += f"DX_FAIL({dx:.1f} not in {min_dx}~{max_dist_x}) "
                    if not cond_vertical: fail_reason += f"DY_FAIL({dy:.1f} >= {dy_max_limit}) "
                
            elif config.direction == "down":
                dx = abs(node['center'][0] - key_node['center'][0])
                dy = node['center'][1] - key_node['bbox'][3]
                
                max_dist_x = int(ref_h * 5.0)
                max_dist_y = self.scaler.scale(300)
                
                cond_dx = (dx < max_dist_x)
                cond_dy = (0 < dy < max_dist_y)
                
                is_dir_match = cond_dx and cond_dy
                
                if not is_dir_match:
                     if not cond_dx: fail_reason += f"DX_FAIL({dx:.1f}) "
                     if not cond_dy: fail_reason += f"DY_FAIL({dy:.1f}) "
            
            if debug:
                status = "PASS" if is_dir_match else "FAIL"
                print(f"      [{status}] ê°’: '{val}', dx={dx:.1f}, dy={dy:.1f} (Limit: {dy_max_limit}) {fail_reason}")

            if not is_dir_match:
                continue
            
            # 3. 0ê°’ í•„í„°ë§
            if not config.allow_zero:
                try:
                    if abs(float(val)) < 0.01:
                        continue
                except:
                    pass
            
            # 4. ëˆˆê¸ˆì„ (ë§¤ìš° ì‘ì€ í…ìŠ¤íŠ¸) í•„í„°ë§
            # í•´ìƒë„ê°€ ë‚®ì•„ì§€ë©´ OCR ë°•ìŠ¤ í¬ê¸°ê°€ ë¹„ì„ í˜•ì ìœ¼ë¡œ ë³€í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 
            # ê¸°ì¤€ ë†’ì´ì˜ 85% ë¯¸ë§Œì€ ê³¼ê°í•˜ê²Œ í•„í„°ë§ (ê¸°ì¡´ 0.7 -> 0.8 ìƒí–¥)
            if node.get('h', 999) < (ref_h * 0.8):
                if debug: print(f"      [SKIP] ì‘ì€ í…ìŠ¤íŠ¸: '{val}' h={node['h']} (ref_h={ref_h})")
                continue

            # 5. ì ìˆ˜ ê³„ì‚°
            # dy ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (2400px ê¸°ì¤€ 500ì  -> í˜„ì¬ í•´ìƒë„ ê¸°ì¤€ ì¡°ì •)
            # ê¸°ì¡´: norm_dy = dy / self.SCALE_FACTOR
            # Scaler ì‚¬ìš©ì‹œ: dyëŠ” ì´ë¯¸ ìŠ¤ì¼€ì¼ë§ëœ ì¢Œí‘œê³„ì„. 
            # ì ìˆ˜ ê°€ì¤‘ì¹˜ëŠ” í•´ìƒë„ì— ë¬´ê´€í•˜ê²Œ 'í”½ì…€ ì°¨ì´'ì— ë¹„ë¡€í•´ì•¼ í•¨.
            # í•˜ì§€ë§Œ ì›ë³¸ ë¡œì§ì´ '2400px ê¸°ì¤€ ê±°ë¦¬'ë¡œ í™˜ì‚°í•´ì„œ ì ìˆ˜ë¥¼ ë§¤ê²¼ì—ˆìŒ.
            # self.scaler.scale_factorë¡œ ë‚˜ëˆ„ë©´ ì›ë³¸ 2400px ê¸°ì¤€ ê±°ë¦¬ê°€ ë¨.
            
            # dy ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (2400px ê¸°ì¤€ 500ì  -> í˜„ì¬ í•´ìƒë„ ê¸°ì¤€ ì¡°ì •)
            # ê¸°ì¡´: norm_dy = dy / self.SCALE_FACTOR
            # Scaler ì‚¬ìš©ì‹œ: dyëŠ” ì´ë¯¸ ìŠ¤ì¼€ì¼ë§ëœ ì¢Œí‘œê³„ì„. 
            # ì ìˆ˜ ê°€ì¤‘ì¹˜ëŠ” í•´ìƒë„ì— ë¬´ê´€í•˜ê²Œ 'í”½ì…€ ì°¨ì´'ì— ë¹„ë¡€í•´ì•¼ í•¨.
            # í•˜ì§€ë§Œ ì›ë³¸ ë¡œì§ì´ '2400px ê¸°ì¤€ ê±°ë¦¬'ë¡œ í™˜ì‚°í•´ì„œ ì ìˆ˜ë¥¼ ë§¤ê²¼ì—ˆìŒ.
            # self.scaler.scale_factorë¡œ ë‚˜ëˆ„ë©´ ì›ë³¸ 2400px ê¸°ì¤€ ê±°ë¦¬ê°€ ë¨.
            
            norm_dy = dy / self.scaler.scale_factor
            norm_dx = abs(dx) / self.scaler.scale_factor
            
            # dy ê°€ì¤‘ì¹˜ë¥¼ 10.0ìœ¼ë¡œ ë³µêµ¬ (í–‰ ë°”ë€œ ë°©ì§€)
            # ì´ìœ : x_toleranceë¥¼ 2000 ë“±ìœ¼ë¡œ ë„“í˜”ìœ¼ë¯€ë¡œ, 
            # ë‹¤ë¥¸ í–‰ì— ìˆì§€ë§Œ xì¢Œí‘œê°€ ë” ê°€ê¹Œìš´ ì—‰ëš±í•œ ê°’ì„ ì¡ì§€ ì•Šë„ë¡ ìˆ˜ì§(dy) íŒ¨ë„í‹°ë¥¼ ê°•í™”í•´ì•¼ í•¨.
            score = (norm_dy * 10.0) + norm_dx
            candidates.append((score, val, node))

        # DEBUG_START
        self.debug_info["matches"].append({
            "key": key,
            "key_node": key_node,
            "config": config,
            "candidates": [c[2] for c in candidates],
            "selected": candidates[0][2] if candidates else None,
            "roi": (yr_min, yr_max)
        })
        # DEBUG_END

        if candidates:
            candidates.sort(key=lambda x: x[0])
            best_node = candidates[0][2]
            best_val = candidates[0][1]
            
            # ì„ íƒëœ ë…¸ë“œ ID ë“±ë¡
            if used_node_ids is not None:
                used_node_ids.add(id(best_node))
            
            if debug:
                print(f"    => ìµœì¢… ì„ íƒ: '{best_val}' (Score={candidates[0][0]:.1f})")
            return best_val
            
        return None
    

    def _extract_segment_evaluations(self, nodes: List[Dict]) -> Dict[str, str]:
        """ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ (Clustering ë°©ì‹)"""
        # í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ëœ ROI
        seg_y_min = self.scaler.scale(1400)
        seg_y_max = self.scaler.scale(1900)
        
        eval_keywords = ["í‘œì¤€ì´í•˜", "í‘œì¤€ì´ìƒ", "í‘œì¤€"]
        
        # 1. í‰ê°€ í‚¤ì›Œë“œ ë…¸ë“œë§Œ ìˆ˜ì§‘ (ROI ë‚´ë¶€ë§Œ)
        eval_nodes = []
        for node in nodes:
            # ROI í•„í„°ë§
            if not (seg_y_min <= node['center'][1] <= seg_y_max):
                continue
                
            for k in eval_keywords:
                if k in node['text']:
                    eval_nodes.append(node)
                    break
        
        if not eval_nodes:
            return {}

        # 2. Yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        eval_nodes.sort(key=lambda x: x['center'][1])
        
        # 3. í–‰ êµ¬ë¶„ (Clustering)
        rows = []
        if eval_nodes:
            current_row = [eval_nodes[0]]
            avg_h = eval_nodes[0]['h']
            
            for i in range(1, len(eval_nodes)):
                node = eval_nodes[i]
                prev_node = current_row[-1]
                
                # Y ì°¨ì´ê°€ ë†’ì´ì˜ 0.6ë°° ì´ìƒì´ë©´ ìƒˆë¡œìš´ í–‰
                if abs(node['center'][1] - prev_node['center'][1]) > (avg_h * 0.6):
                    current_row.sort(key=lambda x: x['center'][0])
                    rows.append(current_row)
                    current_row = []
                
                current_row.append(node)
                avg_h = (avg_h + node['h']) / 2
                
            if current_row:
                current_row.sort(key=lambda x: x['center'][0])
                rows.append(current_row)
            
        results = {}
        
        # í–‰ ìœ„ì¹˜ ê¸°ë°˜ ë§¤í•‘ (ìƒë‹¨, ì¤‘ë‹¨, í•˜ë‹¨)
        row_top = []
        row_mid = []
        row_bot = []
        
        for row in rows:
            avg_y = sum(n['center'][1] for n in row) / len(row)
            rel_y = avg_y / self.TARGET_HEIGHT
            
            if 0.55 <= rel_y < 0.68:
                row_top = row
            elif 0.68 <= rel_y < 0.75:
                row_mid = row
            elif 0.75 <= rel_y < 0.90:
                row_bot = row

        def _get_val(n):
            for k in eval_keywords:
                if k in n['text']: return k
            return "ë¯¸ê²€ì¶œ"

        if len(row_top) >= 4:
            results["ì™¼ìª½íŒ” ê·¼ìœ¡"] = _get_val(row_top[0])
            results["ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"] = _get_val(row_top[1])
            if len(row_top) > 2: results["ì™¼ìª½íŒ” ì²´ì§€ë°©"] = _get_val(row_top[2])
            if len(row_top) > 3: results["ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"] = _get_val(row_top[3])
                
        if len(row_mid) >= 2:
             results["ë³µë¶€ ê·¼ìœ¡"] = _get_val(row_mid[0])
             results["ë³µë¶€ ì²´ì§€ë°©"] = _get_val(row_mid[1])
             
        if len(row_bot) >= 4:
            results["ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"] = _get_val(row_bot[0])
            results["ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"] = _get_val(row_bot[1])
            if len(row_bot) > 2: results["ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"] = _get_val(row_bot[2])
            if len(row_bot) > 3: results["ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"] = _get_val(row_bot[3])
            
        return results
    
    def extract_and_match(self, image_path: str) -> Dict[str, Optional[str]]:
        """ì´ë¯¸ì§€ì—ì„œ ì¸ë°”ë”” ë°ì´í„° ì¶”ì¶œ ë° ë§¤ì¹­"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        try:
            # â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            total_start = time.time()
            
            # DEBUG_START
            self.debug_info = {
                "nodes": [],
                "matches": []
            }
            # DEBUG_END

            
            # â±ï¸ 1. ì´ë¯¸ì§€ ë¡œë“œ
            load_start = time.time()
            src_img = cv2.imread(image_path)
            if src_img is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            load_time = time.time() - load_start
            
            print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {src_img.shape[:2]} (â±ï¸ {load_time:.3f}ì´ˆ)")
            
            # â±ï¸ 2. ì›ê·¼ ë³€í™˜ (Perspective Transform)
            perspective_time = 0.0
            if self.auto_perspective:
                perspective_start = time.time()
                src_img, applied, skew_score = DocumentRectifier.rectify_auto(
                    src_img, threshold=self.skew_threshold
                )
                perspective_time = time.time() - perspective_start
                if applied:
                    print(f"ğŸ”„ ì›ê·¼ ë³€í™˜ ì ìš© (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, â±ï¸ {perspective_time:.3f}ì´ˆ)")
                else:
                    if skew_score > 0:
                        print(f"âœ“ ì •ë©´ ë¬¸ì„œ (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, ì„ê³„ê°’: {self.skew_threshold}, â±ï¸ {perspective_time:.3f}ì´ˆ)")
            
            # â±ï¸ 3. í•´ìƒë„ ì •ê·œí™”
            resize_start = time.time()
            target_h = self.TARGET_HEIGHT  # 1600px (ìµœì í™”)
            ratio = target_h / src_img.shape[0]
            img = cv2.resize(
                src_img,
                (int(src_img.shape[1] * ratio), target_h),
                interpolation=cv2.INTER_LANCZOS4
            )
            resize_time = time.time() - resize_start
            
            print(f"ğŸ“ ì •ê·œí™”ëœ í¬ê¸°: {img.shape[:2]} (â±ï¸ {resize_time:.3f}ì´ˆ)")
            
            # â±ï¸ 4. ì „ì²˜ë¦¬ (Preprocessing)
            preprocess_start = time.time()
            with temporary_file() as temp_path:
                processed_img = self._preprocess_image(img)
                cv2.imwrite(temp_path, processed_img)
                preprocess_time = time.time() - preprocess_start
                print(f"ğŸ¨ ì „ì²˜ë¦¬ ì™„ë£Œ (Deskew + CLAHE, â±ï¸ {preprocess_time:.3f}ì´ˆ)")
                
                # â±ï¸ 5. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°€ì¥ ëŠë¦° ë‹¨ê³„)
                ocr_start = time.time()
                all_nodes = self._extract_nodes(temp_path)
                
                # DEBUG_START
                self.debug_info["nodes"] = all_nodes
                # DEBUG_END
                
                ocr_time = time.time() - ocr_start
            
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë…¸ë“œ: {len(all_nodes)}ê°œ (â±ï¸ {ocr_time:.3f}ì´ˆ)")
            
            if not all_nodes:
                print("âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # â±ï¸ 6. ë§¤ì¹­ ìˆ˜í–‰ (Postprocessing)
            match_start = time.time()
            matched_data = {}
            used_node_ids = set() # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€ìš©
            
            for key, config in self.targets.items():
                key_node = self._find_key_node(key, all_nodes, config.y_range)
                
                if not key_node:
                    matched_data[key] = None
                    continue
                
                value = self._match_value(key, key_node, config, all_nodes, used_node_ids)
                matched_data[key] = value
            
            # ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ
            segment_results = self._extract_segment_evaluations(all_nodes)
            matched_data.update(segment_results)
            match_time = time.time() - match_start
            
            # ë§¤ì¹­ í†µê³„
            detected = sum(1 for v in matched_data.values() if v is not None)
            total = len(matched_data)
            print(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {detected}/{total} í•­ëª© ({detected/total*100:.1f}%, â±ï¸ {match_time:.3f}ì´ˆ)")
            
            # â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ìš”ì•½
            total_time = time.time() - total_start
            print(f"\nâ±ï¸ === OCR ì²˜ë¦¬ ì‹œê°„ ìƒì„¸ ë¶„ì„ ===")
            print(f"   1. ì´ë¯¸ì§€ ë¡œë“œ:      {load_time:.3f}ì´ˆ ({load_time/total_time*100:5.1f}%)")
            print(f"   2. ì›ê·¼ ë³€í™˜:        {perspective_time:.3f}ì´ˆ ({perspective_time/total_time*100:5.1f}%)")
            print(f"   3. í•´ìƒë„ ì •ê·œí™”:    {resize_time:.3f}ì´ˆ ({resize_time/total_time*100:5.1f}%)")
            print(f"   4. ì „ì²˜ë¦¬ (CLAHE):   {preprocess_time:.3f}ì´ˆ ({preprocess_time/total_time*100:5.1f}%)")
            print(f"   5. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ:  {ocr_time:.3f}ì´ˆ ({ocr_time/total_time*100:5.1f}%) âš ï¸ ë³‘ëª©")
            print(f"   6. ë§¤ì¹­ (í›„ì²˜ë¦¬):    {match_time:.3f}ì´ˆ ({match_time/total_time*100:5.1f}%)")
            print(f"   " + "="*40)
            print(f"   ì´ ì²˜ë¦¬ ì‹œê°„:        {total_time:.3f}ì´ˆ")
            print(f"   " + "="*40 + "\n")
            
            return matched_data
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            # DEBUG_START
            if 'processed_img' in locals():
                self.save_visualized_result(processed_img, "debug_ocr_result.jpg")
            # DEBUG_END

    
    def save_results(self, results: Dict, output_path: str, format: str = 'json'):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if format == 'json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            elif format in ['dict', 'python']:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write("# InBody ì¸¡ì • ê²°ê³¼\n")
                    f.write("inbody_data = ")
                    f.write(json.dumps(results, ensure_ascii=False, indent=4))
                print(f"ğŸ’¾ Python í˜•ì‹ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({output_path}): {e}")
    
    def get_structured_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        structured = {
            "ê¸°ë³¸ì •ë³´": {
                "ì‹ ì¥": results.get("ì‹ ì¥"),
                "ì—°ë ¹": results.get("ì—°ë ¹"),
                "ì„±ë³„": results.get("ì„±ë³„"),
            },
            "ì²´ì„±ë¶„": {
                "ì²´ìˆ˜ë¶„": results.get("ì²´ìˆ˜ë¶„"),
                "ë‹¨ë°±ì§ˆ": results.get("ë‹¨ë°±ì§ˆ"),
                "ë¬´ê¸°ì§ˆ": results.get("ë¬´ê¸°ì§ˆ"),
                "ì²´ì§€ë°©": results.get("ì²´ì§€ë°©"),
            },
            "ì²´ì¤‘ê´€ë¦¬": {
                "ì²´ì¤‘": results.get("ì²´ì¤‘"),
                "ê³¨ê²©ê·¼ëŸ‰": results.get("ê³¨ê²©ê·¼ëŸ‰"),
                "ì²´ì§€ë°©ëŸ‰": results.get("ì²´ì§€ë°©ëŸ‰"),
                "ì ì •ì²´ì¤‘": results.get("ì ì •ì²´ì¤‘"),
                "ì²´ì¤‘ì¡°ì ˆ": results.get("ì²´ì¤‘ì¡°ì ˆ"),
                "ì§€ë°©ì¡°ì ˆ": results.get("ì§€ë°©ì¡°ì ˆ"),
                "ê·¼ìœ¡ì¡°ì ˆ": results.get("ê·¼ìœ¡ì¡°ì ˆ"),
            },
            "ë¹„ë§Œë¶„ì„": {
                "BMI": results.get("BMI"),
                "ì²´ì§€ë°©ë¥ ": results.get("ì²´ì§€ë°©ë¥ "),
                "ë³µë¶€ì§€ë°©ë¥ ": results.get("ë³µë¶€ì§€ë°©ë¥ "),
                "ë‚´ì¥ì§€ë°©ë ˆë²¨": results.get("ë‚´ì¥ì§€ë°©ë ˆë²¨"),
                "ë¹„ë§Œë„": results.get("ë¹„ë§Œë„"),
            },
            "ì—°êµ¬í•­ëª©": {
                "ì œì§€ë°©ëŸ‰": results.get("ì œì§€ë°©ëŸ‰"),
                "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": results.get("ê¸°ì´ˆëŒ€ì‚¬ëŸ‰"),
                "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": results.get("ê¶Œì¥ì„­ì·¨ì—´ëŸ‰"),
            },
            "ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"),
                "ë³µë¶€": results.get("ë³µë¶€ ê·¼ìœ¡"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"),
            },
            "ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"),
                "ë³µë¶€": results.get("ë³µë¶€ ì²´ì§€ë°©"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"),
            }
        }
        
        return structured

    # DEBUG_START
    def save_visualized_result(self, img: np.ndarray, output_path: str):
        """ë””ë²„ê¹…ìš© ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥"""
        try:
            vis_img = img.copy()
            
            # 1. ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ê·¸ë¦¬ê¸° (íšŒìƒ‰)
            for node in self.debug_info.get("nodes", []):
                if 'poly' in node:
                    pts = np.array(node['poly'], np.int32).reshape((-1, 1, 2))
                    cv2.polylines(vis_img, [pts], True, (200, 200, 200), 1)
                else:
                    bbox = node['bbox']
                    cv2.rectangle(vis_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (200, 200, 200), 1)
            
            # 2. ë§¤ì¹­ ì •ë³´ ê·¸ë¦¬ê¸°
            for match in self.debug_info.get("matches", []):
                key = match['key']
                key_node = match['key_node']
                selected = match['selected']
                candidates = match['candidates']
                config = match['config']
                
                # ìƒ‰ìƒ ìƒì„± (í‚¤ë§ˆë‹¤ ë‹¤ë¥´ê²Œ)
                color = (random.randint(50, 255), random.randint(50, 255), random.randint(50, 255))
                
                # C. í›„ë³´êµ° (ë…¸ë€ìƒ‰) ë° ì ìˆ˜ í‘œì‹œ
                for idx, cand in enumerate(candidates):
                    # cand êµ¬ì¡°: (dist_score, val, node, dx, dy, dy_score, dx_score)
                    score, val, cand_node, dx, dy, dy_s, dx_s = cand
                    
                    c_bbox = cand_node['bbox']
                    color_cand = (0, 255, 255)
                    
                    # 1ìˆœìœ„ëŠ” ì¡°ê¸ˆ ë” ì§„í•˜ê²Œ
                    if idx == 0:
                        cv2.rectangle(vis_img, (c_bbox[0], c_bbox[1]), (c_bbox[2], c_bbox[3]), (0, 0, 255), 2)
                    else:
                        cv2.rectangle(vis_img, (c_bbox[0], c_bbox[1]), (c_bbox[2], c_bbox[3]), color_cand, 1)
                    
                    # ì ìˆ˜ ìƒì„¸ ì •ë³´ í…ìŠ¤íŠ¸ í‘œì‹œ
                    info_text = f"S:{int(score)} (Y:{int(dy_s)} X:{int(dx_s)})"
                    cv2.putText(vis_img, info_text, (c_bbox[2]+5, c_bbox[1]+10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 2) # ê·¸ë¦¼ì
                    cv2.putText(vis_img, info_text, (c_bbox[2]+5, c_bbox[1]+10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

                
                # D. ìµœì¢… ì„ íƒ (ë¹¨ê°„ìƒ‰ + ì—°ê²°ì„ )
                if selected:
                    s_bbox = selected['bbox']
                    # í‚¤ -> ê°’ ì—°ê²° ì„ 
                    cv2.line(vis_img, 
                            (int(key_node['center'][0]), int(key_node['center'][1])),
                            (int(selected['center'][0]), int(selected['center'][1])),
                            (0, 0, 255), 2)

            cv2.imwrite(output_path, vis_img)
            print(f"ğŸ› ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"âš ï¸ ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
    # DEBUG_END



def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    img_path = sys.argv[1] if len(sys.argv) > 1 else "444.jpg"
    
    try:
        print("=" * 60)
        print("InBody OCR ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        if not os.path.exists(img_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            sys.exit(1)
        
        print(f"âœ“ íŒŒì¼ í™•ì¸: {img_path}")
        
        matcher = InBodyMatcher(
            auto_perspective=True,
            skew_threshold=15.0
        )
        
        print("âœ“ InBodyMatcher ì´ˆê¸°í™” ì™„ë£Œ")
        print()
        
        result = matcher.extract_and_match(img_path)
        
        if not result:
            print("\nâŒ OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            sys.exit(1)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print(f"{'í•­ëª©':<15} | {'ê²°ê³¼'}")
        print("-" * 50)
        
        has_data = False
        for key, val in result.items():
            if val and val != "ë¯¸ê²€ì¶œ":
                has_data = True
            print(f"{key:<15} | {val if val else 'ë¯¸ê²€ì¶œ'}")
        
        print("=" * 50)
        
        if not has_data:
            print("\nâš ï¸ ëª¨ë“  í•­ëª©ì´ ë¯¸ê²€ì¶œì…ë‹ˆë‹¤!")
        else:
            # íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³  ë°ì´í„° êµ¬ì¡°ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
            # matcher.save_results(result, "inbody_result.json", format='json')
            
            structured = matcher.get_structured_results(result)
            # matcher.save_results(structured, "inbody_result_structured.json", format='json')
            
            print("\n" + "=" * 50)
            print("ğŸ“¦ ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬")
            print("=" * 50)
            print(json.dumps(structured, ensure_ascii=False, indent=2))
            print("=" * 50)
            
            print("\nâœ… ì™„ë£Œ")
        
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()