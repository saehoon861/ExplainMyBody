"""
ì¸ë°”ë”” ê²°ê³¼ì§€ ì´ˆì •ë°€ ë§¤ì¹­ - ì›ê·¼ ë³€í™˜ ì¶”ê°€
- 4ê°œ ê¼­ì§€ì  ê²€ì¶œ ë° ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ê¸°ìš¸ì–´ì§„ ë¬¸ì„œ ì •ë ¬
"""

import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from contextlib import contextmanager
import tempfile

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['FLAGS_use_mkldnn'] = '0'
os.environ['FLAGS_enable_pir_api'] = '0'
os.environ['FLAGS_enable_executor_v2'] = '0'
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

import cv2
import json
import re
import numpy as np
import difflib
from paddleocr import PaddleOCR


@dataclass
class MatchConfig:
    """ë§¤ì¹­ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤"""
    regex: str
    y_range: Tuple[int, int]
    direction: str
    x_tolerance: int = 800
    y_tolerance: int = 50
    allow_zero: bool = False


class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_default_targets() -> Dict[str, MatchConfig]:
        """ê¸°ë³¸ íƒ€ê²Ÿ ì„¤ì • ë°˜í™˜ (2400px ê¸°ì¤€ ì¢Œí‘œ)"""
        return {
            "ì‹ ì¥": MatchConfig(r"(\d{3})", (130, 220), "down"),
            "ì—°ë ¹": MatchConfig(r"(\d{2})", (130, 220), "down"),
            "ì„±ë³„": MatchConfig(r"(ë‚¨ì„±|ì—¬ì„±|ë‚¨|ì—¬)$", (130, 220), "down"),
            "ì²´ìˆ˜ë¶„": MatchConfig(r"(\d+\.\d+)", (300, 380), "right"),
            "ë‹¨ë°±ì§ˆ": MatchConfig(r"(\d+\.\d+)", (370, 440), "right"),
            "ë¬´ê¸°ì§ˆ": MatchConfig(r"(\d+\.\d+)", (430, 490), "right"),
            "ì²´ì§€ë°©": MatchConfig(r"(\d+\.\d+)", (480, 550), "right"),
            "ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (740, 830), "right"),
            "ê³¨ê²©ê·¼ëŸ‰": MatchConfig(r"(\d+\.\d+)", (830, 910), "right"),
            "ì²´ì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.\d+)", (910, 980), "right"),
            "ì ì •ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (550, 650), "right"),
            "ì²´ì¤‘ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (550, 750), "right", allow_zero=True, x_tolerance=1000),
            "ì§€ë°©ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (600, 800), "right", allow_zero=True, x_tolerance=1000),
            "ê·¼ìœ¡ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (650, 850), "right", allow_zero=True, x_tolerance=1000),
            "ë³µë¶€ì§€ë°©ë¥ ": MatchConfig(r"(\d\.\d{2})", (850, 1050), "down"),
            "ë‚´ì¥ì§€ë°©ë ˆë²¨": MatchConfig(r"(\d+)", (950, 1150), "down"),
            "BMI": MatchConfig(r"(\d+\.\d+)", (1120, 1180), "right"),
            "ì²´ì§€ë°©ë¥ ": MatchConfig(r"(\d+\.\d+)", (1200, 1260), "right"),
            "ì œì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.?\d*)", (1140, 1210), "right"),
            "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": MatchConfig(r"(\d{4})", (1210, 1260), "right"),
            "ë¹„ë§Œë„": MatchConfig(r"(\d+)", (1250, 1300), "right"),
            "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": MatchConfig(r"(\d{4})", (1290, 1350), "right"),
        }
    
    @staticmethod
    def scale_targets(targets: Dict[str, MatchConfig], scale_factor: float) -> Dict[str, MatchConfig]:
        """íƒ€ê²Ÿ ì¢Œí‘œë¥¼ ìŠ¤ì¼€ì¼ë§ (í•´ìƒë„ ë³€ê²½ ì‹œ ì‚¬ìš©)
        
        Args:
            targets: ì›ë³¸ íƒ€ê²Ÿ ì„¤ì • (2400px ê¸°ì¤€)
            scale_factor: ìŠ¤ì¼€ì¼ë§ íŒ©í„° (ì˜ˆ: 1200/2400 = 0.5)
            
        Returns:
            ìŠ¤ì¼€ì¼ë§ëœ íƒ€ê²Ÿ ì„¤ì • (x_tolerance, y_toleranceë„ ìŠ¤ì¼€ì¼ë§)
        """
        scaled_targets = {}
        for key, config in targets.items():
            yr_min, yr_max = config.y_range
            scaled_yr = (int(yr_min * scale_factor), int(yr_max * scale_factor))
            
            # x_tolerance, y_toleranceë„ ìŠ¤ì¼€ì¼ë§ (ì¤‘ìš”!)
            scaled_x_tolerance = int(config.x_tolerance * scale_factor)
            scaled_y_tolerance = int(config.y_tolerance * scale_factor)
            
            scaled_targets[key] = MatchConfig(
                regex=config.regex,
                y_range=scaled_yr,
                direction=config.direction,
                x_tolerance=scaled_x_tolerance,
                y_tolerance=scaled_y_tolerance,
                allow_zero=config.allow_zero
            )
        return scaled_targets
    
    @staticmethod
    def get_correction_map() -> Dict[str, str]:
        """ì˜¤íƒ€ êµì • ë§µ ë°˜í™˜"""
        return {
            "ì²™ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘", "ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘",
            "ì²´ì§€ë°©ë¥¨": "ì²´ì§€ë°©ë¥ ", "ì²´ì§€ë°©ìœ¨": "ì²´ì§€ë°©ë¥ ",
            "ê³¨ê²©ê·¹ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ê·¹ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰",
            "ë¬´ê¸°ì‹¤": "ë¬´ê¸°ì§ˆ", "ë³´ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ",
            "ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ", "ë‚´ì¥ì§€ë°©ë ˆë¹Œ": "ë‚´ì¥ì§€ë°©ë ˆë²¨",
            "ì œì§€ë°©ë¥¨": "ì œì§€ë°©ëŸ‰", "ì œì§€ë°©ë¥ ": "ì œì§€ë°©ëŸ‰",
            "ìœ¨ê·¼ë¡ ": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ë¥œ": "ê³¨ê²©ê·¼ëŸ‰",
            "ê·¼ìœ¡ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "Skeletal": "ê³¨ê²©ê·¼ëŸ‰",
            "MuscleMass": "ê³¨ê²©ê·¼ëŸ‰", "SkeletalMtiscleMass": "ê³¨ê²©ê·¼ëŸ‰",
            "ë‹¨ë°±ì¹ ": "ë‹¨ë°±ì§ˆ", "ë¬´ê¸°ì¹ ": "ë¬´ê¸°ì§ˆ", 
            "ë‹¨ë°±ì ˆ": "ë‹¨ë°±ì§ˆ", "ê³¨ê²©ê·¼": "ê³¨ê²©ê·¼ëŸ‰"
        }


@contextmanager
def temporary_file(suffix='.jpg'):
    """ì„ì‹œ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_path = temp_file.name
    temp_file.close()
    
    try:
        yield temp_path
    finally:
        try:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        except:
            pass


class DocumentRectifier:
    """ë¬¸ì„œ 4ì  ì›ê·¼ ë³€í™˜ í´ë˜ìŠ¤"""
    
    @staticmethod
    def order_points(pts: np.ndarray) -> np.ndarray:
        """4ê°œì˜ ì ì„ [ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜] ìˆœì„œë¡œ ì •ë ¬"""
        rect = np.zeros((4, 2), dtype="float32")
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        return rect
    
    @staticmethod
    def calculate_skew_score(corners: np.ndarray, img_shape: tuple) -> float:
        """
        ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚° (0~100, ë†’ì„ìˆ˜ë¡ ê¸°ìš¸ì–´ì§)
        
        Returns:
            0-20: ê±°ì˜ ì •ë©´ (ì›ê·¼ ë³€í™˜ ë¶ˆí•„ìš”)
            20-50: ì•½ê°„ ê¸°ìš¸ì–´ì§ (ì„ íƒì )
            50+: ì‹¬í•˜ê²Œ ê¸°ìš¸ì–´ì§ (ì›ê·¼ ë³€í™˜ í•„ìš”)
        """
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        h, w = img_shape[:2]
        
        # 1. ë©´ì  ë¹„ìœ¨
        detected_area = cv2.contourArea(corners)
        image_area = h * w
        area_ratio = detected_area / image_area
        area_score = (1 - area_ratio) * 100
        
        # 2. ê°ë„ ì™œê³¡
        def angle_between(p1, p2, p3):
            v1 = p1 - p2
            v2 = p3 - p2
            angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))
            return np.degrees(angle)
        
        angles = [
            angle_between(tl, tr, br),
            angle_between(tr, br, bl),
            angle_between(br, bl, tl),
            angle_between(bl, tl, tr)
        ]
        
        angle_deviation = np.mean([abs(angle - 90) for angle in angles])
        angle_score = angle_deviation * 2
        
        # 3. ë³€ ê¸¸ì´ ë¹„ìœ¨
        top_width = np.linalg.norm(tr - tl)
        bottom_width = np.linalg.norm(br - bl)
        left_height = np.linalg.norm(bl - tl)
        right_height = np.linalg.norm(br - tr)
        
        width_ratio = abs(top_width - bottom_width) / max(top_width, bottom_width)
        height_ratio = abs(left_height - right_height) / max(left_height, right_height)
        ratio_score = (width_ratio + height_ratio) * 50
        
        total_score = (area_score * 0.3 + angle_score * 0.5 + ratio_score * 0.2)
        
        return min(100, total_score)
    
    @staticmethod
    def find_document_corners(img: np.ndarray) -> Optional[np.ndarray]:
        """ìœ¤ê³½ì„  ê²€ì¶œë¡œ ë¬¸ì„œ 4ê°œ ê¼­ì§€ì  ì°¾ê¸°"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
            
            for contour in contours:
                peri = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
                if len(approx) == 4:
                    return approx.reshape(4, 2)
            return None
        except:
            return None
    
    @staticmethod
    def apply_perspective_transform(img: np.ndarray, corners: np.ndarray) -> np.ndarray:
        """ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì •ë©´ìœ¼ë¡œ í¼ì¹˜ê¸°"""
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        
        widthA = np.sqrt((br[0] - bl[0]) ** 2 + (br[1] - bl[1]) ** 2)
        widthB = np.sqrt((tr[0] - tl[0]) ** 2 + (tr[1] - tl[1]) ** 2)
        maxWidth = max(int(widthA), int(widthB))
        
        heightA = np.sqrt((tr[0] - br[0]) ** 2 + (tr[1] - br[1]) ** 2)
        heightB = np.sqrt((tl[0] - bl[0]) ** 2 + (tl[1] - bl[1]) ** 2)
        maxHeight = max(int(heightA), int(heightB))
        
        dst = np.array([
            [0, 0],
            [maxWidth - 1, 0],
            [maxWidth - 1, maxHeight - 1],
            [0, maxHeight - 1]
        ], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect, dst)
        warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))
        return warped
    
    @staticmethod
    def rectify_auto(img: np.ndarray, threshold: float = 15.0) -> Tuple[np.ndarray, bool, float]:
        """
        ìë™ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ íŒë‹¨í•˜ì—¬ ì›ê·¼ ë³€í™˜ ì ìš©
        
        Args:
            img: ì…ë ¥ ì´ë¯¸ì§€
            threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ ë³€í™˜ ì ìš©)
        
        Returns:
            (ë³€í™˜ëœ ì´ë¯¸ì§€, ë³€í™˜ ì ìš© ì—¬ë¶€, ê¸°ìš¸ê¸° ì ìˆ˜)
        """
        try:
            corners = DocumentRectifier.find_document_corners(img)
            
            if corners is None:
                return img, False, 0.0
            
            h, w = img.shape[:2]
            detected_area = cv2.contourArea(corners)
            image_area = h * w
            area_ratio = detected_area / image_area
            
            if area_ratio < 0.3:
                return img, False, 0.0
            
            skew_score = DocumentRectifier.calculate_skew_score(corners, img.shape)
            
            if skew_score >= threshold:
                warped = DocumentRectifier.apply_perspective_transform(img, corners)
                return warped, True, skew_score
            else:
                return img, False, skew_score
                
        except:
            return img, False, 0.0


class InBodyMatcher:
    """ì¸ë°”ë”” ê²°ê³¼ì§€ ë§¤ì¹­ í´ë˜ìŠ¤"""
    
    # í•´ìƒë„ ì„¤ì • (ì„±ëŠ¥ ìµœì í™”)
    TARGET_HEIGHT = 1200  # 2400 â†’ 1200 (50% ê°ì†Œ, 60-70% ì†ë„ í–¥ìƒ)
    SCALE_FACTOR = TARGET_HEIGHT / 2400  # ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ íŒ©í„° (0.5)
    
    def __init__(self, config_path: Optional[str] = None, 
                 auto_perspective: bool = True,
                 skew_threshold: float = 15.0):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)
            auto_perspective: ìë™ ì›ê·¼ ë³€í™˜ í™œì„±í™” (ê¸°ë³¸: True)
            skew_threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (0-100, ê¸°ë³¸: 15.0)
        """
        try:
            import logging
            logging.getLogger('ppocr').setLevel(logging.ERROR)
            
            self.ocr = PaddleOCR(
                lang='korean',
                ocr_version='PP-OCRv5',
                text_det_limit_side_len=960,      # 2560 â†’ 960 (ë” ê³µê²©ì )
                text_det_unclip_ratio=1.6,        # 2.0 â†’ 1.6 (ì†ë„ í–¥ìƒ)
                use_textline_orientation=False,   # ì¸ë°”ë””ëŠ” ìˆ˜í‰ ë¬¸ì„œ
                # det_db_thresh=0.3,                # ê²€ì¶œ ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë§ì€ í…ìŠ¤íŠ¸)
                # det_db_box_thresh=0.5             # ë°•ìŠ¤ ì„ê³„ê°’ ë‚®ì¶¤
            )
        except Exception as e:
            raise Exception(f"PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        self.correction_map = ConfigManager.get_correction_map()
        
        # íƒ€ê²Ÿ ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ (2400px ê¸°ì¤€ â†’ TARGET_HEIGHT ê¸°ì¤€)
        base_targets = ConfigManager.get_default_targets()
        self.targets = ConfigManager.scale_targets(base_targets, self.SCALE_FACTOR)
        
        self.auto_perspective = auto_perspective
        self.skew_threshold = skew_threshold
        
        print(f"âœ… OCR ì„¤ì •: í•´ìƒë„={self.TARGET_HEIGHT}px, ìŠ¤ì¼€ì¼={self.SCALE_FACTOR:.3f}")
        
        if config_path and os.path.exists(config_path):
            self._load_config(config_path)
    
    def _load_config(self, config_path: str):
        """ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            pass
    
    def _deskew(self, img: np.ndarray) -> np.ndarray:
        """Hough Transformì„ ì´ìš©í•œ ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì •"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)
            
            if lines is not None:
                angles = []
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))
                    if -10 < angle < 10:
                        angles.append(angle)
                
                if angles:
                    median_angle = np.median(angles)
                    (h, w) = img.shape[:2]
                    center = (w // 2, h // 2)
                    M = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
            
            return img
        except:
            return img
    
    def _preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            img = self._deskew(img)
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            enhanced = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)
            return enhanced
        except:
            return img
    
    def _extract_nodes(self, image_path: str) -> List[Dict[str, Any]]:
        """OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ"""
        try:
            result = self.ocr.predict(input=image_path)
            all_nodes = []
            
            if result:
                for res in result:
                    dt_polys = res.get('dt_polys', [])
                    rec_texts = res.get('rec_texts', [])
                    rec_scores = res.get('rec_scores', [])
                    
                    for poly, text, conf in zip(dt_polys, rec_texts, rec_scores):
                        pts = np.array(poly)
                        x_min, y_min = pts.min(axis=0)
                        x_max, y_max = pts.max(axis=0)
                        
                        node = {
                            'text': text.strip().replace(" ", "").replace("|", ""),
                            'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],
                            'h': int(y_max - y_min),
                            'center': [(x_min + x_max) / 2, (y_min + y_max) / 2],
                            'conf': float(conf)
                        }
                        all_nodes.append(node)
            
            return all_nodes
        except:
            return []
    
    def _correct_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì˜¤íƒ€ êµì •"""
        return self.correction_map.get(text, text)
    
    def _find_key_node(self, key: str, nodes: List[Dict], y_range: Tuple[int, int]) -> Optional[Dict]:
        """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        yr_min, yr_max = y_range
        
        candidates = []
        for node in nodes:
            if not (yr_min - 50 <= node['center'][1] <= yr_max + 50):
                continue
            
            text_without_parens = re.sub(r'\([^)]*\)', '', node['text'])
            corrected_text = self._correct_text(text_without_parens)
            original_corrected = self._correct_text(node['text'])
            
            if key in corrected_text or key in original_corrected:
                candidates.append(node)
            else:
                ratio1 = difflib.SequenceMatcher(None, key, corrected_text).ratio()
                ratio2 = difflib.SequenceMatcher(None, key, original_corrected).ratio()
                max_ratio = max(ratio1, ratio2)
                
                if max_ratio > 0.5:
                    candidates.append(node)
        
        if candidates:
            best = max(candidates, key=lambda x: x['conf'])
            return best
        
        return None
    
    def _match_value(self, key: str, key_node: Dict, config: MatchConfig, 
                     nodes: List[Dict]) -> Optional[str]:
        """ê°’ ë…¸ë“œ ë§¤ì¹­"""
        yr_min, yr_max = config.y_range
        candidates = []
        
        # ë””ë²„ê·¸ ëª¨ë“œ
        debug = key in ["ì²´ì¤‘ì¡°ì ˆ", "ì§€ë°©ì¡°ì ˆ", "ê·¼ìœ¡ì¡°ì ˆ"]
        
        if debug:
            print(f"\n{'='*60}")
            print(f"[{key}] ë§¤ì¹­ ì‹œì‘")
            print(f"  í‚¤ì›Œë“œ ìœ„ì¹˜: y={key_node['center'][1]:.0f}, bbox={key_node['bbox']}")
            print(f"  Y ë²”ìœ„: {yr_min-50} ~ {yr_max+50}")
            print(f"  ì •ê·œì‹: {config.regex}")
            print(f"  allow_zero: {config.allow_zero}")
            print(f"{'='*60}")
        
        for node in nodes:
            if node == key_node:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ê·œí™”
            clean_text = re.sub(r'\(.*?\)', '', node['text'])
            clean_text = clean_text.replace('I', '1').replace('l', '1').replace(',', '.')
            
            # ë””ë²„ê·¸: Y ë²”ìœ„ ë‚´ì˜ ëª¨ë“  ë…¸ë“œ ì¶œë ¥
            if debug and (yr_min - 100 <= node['center'][1] <= yr_max + 100):
                print(f"  ë…¸ë“œ: '{node['text']}' (ì •ê·œí™”: '{clean_text}') at y={node['center'][1]:.0f}")
            
            # ì •ê·œì‹ ë§¤ì¹­
            match = re.search(config.regex, clean_text)
            if not match:
                continue
            
            # ê°’ ì¶”ì¶œ
            val = match.group(1)
            
            if debug:
                print(f"    âœ“ ì •ê·œì‹ ë§¤ì¹­: '{val}'")
            
            # ìœ„ì¹˜ ê³„ì‚°
            dx = node['center'][0] - key_node['bbox'][2] if config.direction == "right" else abs(node['center'][0] - key_node['center'][0])
            dy = abs(node['center'][1] - key_node['center'][1])
            
            # ROI ì²´í¬ (ìŠ¤ì¼€ì¼ë§ ì ìš©)
            if key == "ì²´ì§€ë°©ë¥ " and node['center'][1] < int(1210 * self.SCALE_FACTOR):
                continue
            
            in_roi = (yr_min - 50 <= node['center'][1] <= yr_max + 50)
            is_right_dir = (config.direction == "right" and -50 < dx < config.x_tolerance and dy < 80)
            is_down_dir = (config.direction == "down" and 0 < (node['center'][1] - key_node['bbox'][3]) < 300 and abs(node['center'][0] - key_node['center'][0]) < 150)
            
            if debug:
                print(f"      dx={dx:.0f}, dy={dy:.0f}")
                print(f"      in_roi={in_roi}, is_right={is_right_dir}, is_down={is_down_dir}")
            
            if not in_roi:
                if debug:
                    print(f"      âœ— ROI ë°–")
                continue
            
            if not (is_right_dir or is_down_dir):
                if debug:
                    print(f"      âœ— ë°©í–¥ ì¡°ê±´ ë¶ˆë§Œì¡±")
                continue
            
            # 0ê°’ í•„í„°ë§
            if not config.allow_zero:
                if val in ["0.0", "0", "+0.0"]:
                    if debug:
                        print(f"      âœ— 0ê°’ í•„í„°ë§")
                    continue
            
            # ëˆˆê¸ˆì„  ê°’ í•„í„°ë§
            is_scale_mark = node.get('h', 0) < 30
            
            # ê±°ë¦¬ ì ìˆ˜ ê³„ì‚°
            dist_score = (dy * 300) + abs(dx)
            
            if node.get('h', 0) > 35:
                dist_score -= 20000
            
            if is_scale_mark:
                dist_score += 50000
            
            if debug:
                print(f"      âœ“ í›„ë³´ ì¶”ê°€: dist_score={dist_score:.0f}, h={node.get('h', 0)}")
            
            candidates.append((dist_score, val, node, dx, dy))
        
        if candidates:
            candidates.sort(key=lambda x: x[0])
            best_match = candidates[0]
            
            if debug:
                print(f"\n[{key}] ìµœì¢… ê²°ê³¼: {best_match[1]}")
                print(f"  ì „ì²´ í›„ë³´ ({len(candidates)}ê°œ): {[(c[1], f'{c[0]:.0f}') for c in candidates[:5]]}")
            
            return best_match[1]
        
        if debug:
            print(f"\n[{key}] âœ— í›„ë³´ ì—†ìŒ!")
        
        return None
    
    def _extract_segment_evaluations(self, nodes: List[Dict]) -> Dict[str, str]:
        """ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ (ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ ì ìš©)"""
        # 2400px ê¸°ì¤€ ì¢Œí‘œë¥¼ í˜„ì¬ í•´ìƒë„ë¡œ ìŠ¤ì¼€ì¼ë§
        SCALE = self.SCALE_FACTOR
        
        seg_y_min = int(1400 * SCALE)  # 933
        seg_y_max = int(1900 * SCALE)  # 1267
        row_top_max = int(1580 * SCALE)  # 1053
        row_mid_min = int(1580 * SCALE)  # 1053
        row_mid_max = int(1700 * SCALE)  # 1133
        row_bot_min = int(1700 * SCALE)  # 1133
        
        evals = ["í‘œì¤€ì´í•˜", "í‘œì¤€ì´ìƒ", "í‘œì¤€"]
        seg_nodes = sorted(
            [n for n in nodes if any(ev in n['text'] for ev in evals) 
             and (seg_y_min <= n['center'][1] <= seg_y_max)],
            key=lambda x: x['center'][1]
        )
        
        row_top = sorted([n for n in seg_nodes if n['center'][1] < row_top_max], 
                         key=lambda x: x['center'][0])
        row_mid = sorted([n for n in seg_nodes if row_mid_min <= n['center'][1] <= row_mid_max], 
                         key=lambda x: x['center'][0])
        row_bot = sorted([n for n in seg_nodes if n['center'][1] > row_bot_min], 
                         key=lambda x: x['center'][0])
        
        results = {}
        
        try:
            if len(row_top) >= 4:
                results["ì™¼ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[3]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_mid) >= 2:
                results["ë³µë¶€ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_mid[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ë³µë¶€ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_mid[1]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_bot) >= 4:
                results["ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[3]['text']), "ë¯¸ê²€ì¶œ")
        except:
            pass
        
        return results
    
    def extract_and_match(self, image_path: str) -> Dict[str, Optional[str]]:
        """ì´ë¯¸ì§€ì—ì„œ ì¸ë°”ë”” ë°ì´í„° ì¶”ì¶œ ë° ë§¤ì¹­"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        try:
            # â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
            total_start = time.time()
            
            # â±ï¸ 1. ì´ë¯¸ì§€ ë¡œë“œ
            load_start = time.time()
            src_img = cv2.imread(image_path)
            if src_img is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            load_time = time.time() - load_start
            
            print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {src_img.shape[:2]} (â±ï¸ {load_time:.3f}ì´ˆ)")
            
            # â±ï¸ 2. ì›ê·¼ ë³€í™˜ (Perspective Transform)
            perspective_time = 0.0
            if self.auto_perspective:
                perspective_start = time.time()
                src_img, applied, skew_score = DocumentRectifier.rectify_auto(
                    src_img, threshold=self.skew_threshold
                )
                perspective_time = time.time() - perspective_start
                if applied:
                    print(f"ğŸ”„ ì›ê·¼ ë³€í™˜ ì ìš© (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, â±ï¸ {perspective_time:.3f}ì´ˆ)")
                else:
                    if skew_score > 0:
                        print(f"âœ“ ì •ë©´ ë¬¸ì„œ (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, ì„ê³„ê°’: {self.skew_threshold}, â±ï¸ {perspective_time:.3f}ì´ˆ)")
            
            # â±ï¸ 3. í•´ìƒë„ ì •ê·œí™”
            resize_start = time.time()
            target_h = self.TARGET_HEIGHT  # 1600px (ìµœì í™”)
            ratio = target_h / src_img.shape[0]
            img = cv2.resize(
                src_img,
                (int(src_img.shape[1] * ratio), target_h),
                interpolation=cv2.INTER_LANCZOS4
            )
            resize_time = time.time() - resize_start
            
            print(f"ğŸ“ ì •ê·œí™”ëœ í¬ê¸°: {img.shape[:2]} (â±ï¸ {resize_time:.3f}ì´ˆ)")
            
            # â±ï¸ 4. ì „ì²˜ë¦¬ (Preprocessing)
            preprocess_start = time.time()
            with temporary_file() as temp_path:
                processed_img = self._preprocess_image(img)
                cv2.imwrite(temp_path, processed_img)
                preprocess_time = time.time() - preprocess_start
                print(f"ğŸ¨ ì „ì²˜ë¦¬ ì™„ë£Œ (Deskew + CLAHE, â±ï¸ {preprocess_time:.3f}ì´ˆ)")
                
                # â±ï¸ 5. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°€ì¥ ëŠë¦° ë‹¨ê³„)
                ocr_start = time.time()
                all_nodes = self._extract_nodes(temp_path)
                ocr_time = time.time() - ocr_start
            
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë…¸ë“œ: {len(all_nodes)}ê°œ (â±ï¸ {ocr_time:.3f}ì´ˆ)")
            
            if not all_nodes:
                print("âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # â±ï¸ 6. ë§¤ì¹­ ìˆ˜í–‰ (Postprocessing)
            match_start = time.time()
            matched_data = {}
            
            for key, config in self.targets.items():
                key_node = self._find_key_node(key, all_nodes, config.y_range)
                
                if not key_node:
                    matched_data[key] = None
                    continue
                
                value = self._match_value(key, key_node, config, all_nodes)
                matched_data[key] = value
            
            # ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ
            segment_results = self._extract_segment_evaluations(all_nodes)
            matched_data.update(segment_results)
            match_time = time.time() - match_start
            
            # ë§¤ì¹­ í†µê³„
            detected = sum(1 for v in matched_data.values() if v is not None)
            total = len(matched_data)
            print(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {detected}/{total} í•­ëª© ({detected/total*100:.1f}%, â±ï¸ {match_time:.3f}ì´ˆ)")
            
            # â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ìš”ì•½
            total_time = time.time() - total_start
            print(f"\nâ±ï¸ === OCR ì²˜ë¦¬ ì‹œê°„ ìƒì„¸ ë¶„ì„ ===")
            print(f"   1. ì´ë¯¸ì§€ ë¡œë“œ:      {load_time:.3f}ì´ˆ ({load_time/total_time*100:5.1f}%)")
            print(f"   2. ì›ê·¼ ë³€í™˜:        {perspective_time:.3f}ì´ˆ ({perspective_time/total_time*100:5.1f}%)")
            print(f"   3. í•´ìƒë„ ì •ê·œí™”:    {resize_time:.3f}ì´ˆ ({resize_time/total_time*100:5.1f}%)")
            print(f"   4. ì „ì²˜ë¦¬ (CLAHE):   {preprocess_time:.3f}ì´ˆ ({preprocess_time/total_time*100:5.1f}%)")
            print(f"   5. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ:  {ocr_time:.3f}ì´ˆ ({ocr_time/total_time*100:5.1f}%) âš ï¸ ë³‘ëª©")
            print(f"   6. ë§¤ì¹­ (í›„ì²˜ë¦¬):    {match_time:.3f}ì´ˆ ({match_time/total_time*100:5.1f}%)")
            print(f"   " + "="*40)
            print(f"   ì´ ì²˜ë¦¬ ì‹œê°„:        {total_time:.3f}ì´ˆ")
            print(f"   " + "="*40 + "\n")
            
            return matched_data
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def save_results(self, results: Dict, output_path: str, format: str = 'json'):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if format == 'json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            elif format in ['dict', 'python']:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write("# InBody ì¸¡ì • ê²°ê³¼\n")
                    f.write("inbody_data = ")
                    f.write(json.dumps(results, ensure_ascii=False, indent=4))
                print(f"ğŸ’¾ Python í˜•ì‹ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({output_path}): {e}")
    
    def get_structured_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        structured = {
            "ê¸°ë³¸ì •ë³´": {
                "ì‹ ì¥": results.get("ì‹ ì¥"),
                "ì—°ë ¹": results.get("ì—°ë ¹"),
                "ì„±ë³„": results.get("ì„±ë³„"),
            },
            "ì²´ì„±ë¶„": {
                "ì²´ìˆ˜ë¶„": results.get("ì²´ìˆ˜ë¶„"),
                "ë‹¨ë°±ì§ˆ": results.get("ë‹¨ë°±ì§ˆ"),
                "ë¬´ê¸°ì§ˆ": results.get("ë¬´ê¸°ì§ˆ"),
                "ì²´ì§€ë°©": results.get("ì²´ì§€ë°©"),
            },
            "ì²´ì¤‘ê´€ë¦¬": {
                "ì²´ì¤‘": results.get("ì²´ì¤‘"),
                "ê³¨ê²©ê·¼ëŸ‰": results.get("ê³¨ê²©ê·¼ëŸ‰"),
                "ì²´ì§€ë°©ëŸ‰": results.get("ì²´ì§€ë°©ëŸ‰"),
                "ì ì •ì²´ì¤‘": results.get("ì ì •ì²´ì¤‘"),
                "ì²´ì¤‘ì¡°ì ˆ": results.get("ì²´ì¤‘ì¡°ì ˆ"),
                "ì§€ë°©ì¡°ì ˆ": results.get("ì§€ë°©ì¡°ì ˆ"),
                "ê·¼ìœ¡ì¡°ì ˆ": results.get("ê·¼ìœ¡ì¡°ì ˆ"),
            },
            "ë¹„ë§Œë¶„ì„": {
                "BMI": results.get("BMI"),
                "ì²´ì§€ë°©ë¥ ": results.get("ì²´ì§€ë°©ë¥ "),
                "ë³µë¶€ì§€ë°©ë¥ ": results.get("ë³µë¶€ì§€ë°©ë¥ "),
                "ë‚´ì¥ì§€ë°©ë ˆë²¨": results.get("ë‚´ì¥ì§€ë°©ë ˆë²¨"),
                "ë¹„ë§Œë„": results.get("ë¹„ë§Œë„"),
            },
            "ì—°êµ¬í•­ëª©": {
                "ì œì§€ë°©ëŸ‰": results.get("ì œì§€ë°©ëŸ‰"),
                "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": results.get("ê¸°ì´ˆëŒ€ì‚¬ëŸ‰"),
                "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": results.get("ê¶Œì¥ì„­ì·¨ì—´ëŸ‰"),
            },
            "ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"),
                "ë³µë¶€": results.get("ë³µë¶€ ê·¼ìœ¡"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"),
            },
            "ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"),
                "ë³µë¶€": results.get("ë³µë¶€ ì²´ì§€ë°©"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"),
            }
        }
        
        return structured


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    img_path = sys.argv[1] if len(sys.argv) > 1 else "444.jpg"
    
    try:
        print("=" * 60)
        print("InBody OCR ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        if not os.path.exists(img_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            sys.exit(1)
        
        print(f"âœ“ íŒŒì¼ í™•ì¸: {img_path}")
        
        matcher = InBodyMatcher(
            auto_perspective=True,
            skew_threshold=15.0
        )
        
        print("âœ“ InBodyMatcher ì´ˆê¸°í™” ì™„ë£Œ")
        print()
        
        result = matcher.extract_and_match(img_path)
        
        if not result:
            print("\nâŒ OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            sys.exit(1)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print(f"{'í•­ëª©':<15} | {'ê²°ê³¼'}")
        print("-" * 50)
        
        has_data = False
        for key, val in result.items():
            if val and val != "ë¯¸ê²€ì¶œ":
                has_data = True
            print(f"{key:<15} | {val if val else 'ë¯¸ê²€ì¶œ'}")
        
        print("=" * 50)
        
        if not has_data:
            print("\nâš ï¸ ëª¨ë“  í•­ëª©ì´ ë¯¸ê²€ì¶œì…ë‹ˆë‹¤!")
        else:
            # íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•Šê³  ë°ì´í„° êµ¬ì¡°ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
            # matcher.save_results(result, "inbody_result.json", format='json')
            
            structured = matcher.get_structured_results(result)
            # matcher.save_results(structured, "inbody_result_structured.json", format='json')
            
            print("\n" + "=" * 50)
            print("ğŸ“¦ ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬")
            print("=" * 50)
            print(json.dumps(structured, ensure_ascii=False, indent=2))
            print("=" * 50)
            
            print("\nâœ… ì™„ë£Œ")
        
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()