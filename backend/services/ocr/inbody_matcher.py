"""
ì¸ë°”ë”” ê²°ê³¼ì§€ ì´ˆì •ë°€ ë§¤ì¹­ - ì›ê·¼ ë³€í™˜ ì¶”ê°€
- 4ê°œ ê¼­ì§€ì  ê²€ì¶œ ë° ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ê¸°ìš¸ì–´ì§„ ë¬¸ì„œ ì •ë ¬
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from contextlib import contextmanager
import tempfile

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['FLAGS_use_mkldnn'] = '0'
os.environ['FLAGS_enable_pir_api'] = '0'
os.environ['FLAGS_enable_executor_v2'] = '0'
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'

import cv2
import json
import re
import numpy as np
import difflib
from paddleocr import PaddleOCR


class ScaleManager:
    """í•´ìƒë„ ìŠ¤ì¼€ì¼ë§ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, target_height: int, base_height: int = 2400):
        """
        Args:
            target_height: í˜„ì¬ ì´ë¯¸ì§€ì˜ ë†’ì´
            base_height: ê¸°ì¤€ ë†’ì´ (ê¸°ë³¸ê°’: 2400 - ì›ë³¸ í•˜ë“œì½”ë”© ê¸°ì¤€)
        """
        # Scaling Policy:
        # scale_ratio = current_image_height / BASE_HEIGHT (2400)
        self.scale_ratio = target_height / base_height
    
    def scale_y(self, y: int) -> int:
        """Y ì¢Œí‘œ/ê±°ë¦¬ ìŠ¤ì¼€ì¼ë§"""
        return int(y * self.scale_ratio)
    
    def scale_x(self, x: int) -> int:
        """X ì¢Œí‘œ/ê±°ë¦¬ ìŠ¤ì¼€ì¼ë§ (ë†’ì´ ë¹„ìœ¨ ê¸°ë°˜)"""
        # X-related distances also scale by height ratio to maintain aspect ratio logic
        return int(x * self.scale_ratio)
    
    def scale_range(self, y_range: Tuple[int, int]) -> Tuple[int, int]:
        """Y ë²”ìœ„ ìŠ¤ì¼€ì¼ë§"""
        return (int(y_range[0] * self.scale_ratio), int(y_range[1] * self.scale_ratio))


@dataclass
class ScaledMatchingParameters:
    """ìŠ¤ì¼€ì¼ë§ëœ ë§¤ì¹­ íŒŒë¼ë¯¸í„° (Read-only)"""
    # A. Position Values
    segment_y_min: int
    segment_y_max: int
    segment_row_top_max: int
    segment_row_mid_min: int
    segment_row_mid_max: int
    segment_row_bot_min: int
    body_fat_percent_y_min: int

    # B. Distance/Tolerance Values
    keyword_search_y_margin: int
    roi_y_margin: int
    right_dir_x_min: int
    right_dir_y_max: int
    right_dir_x_tolerance_default: int
    down_dir_y_max: int
    down_dir_x_tolerance: int
    scale_mark_height_max: int
    large_node_height_min: int
    distance_y_weight: int # Scaled per policy

    # C. Ratio/Weight Values (No Scale)
    similarity_threshold: float
    large_node_bonus: int
    scale_mark_penalty: int
    
    # Hough Transform (Scaled)
    hough_min_line_length: int
    hough_max_line_gap: int


@dataclass
class MatchingParameters:
    """
    ë§¤ì¹­ ë¡œì§ì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„° ë° í—ˆìš© ì˜¤ì°¨ ì •ì˜ (Base: 2400px)
    """
    # ==========================================
    # Category A: Position Values (SCALE)
    # ==========================================
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€(ê·¼ìœ¡, ì²´ì§€ë°©) ì„¹ì…˜ì´ ì‹œì‘ë˜ëŠ” ìµœì†Œ Y ì¢Œí‘œ
    # ê·¼ê±°: ì¸ë°”ë”” ê²°ê³¼ì§€ ë ˆì´ì•„ì›ƒ ìƒ ìƒë‹¨ í…Œì´ë¸” ì´í›„ì— ìœ„ì¹˜í•¨
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_y_min: int = 1400
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€ ì„¹ì…˜ì´ ëë‚˜ëŠ” ìµœëŒ€ Y ì¢Œí‘œ
    # ê·¼ê±°: í•˜ë‹¨ ë¡œê³ ë‚˜ ê¸°íƒ€ ì •ë³´ ì§ì „ê¹Œì§€
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_y_max: int = 1900
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€ ìƒë‹¨ í–‰(íŒ”)ì˜ ìµœëŒ€ Y ì¢Œí‘œ
    # ê·¼ê±°: íŒ” ë°ì´í„°ì™€ ë³µë¶€ ë°ì´í„° ì‚¬ì´ì˜ ê²½ê³„
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_row_top_max: int = 1580
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€ ì¤‘ê°„ í–‰(ë³µë¶€)ì˜ ìµœì†Œ Y ì¢Œí‘œ
    # ê·¼ê±°: ìƒë‹¨ í–‰(íŒ”) ì§í›„ ì‹œì‘
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_row_mid_min: int = 1580
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€ ì¤‘ê°„ í–‰(ë³µë¶€)ì˜ ìµœëŒ€ Y ì¢Œí‘œ
    # ê·¼ê±°: ë³µë¶€ ë°ì´í„°ì™€ í•˜ì²´ ë°ì´í„° ì‚¬ì´ì˜ ê²½ê³„
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_row_mid_max: int = 1700
    
    # ì˜ë¯¸: ë¶€ìœ„ë³„ í‰ê°€ í•˜ë‹¨ í–‰(í•˜ì²´)ì˜ ìµœì†Œ Y ì¢Œí‘œ
    # ê·¼ê±°: ì¤‘ê°„ í–‰(ë³µë¶€) ì§í›„ ì‹œì‘
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    segment_row_bot_min: int = 1700
    
    # ì˜ë¯¸: 'ì²´ì§€ë°©ë¥ ' í•­ëª© í•„í„°ë§ì„ ìœ„í•œ ìµœì†Œ Y ìœ„ì¹˜
    # ê·¼ê±°: ë¹„ë§Œ ë¶„ì„ ì„¹ì…˜ ë‚´ì˜ ì²´ì§€ë°©ë¥ ë§Œ ì°¾ê¸° ìœ„í•´ ìƒë‹¨ì˜ ë‹¤ë¥¸ ì²´ì§€ë°©ë¥  í…ìŠ¤íŠ¸ ë¬´ì‹œ
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (Y ì¢Œí‘œ ìœ„ì¹˜)
    body_fat_percent_y_min: int = 1210

    # ==========================================
    # Category B: Distance/Tolerance Values (SCALE)
    # ==========================================

    # ì˜ë¯¸: í‚¤ì›Œë“œ ë…¸ë“œ(ì˜ˆ: 'ì‹ ì¥')ë¥¼ ì°¾ì„ ë•Œ ì˜ˆìƒ ë²”ìœ„ ì•ë’¤ë¡œ ì£¼ëŠ” ì—¬ìœ  ë§ˆì§„
    # ê·¼ê±°: ë¬¸ì„œì˜ ë¯¸ì„¸í•œ ì´ë™ì´ë‚˜ OCR ë°•ìŠ¤ í¬ê¸° ë³€í™” ëŒ€ì‘
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    keyword_search_y_margin: int = 50
    
    # ì˜ë¯¸: ê°’ ë…¸ë“œë¥¼ ë§¤ì¹­í•  ë•Œ í‚¤ì›Œë“œ ê¸°ì¤€ Yì¶• íƒìƒ‰ ë²”ìœ„(ìœ„ì•„ë˜)
    # ê·¼ê±°: í‚¤ì›Œë“œì™€ ê°’ì˜ ì¤‘ì‹¬ Yì¢Œí‘œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    roi_y_margin: int = 50
    
    # ì˜ë¯¸: Right ë°©í–¥ ë§¤ì¹­ ì‹œ, í‚¤ì›Œë“œë³´ë‹¤ ì•½ê°„ ì™¼ìª½(-X)ì— ìˆëŠ” ê°’ë„ í—ˆìš©í•˜ëŠ” ë²”ìœ„
    # ê·¼ê±°: ì •ë ¬ ì˜¤ì°¨ë¡œ ì¸í•´ ê°’ì´ í‚¤ì›Œë“œ ì™¼ìª½ ëë³´ë‹¤ ì‚´ì§ ì•ìœ¼ë¡œ íŠ€ì–´ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    right_dir_x_min: int = -50
    
    # ì˜ë¯¸: Right ë°©í–¥ ë§¤ì¹­ ì‹œ, ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼í•˜ëŠ” ìµœëŒ€ Y ì°¨ì´
    # ê·¼ê±°: í‚¤ì›Œë“œì™€ ê°’ì´ ê°™ì€ ë¼ì¸ì— ìˆë‹¤ê³  íŒë‹¨í•˜ëŠ” ê¸°ì¤€
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    right_dir_y_max: int = 80
    
    # ì˜ë¯¸: Right ë°©í–¥ ë§¤ì¹­ ì‹œ ê°’ íƒìƒ‰ ìµœëŒ€ ê±°ë¦¬
    # ê·¼ê±°: í‚¤ì›Œë“œë¡œë¶€í„° ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì§„ ê°’ì€ ì˜¤ë§¤ì¹­ ë°©ì§€
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    right_dir_x_tolerance_default: int = 800
    
    # ì˜ë¯¸: Down ë°©í–¥ ë§¤ì¹­ ì‹œ ê°’ íƒìƒ‰ ìµœëŒ€ Y ê±°ë¦¬
    # ê·¼ê±°: í‚¤ì›Œë“œ ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” ê°’ì„ ì°¾ê¸° ìœ„í•¨
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    down_dir_y_max: int = 300
    
    # ì˜ë¯¸: Down ë°©í–¥ ë§¤ì¹­ ì‹œ ì¢Œìš° Xì¶• í—ˆìš© ì˜¤ì°¨
    # ê·¼ê±°: í‚¤ì›Œë“œì™€ ê°’ì´ ìˆ˜ì§ìœ¼ë¡œ ì˜ ì •ë ¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ê±°ë¦¬)
    down_dir_x_tolerance: int = 150
    
    # ì˜ë¯¸: ëˆˆê¸ˆì„ ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ì œì™¸í•  ìµœëŒ€ ë†’ì´
    # ê·¼ê±°: ê·¸ë˜í”„ë‚˜ í…Œì´ë¸”ì˜ ì‘ì€ ëˆˆê¸ˆì„ ë“¤ì´ OCRë¡œ ì¡íˆëŠ” ê²ƒ ë°©ì§€
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (ë…¸ë“œ í¬ê¸° í”½ì…€)
    scale_mark_height_max: int = 30
    
    # ì˜ë¯¸: ì¤‘ìš” í…ìŠ¤íŠ¸(í° ê¸€ì)ë¡œ íŒë‹¨í•  ìµœì†Œ ë†’ì´
    # ê·¼ê±°: ê²°ê³¼ê°’ì€ ë³´í†µ í…ìŠ¤íŠ¸ë³´ë‹¤ í¬ê²Œ ì¸ì‡„ë¨
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (ë…¸ë“œ í¬ê¸° í”½ì…€)
    large_node_height_min: int = 35
    
    # ì˜ë¯¸: ê±°ë¦¬ ì ìˆ˜ ê³„ì‚° ì‹œ Y ì°¨ì´ì— ë¶€ì—¬í•˜ëŠ” ê°€ì¤‘ì¹˜ (score = dy * weight + dx)
    # ê·¼ê±°: ê°™ì€ í–‰(Yì°¨ì´ê°€ ì ìŒ)ì— ìˆëŠ” ê²ƒì´ X ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ê²ƒë³´ë‹¤ í›¨ì”¬ ì¤‘ìš”í•¨
    # ìŠ¤ì¼€ì¼ë§: í•„ìš” (í”½ì…€ ë‹¨ìœ„ ê°€ì¤‘ì¹˜ì´ë¯€ë¡œ í•´ìƒë„ì— ë”°ë¼ ì˜ë¯¸ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ ìŠ¤ì¼€ì¼ë§ ê²°ì •)
    distance_y_weight: int = 300

    # ==========================================
    # Category C: Ratio/Weight Values (NO SCALE)
    # ==========================================
    
    # ì˜ë¯¸: ë¬¸ìì—´ ìœ ì‚¬ë„ ë§¤ì¹­ ì„ê³„ê°’ (0.0 ~ 1.0)
    # ê·¼ê±°: difflib.SequenceMatcher ê¸°ì¤€
    # ìŠ¤ì¼€ì¼ë§: ë¶ˆí•„ìš” (ë¹„ìœ¨ê°’)
    similarity_threshold: float = 0.5
    
    # ì˜ë¯¸: í° ë…¸ë“œ(ì¤‘ìš” ê°’)ì— ë¶€ì—¬í•˜ëŠ” ì ìˆ˜ ë³´ë„ˆìŠ¤ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    # ê·¼ê±°: ìš°ì„ ìˆœìœ„ ì¡°ì •ì„ ìœ„í•œ ìƒëŒ€ì  ì ìˆ˜
    # ìŠ¤ì¼€ì¼ë§: ë¶ˆí•„ìš” (ìƒëŒ€ì  ê°€ì¤‘ì¹˜)
    large_node_bonus: int = 20000
    
    # ì˜ë¯¸: ëˆˆê¸ˆì„ (ë…¸ì´ì¦ˆ)ì— ë¶€ì—¬í•˜ëŠ” ì ìˆ˜ í˜ë„í‹° (ë†’ì„ìˆ˜ë¡ ë‚˜ì¨)
    # ê·¼ê±°: ìš°ì„ ìˆœìœ„ ì¡°ì •ì„ ìœ„í•œ ìƒëŒ€ì  ì ìˆ˜
    # ìŠ¤ì¼€ì¼ë§: ë¶ˆí•„ìš” (ìƒëŒ€ì  ê°€ì¤‘ì¹˜)
    scale_mark_penalty: int = 50000
    
    # ==========================================
    # Hough Transform (Scale needed)
    # ==========================================
    # ì˜ë¯¸: ì„ ìœ¼ë¡œ ì¸ì‹í•  ìµœì†Œ ê¸¸ì´
    # ê·¼ê±°: ë„ˆë¬´ ì§§ì€ ì„ ì€ ë…¸ì´ì¦ˆë¡œ ì²˜ë¦¬
    # ìŠ¤ì¼€ì¼ë§: í•„ìš”
    hough_min_line_length: int = 100
    
    # ì˜ë¯¸: í•˜ë‚˜ì˜ ì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœëŒ€ ëŠê¹€ ê±°ë¦¬
    # ê·¼ê±°: ì ì„ ì´ë‚˜ ì•½ê°„ ëŠê¸´ ì„  ì—°ê²°
    # ìŠ¤ì¼€ì¼ë§: í•„ìš”
    hough_max_line_gap: int = 10

    def scale(self, manager: ScaleManager) -> ScaledMatchingParameters:
        """í˜„ì¬ í•´ìƒë„ì— ë§ì¶° íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§"""
        return ScaledMatchingParameters(
            # A. Position Values
            segment_y_min=manager.scale_y(self.segment_y_min),
            segment_y_max=manager.scale_y(self.segment_y_max),
            segment_row_top_max=manager.scale_y(self.segment_row_top_max),
            segment_row_mid_min=manager.scale_y(self.segment_row_mid_min),
            segment_row_mid_max=manager.scale_y(self.segment_row_mid_max),
            segment_row_bot_min=manager.scale_y(self.segment_row_bot_min),
            body_fat_percent_y_min=manager.scale_y(self.body_fat_percent_y_min),

            # B. Distance/Tolerance Values
            keyword_search_y_margin=manager.scale_y(self.keyword_search_y_margin),
            roi_y_margin=manager.scale_y(self.roi_y_margin),
            right_dir_x_min=manager.scale_x(self.right_dir_x_min),
            right_dir_y_max=manager.scale_y(self.right_dir_y_max),
            right_dir_x_tolerance_default=manager.scale_x(self.right_dir_x_tolerance_default),
            down_dir_y_max=manager.scale_y(self.down_dir_y_max),
            down_dir_x_tolerance=manager.scale_x(self.down_dir_x_tolerance),
            scale_mark_height_max=manager.scale_y(self.scale_mark_height_max),
            large_node_height_min=manager.scale_y(self.large_node_height_min),
            distance_y_weight=manager.scale_y(self.distance_y_weight),

            # C. Ratio/Weight Values
            similarity_threshold=self.similarity_threshold,
            large_node_bonus=self.large_node_bonus,
            scale_mark_penalty=self.scale_mark_penalty,
            
            # Hough Transform (Lower bound applied)
            # ìµœì†Œê°’ ë³´ì¥: ê¸¸ì´ 40px, ê°„ê²© 5px
            hough_min_line_length=max(40, manager.scale_x(self.hough_min_line_length)),
            hough_max_line_gap=max(5, manager.scale_x(self.hough_max_line_gap))
        )


@dataclass
class MatchConfig:
    """ë§¤ì¹­ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤"""
    regex: str
    y_range: Tuple[int, int]
    direction: str
    x_tolerance: int = 800
    y_tolerance: int = 50
    allow_zero: bool = False


class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_default_targets() -> Dict[str, MatchConfig]:
        """ê¸°ë³¸ íƒ€ê²Ÿ ì„¤ì • ë°˜í™˜ (Based on 2400px)"""
        return {
            "ì‹ ì¥": MatchConfig(r"(\d{3})", (130, 220), "down"),
            "ì—°ë ¹": MatchConfig(r"(\d{2})", (130, 220), "down"),
            "ì„±ë³„": MatchConfig(r"(ë‚¨ì„±|ì—¬ì„±|ë‚¨|ì—¬)$", (130, 220), "down"),
            "ì²´ìˆ˜ë¶„": MatchConfig(r"(\d+\.\d+)", (300, 380), "right"),
            "ë‹¨ë°±ì§ˆ": MatchConfig(r"(\d+\.\d+)", (370, 440), "right"),
            "ë¬´ê¸°ì§ˆ": MatchConfig(r"(\d+\.\d+)", (430, 490), "right"),
            "ì²´ì§€ë°©": MatchConfig(r"(\d+\.\d+)", (480, 550), "right"),
            "ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (740, 830), "right"),
            "ê³¨ê²©ê·¼ëŸ‰": MatchConfig(r"(\d+\.\d+)", (830, 910), "right"),
            "ì²´ì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.\d+)", (910, 980), "right"),
            "ì ì •ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (550, 650), "right"),
            "ì²´ì¤‘ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (550, 750), "right", allow_zero=True, x_tolerance=1000),
            "ì§€ë°©ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (600, 800), "right", allow_zero=True, x_tolerance=1000),
            "ê·¼ìœ¡ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (650, 850), "right", allow_zero=True, x_tolerance=1000),
            "ë³µë¶€ì§€ë°©ë¥ ": MatchConfig(r"(\d\.\d{2})", (850, 1050), "down"),
            "ë‚´ì¥ì§€ë°©ë ˆë²¨": MatchConfig(r"(\d+)", (950, 1150), "down"),
            "BMI": MatchConfig(r"(\d+\.\d+)", (1120, 1180), "right"),
            "ì²´ì§€ë°©ë¥ ": MatchConfig(r"(\d+\.\d+)", (1200, 1260), "right"),
            "ì œì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.?\d*)", (1140, 1210), "right"),
            "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": MatchConfig(r"(\d{4})", (1210, 1260), "right"),
            "ë¹„ë§Œë„": MatchConfig(r"(\d+)", (1250, 1300), "right"),
            "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": MatchConfig(r"(\d{4})", (1290, 1350), "right"),
        }
    
    @staticmethod
    def get_correction_map() -> Dict[str, str]:
        """ì˜¤íƒ€ êµì • ë§µ ë°˜í™˜"""
        return {
            "ì²™ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘", "ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘",
            "ì²´ì§€ë°©ë¥¨": "ì²´ì§€ë°©ë¥ ", "ì²´ì§€ë°©ìœ¨": "ì²´ì§€ë°©ë¥ ",
            "ê³¨ê²©ê·¹ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ê·¹ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰",
            "ë¬´ê¸°ì‹¤": "ë¬´ê¸°ì§ˆ", "ë³´ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ",
            "ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ", "ë‚´ì¥ì§€ë°©ë ˆë¹Œ": "ë‚´ì¥ì§€ë°©ë ˆë²¨",
            "ì œì§€ë°©ë¥¨": "ì œì§€ë°©ëŸ‰", "ì œì§€ë°©ë¥ ": "ì œì§€ë°©ëŸ‰",
            "ìœ¨ê·¼ë¡ ": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ë¥œ": "ê³¨ê²©ê·¼ëŸ‰",
            "ê·¼ìœ¡ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "Skeletal": "ê³¨ê²©ê·¼ëŸ‰",
            "MuscleMass": "ê³¨ê²©ê·¼ëŸ‰", "SkeletalMtiscleMass": "ê³¨ê²©ê·¼ëŸ‰",
            "ë‹¨ë°±ì¹ ": "ë‹¨ë°±ì§ˆ", "ë¬´ê¸°ì¹ ": "ë¬´ê¸°ì§ˆ", 
            "ë‹¨ë°±ì ˆ": "ë‹¨ë°±ì§ˆ", "ê³¨ê²©ê·¼": "ê³¨ê²©ê·¼ëŸ‰"
        }


@contextmanager
def temporary_file(suffix='.jpg'):
    """ì„ì‹œ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_path = temp_file.name
    temp_file.close()
    
    try:
        yield temp_path
    finally:
        try:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        except:
            pass


class DocumentRectifier:
    """ë¬¸ì„œ 4ì  ì›ê·¼ ë³€í™˜ í´ë˜ìŠ¤"""
    
    @staticmethod
    def order_points(pts: np.ndarray) -> np.ndarray:
        """4ê°œì˜ ì ì„ [ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜] ìˆœì„œë¡œ ì •ë ¬"""
        rect = np.zeros((4, 2), dtype="float32")
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        return rect
    
    @staticmethod
    def calculate_skew_score(corners: np.ndarray, img_shape: tuple) -> float:
        """
        ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚° (0~100, ë†’ì„ìˆ˜ë¡ ê¸°ìš¸ì–´ì§)
        
        Returns:
            0-20: ê±°ì˜ ì •ë©´ (ì›ê·¼ ë³€í™˜ ë¶ˆí•„ìš”)
            20-50: ì•½ê°„ ê¸°ìš¸ì–´ì§ (ì„ íƒì )
            50+: ì‹¬í•˜ê²Œ ê¸°ìš¸ì–´ì§ (ì›ê·¼ ë³€í™˜ í•„ìš”)
        """
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        h, w = img_shape[:2]
        
        # 1. ë©´ì  ë¹„ìœ¨
        detected_area = cv2.contourArea(corners)
        image_area = h * w
        area_ratio = detected_area / image_area
        area_score = (1 - area_ratio) * 100
        
        # 2. ê°ë„ ì™œê³¡
        def angle_between(p1, p2, p3):
            v1 = p1 - p2
            v2 = p3 - p2
            angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))
            return np.degrees(angle)
        
        angles = [
            angle_between(tl, tr, br),
            angle_between(tr, br, bl),
            angle_between(br, bl, tl),
            angle_between(bl, tl, tr)
        ]
        
        angle_deviation = np.mean([abs(angle - 90) for angle in angles])
        angle_score = angle_deviation * 2
        
        # 3. ë³€ ê¸¸ì´ ë¹„ìœ¨
        top_width = np.linalg.norm(tr - tl)
        bottom_width = np.linalg.norm(br - bl)
        left_height = np.linalg.norm(bl - tl)
        right_height = np.linalg.norm(br - tr)
        
        width_ratio = abs(top_width - bottom_width) / max(top_width, bottom_width)
        height_ratio = abs(left_height - right_height) / max(left_height, right_height)
        ratio_score = (width_ratio + height_ratio) * 50
        
        total_score = (area_score * 0.3 + angle_score * 0.5 + ratio_score * 0.2)
        
        return min(100, total_score)
    
    @staticmethod
    def find_document_corners(img: np.ndarray) -> Optional[np.ndarray]:
        """ìœ¤ê³½ì„  ê²€ì¶œë¡œ ë¬¸ì„œ 4ê°œ ê¼­ì§€ì  ì°¾ê¸°"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
            
            for contour in contours:
                peri = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
                if len(approx) == 4:
                    return approx.reshape(4, 2)
            return None
        except:
            return None
    
    @staticmethod
    def apply_perspective_transform(img: np.ndarray, corners: np.ndarray) -> np.ndarray:
        """ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì •ë©´ìœ¼ë¡œ í¼ì¹˜ê¸°"""
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        
        widthA = np.sqrt((br[0] - bl[0]) ** 2 + (br[1] - bl[1]) ** 2)
        widthB = np.sqrt((tr[0] - tl[0]) ** 2 + (tr[1] - tl[1]) ** 2)
        maxWidth = max(int(widthA), int(widthB))
        
        heightA = np.sqrt((tr[0] - br[0]) ** 2 + (tr[1] - br[1]) ** 2)
        heightB = np.sqrt((tl[0] - bl[0]) ** 2 + (tl[1] - bl[1]) ** 2)
        maxHeight = max(int(heightA), int(heightB))
        
        dst = np.array([
            [0, 0],
            [maxWidth - 1, 0],
            [maxWidth - 1, maxHeight - 1],
            [0, maxHeight - 1]
        ], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect, dst)
        warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))
        return warped
    
    @staticmethod
    def rectify_auto(img: np.ndarray, threshold: float = 15.0) -> Tuple[np.ndarray, bool, float]:
        """
        ìë™ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ íŒë‹¨í•˜ì—¬ ì›ê·¼ ë³€í™˜ ì ìš©
        
        Args:
            img: ì…ë ¥ ì´ë¯¸ì§€
            threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ ë³€í™˜ ì ìš©)
        
        Returns:
            (ë³€í™˜ëœ ì´ë¯¸ì§€, ë³€í™˜ ì ìš© ì—¬ë¶€, ê¸°ìš¸ê¸° ì ìˆ˜)
        """
        try:
            corners = DocumentRectifier.find_document_corners(img)
            
            if corners is None:
                return img, False, 0.0
            
            h, w = img.shape[:2]
            detected_area = cv2.contourArea(corners)
            image_area = h * w
            area_ratio = detected_area / image_area
            
            if area_ratio < 0.3:
                return img, False, 0.0
            
            skew_score = DocumentRectifier.calculate_skew_score(corners, img.shape)
            
            if skew_score >= threshold:
                warped = DocumentRectifier.apply_perspective_transform(img, corners)
                return warped, True, skew_score
            else:
                return img, False, skew_score
                
        except:
            return img, False, 0.0


class InBodyMatcher:
    """ì¸ë°”ë”” ê²°ê³¼ì§€ ë§¤ì¹­ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: Optional[str] = None, 
                 auto_perspective: bool = True,
                 skew_threshold: float = 15.0,
                 target_height: int = 960):   # í•´ìƒë„ ë³€ê²½í•˜ê¸°  #fixme
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)
            auto_perspective: ìë™ ì›ê·¼ ë³€í™˜ í™œì„±í™” (ê¸°ë³¸: True)
            skew_threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (0-100, ê¸°ë³¸: 15.0)
            target_height: OCR ìˆ˜í–‰ ì‹œ ì •ê·œí™”í•  ë†’ì´ (ê¸°ë³¸: 2400)
        """
        self.target_height = target_height
        
        # í•´ìƒë„ì— ë”°ë¥¸ PaddleOCR íŒŒë¼ë¯¸í„° ë¯¸ì„¸ ì¡°ì • (ë¹„ë¡€ì ìš©)
        # 2400px ê¸°ì¤€ 2560 ì‚¬ìš©. 960pxì´ë©´ ì•½ 1000ì´ ì ë‹¹í•¨.
        det_limit = max(960, int(2560 * (target_height / 2400)))
        
        try:
            import logging
            logging.getLogger('ppocr').setLevel(logging.ERROR)
            
            self.ocr = PaddleOCR(
                lang='korean',
                ocr_version='PP-OCRv5',
                text_det_limit_side_len=det_limit,
                text_det_unclip_ratio=2.0,
                use_textline_orientation=True
            )
        except Exception as e:
            raise Exception(f"PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        self.correction_map = ConfigManager.get_correction_map()
        
        # Base Configuration (2400px)
        self.base_targets = ConfigManager.get_default_targets() 
        self.base_params = MatchingParameters()
        
        # Scaled (Initialized in extract_and_match)
        self.scale_manager: Optional[ScaleManager] = None
        self.params: Optional[ScaledMatchingParameters] = None
        self.targets: Optional[Dict[str, MatchConfig]] = None
        
        self.auto_perspective = auto_perspective
        self.skew_threshold = skew_threshold
        
        if config_path and os.path.exists(config_path):
            self._load_config(config_path)

    def _initialize_scaling(self, img_height: int):
        """í˜„ì¬ ì´ë¯¸ì§€ ë†’ì´ì— ë§ì¶° ìŠ¤ì¼€ì¼ë§ ì´ˆê¸°í™” (Method B)"""
        self.scale_manager = ScaleManager(target_height=img_height)
        
        # 1. MatchingParameters ìŠ¤ì¼€ì¼ë§
        self.params = self.base_params.scale(self.scale_manager)
        
        # 2. MatchConfig íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ë§
        self.targets = {}
        for key, cfg in self.base_targets.items():
            self.targets[key] = MatchConfig(
                regex=cfg.regex,
                y_range=self.scale_manager.scale_range(cfg.y_range),
                direction=cfg.direction,
                x_tolerance=self.scale_manager.scale_x(cfg.x_tolerance),
                y_tolerance=self.scale_manager.scale_y(cfg.y_tolerance),
                allow_zero=cfg.allow_zero
            )
            
        print(f"âš–ï¸ Scaling Initialized: ratio={self.scale_manager.scale_ratio:.3f} (h={img_height})")
    
    def _load_config(self, config_path: str):
        """ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            pass
    
    def _deskew(self, img: np.ndarray) -> np.ndarray:
        """Hough Transformì„ ì´ìš©í•œ ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì •"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            
            # Use scaled Hough parameters if available, else default
            min_len = self.params.hough_min_line_length if self.params else 100
            max_gap = self.params.hough_max_line_gap if self.params else 10
            
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=min_len, maxLineGap=max_gap)
            
            if lines is not None:
                angles = []
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))
                    if -10 < angle < 10:
                        angles.append(angle)
                
                if angles:
                    median_angle = np.median(angles)
                    (h, w) = img.shape[:2]
                    center = (w // 2, h // 2)
                    M = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
            
            return img
        except:
            return img
    
    def _preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            img = self._deskew(img)
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            enhanced = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)
            return enhanced
        except:
            return img
    
    def _extract_nodes(self, image_path: str) -> List[Dict[str, Any]]:
        """OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ"""
        try:
            result = self.ocr.predict(input=image_path)
            all_nodes = []
            
            if result:
                for res in result:
                    dt_polys = res.get('dt_polys', [])
                    rec_texts = res.get('rec_texts', [])
                    rec_scores = res.get('rec_scores', [])
                    
                    for poly, text, conf in zip(dt_polys, rec_texts, rec_scores):
                        pts = np.array(poly)
                        x_min, y_min = pts.min(axis=0)
                        x_max, y_max = pts.max(axis=0)
                        
                        node = {
                            'text': text.strip().replace(" ", "").replace("|", ""),
                            'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],
                            'h': int(y_max - y_min),
                            'center': [(x_min + x_max) / 2, (y_min + y_max) / 2],
                            'conf': float(conf)
                        }
                        all_nodes.append(node)
            
            return all_nodes
        except:
            return []
    
    def _correct_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì˜¤íƒ€ êµì •"""
        return self.correction_map.get(text, text)
    
    def _find_key_node(self, key: str, nodes: List[Dict], y_range: Tuple[int, int]) -> Optional[Dict]:
        """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        yr_min, yr_max = y_range
        # Use scaled margin
        y_buffer = self.params.keyword_search_y_margin if self.params else 50
        
        candidates = []
        for node in nodes:
            if not (yr_min - y_buffer <= node['center'][1] <= yr_max + y_buffer):
                continue
            
            text_without_parens = re.sub(r'\([^)]*\)', '', node['text'])
            corrected_text = self._correct_text(text_without_parens)
            original_corrected = self._correct_text(node['text'])
            
            if key in corrected_text or key in original_corrected:
                candidates.append(node)
            else:
                ratio1 = difflib.SequenceMatcher(None, key, corrected_text).ratio()
                ratio2 = difflib.SequenceMatcher(None, key, original_corrected).ratio()
                max_ratio = max(ratio1, ratio2)
                
                # Similarity threshold (No Scale)
                threshold = self.params.similarity_threshold if self.params else 0.5
                if max_ratio > threshold:
                    candidates.append(node)
        
        if candidates:
            best = max(candidates, key=lambda x: x['conf'])
            return best
        
        return None
    
    def _match_value(self, key: str, key_node: Dict, config: MatchConfig, 
                     nodes: List[Dict]) -> Optional[str]:
        """ê°’ ë…¸ë“œ ë§¤ì¹­"""
        # Ensure params are loaded
        if not self.params:
            raise RuntimeError("MatchingParameters not initialized. Call extract_and_match first.")

        p = self.params
        yr_min, yr_max = config.y_range
        candidates = []
        
        # ë””ë²„ê·¸ ëª¨ë“œ
        debug = key in ["ì²´ì¤‘ì¡°ì ˆ", "ì§€ë°©ì¡°ì ˆ", "ê·¼ìœ¡ì¡°ì ˆ"]
        
        # Check buffer for debug printing (Scaled)
        y_chk_buffer = p.roi_y_margin * 2
        
        for node in nodes:
            if node == key_node:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ê·œí™”
            clean_text = re.sub(r'\(.*?\)', '', node['text'])
            clean_text = clean_text.replace('I', '1').replace('l', '1').replace(',', '.')
            
            # ë””ë²„ê·¸: Y ë²”ìœ„ ë‚´ì˜ ëª¨ë“  ë…¸ë“œ ì¶œë ¥
            if debug and (yr_min - y_chk_buffer <= node['center'][1] <= yr_max + y_chk_buffer):
                print(f"  ë…¸ë“œ: '{node['text']}' (ì •ê·œí™”: '{clean_text}') at y={node['center'][1]:.0f}")
            
            # ì •ê·œì‹ ë§¤ì¹­
            match = re.search(config.regex, clean_text)
            if not match:
                continue
            
            # ê°’ ì¶”ì¶œ
            val = match.group(1)
            
            # ìœ„ì¹˜ ê³„ì‚°
            dx = node['center'][0] - key_node['bbox'][2] if config.direction == "right" else abs(node['center'][0] - key_node['center'][0])
            dy = abs(node['center'][1] - key_node['center'][1])
            
            # ROI ì²´í¬ (ì²´ì§€ë°©ë¥  íŠ¹ìˆ˜ ì²˜ë¦¬)
            if key == "ì²´ì§€ë°©ë¥ " and node['center'][1] < p.body_fat_percent_y_min:
                continue
            
            in_roi = (yr_min - p.roi_y_margin <= node['center'][1] <= yr_max + p.roi_y_margin)
            
            # Direction checks using scaled parameters
            # config.x_tolerance is already scaled in _initialize_scaling
            is_right_dir = (
                config.direction == "right" and 
                p.right_dir_x_min < dx < config.x_tolerance and 
                dy < p.right_dir_y_max
            )
            is_down_dir = (
                config.direction == "down" and 
                0 < (node['center'][1] - key_node['bbox'][3]) < p.down_dir_y_max and 
                abs(node['center'][0] - key_node['center'][0]) < p.down_dir_x_tolerance
            )
            
            if not in_roi or not (is_right_dir or is_down_dir):
                continue
            
            # 0ê°’ í•„í„°ë§
            if not config.allow_zero:
                if val in ["0.0", "0", "+0.0"]:
                    continue
            
            # ëˆˆê¸ˆì„  ê°’ í•„í„°ë§
            is_scale_mark = node.get('h', 0) < p.scale_mark_height_max
            
            # ê±°ë¦¬ ì ìˆ˜ ê³„ì‚° (Scaled weight)
            dist_score = (dy * p.distance_y_weight) + abs(dx)
            
            # Large node bonus (No Scale)
            if node.get('h', 0) > p.large_node_height_min:
                dist_score -= p.large_node_bonus
            
            # Scale mark penalty (No Scale)
            if is_scale_mark:
                dist_score += p.scale_mark_penalty
            
            candidates.append((dist_score, val, node, dx, dy))
        
        if candidates:
            candidates.sort(key=lambda x: x[0])
            best_match = candidates[0]
            if debug:
                print(f"  [{key}] Selected: {best_match[1]} (score={best_match[0]:.0f})")
            return best_match[1]
        
        return None
    
    def _extract_segment_evaluations(self, nodes: List[Dict]) -> Dict[str, str]:
        """ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ"""
        if not self.params:
             return {}

        p = self.params
        evals = ["í‘œì¤€ì´í•˜", "í‘œì¤€ì´ìƒ", "í‘œì¤€"]
        
        seg_nodes = sorted(
            [n for n in nodes if any(ev in n['text'] for ev in evals) and (p.segment_y_min <= n['center'][1] <= p.segment_y_max)],
            key=lambda x: x['center'][1]
        )
        
        row_top = sorted([n for n in seg_nodes if n['center'][1] < p.segment_row_top_max], key=lambda x: x['center'][0])
        row_mid = sorted([n for n in seg_nodes if p.segment_row_mid_min <= n['center'][1] <= p.segment_row_mid_max], key=lambda x: x['center'][0])
        row_bot = sorted([n for n in seg_nodes if n['center'][1] > p.segment_row_bot_min], key=lambda x: x['center'][0])
        
        results = {}
        
        try:
            if len(row_top) >= 4:
                results["ì™¼ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[3]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_mid) >= 2:
                results["ë³µë¶€ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_mid[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ë³µë¶€ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_mid[1]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_bot) >= 4:
                results["ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[3]['text']), "ë¯¸ê²€ì¶œ")
        except:
            pass
        
        return results
    
    def extract_and_match(self, image_path: str) -> Dict[str, Optional[str]]:
        """ì´ë¯¸ì§€ì—ì„œ ì¸ë°”ë”” ë°ì´í„° ì¶”ì¶œ ë° ë§¤ì¹­"""
        import time
        start_time = time.time()
        
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        try:
            # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ì›ê·¼ ë³€í™˜
            step_start = time.time()
            src_img = cv2.imread(image_path)
            if src_img is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {src_img.shape[:2]}")
            
            if self.auto_perspective:
                src_img, applied, skew_score = DocumentRectifier.rectify_auto(
                    src_img, threshold=self.skew_threshold
                )
                if applied:
                    print(f"ğŸ”„ ì›ê·¼ ë³€í™˜ ì ìš© (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f})")
                else:
                    if skew_score > 0:
                        print(f"âœ“ ì •ë©´ ë¬¸ì„œ (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, ì„ê³„ê°’: {self.skew_threshold})")
            print(f"â±ï¸ [1/4] ì´ë¯¸ì§€ ë¡œë“œ ë° ë³´ì •: {time.time() - step_start:.4f}ì´ˆ")
            
            # 2. í•´ìƒë„ ì •ê·œí™” ë° ìŠ¤ì¼€ì¼ë§ ì´ˆê¸°í™”
            step_start = time.time()
            target_h = self.target_height
            ratio = target_h / src_img.shape[0]
            img = cv2.resize(
                src_img,
                (int(src_img.shape[1] * ratio), target_h),
                interpolation=cv2.INTER_LANCZOS4
            )
            
            print(f"ğŸ“ ì •ê·œí™”ëœ í¬ê¸°: {img.shape[:2]}")
            
            # ìŠ¤ì¼€ì¼ë§ ì´ˆê¸°í™” (Method B)
            self._initialize_scaling(img.shape[0])
            print(f"â±ï¸ [2/4] ë¦¬ì‚¬ì´ì§• ë° ìŠ¤ì¼€ì¼ë§ ì´ˆê¸°í™”: {time.time() - step_start:.4f}ì´ˆ")
            
            # 3. ì „ì²˜ë¦¬ ë° OCR ìˆ˜í–‰
            step_start = time.time()
            with temporary_file() as temp_path:
                processed_img = self._preprocess_image(img)
                cv2.imwrite(temp_path, processed_img)
                all_nodes = self._extract_nodes(temp_path)
            
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë…¸ë“œ: {len(all_nodes)}ê°œ")
            print(f"â±ï¸ [3/4] ì „ì²˜ë¦¬ ë° OCR ì¶”ë¡ : {time.time() - step_start:.4f}ì´ˆ")
            
            if not all_nodes:
                print("âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # 4. ë§¤ì¹­ ìˆ˜í–‰
            step_start = time.time()
            matched_data = {}
            
            for key, config in self.targets.items():
                key_node = self._find_key_node(key, all_nodes, config.y_range)
                
                if not key_node:
                    matched_data[key] = None
                    continue
                
                value = self._match_value(key, key_node, config, all_nodes)
                matched_data[key] = value
            
            # ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ
            segment_results = self._extract_segment_evaluations(all_nodes)
            matched_data.update(segment_results)
            
            # ë§¤ì¹­ í†µê³„
            detected = sum(1 for v in matched_data.values() if v is not None)
            total = len(matched_data)
            print(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {detected}/{total} í•­ëª© ({detected/total*100:.1f}%)")
            print(f"â±ï¸ [4/4] ë°ì´í„° ë§¤ì¹­: {time.time() - step_start:.4f}ì´ˆ")
            
            print(f"âœ¨ ì „ì²´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.4f}ì´ˆ")
            
            return matched_data
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def save_results(self, results: Dict, output_path: str, format: str = 'json'):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if format == 'json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            elif format in ['dict', 'python']:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write("# InBody ì¸¡ì • ê²°ê³¼\n")
                    f.write("inbody_data = ")
                    f.write(json.dumps(results, ensure_ascii=False, indent=4))
                print(f"ğŸ’¾ Python í˜•ì‹ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({output_path}): {e}")
    
    def get_structured_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        structured = {
            "ê¸°ë³¸ì •ë³´": {
                "ì‹ ì¥": results.get("ì‹ ì¥"),
                "ì—°ë ¹": results.get("ì—°ë ¹"),
                "ì„±ë³„": results.get("ì„±ë³„"),
            },
            "ì²´ì„±ë¶„": {
                "ì²´ìˆ˜ë¶„": results.get("ì²´ìˆ˜ë¶„"),
                "ë‹¨ë°±ì§ˆ": results.get("ë‹¨ë°±ì§ˆ"),
                "ë¬´ê¸°ì§ˆ": results.get("ë¬´ê¸°ì§ˆ"),
                "ì²´ì§€ë°©": results.get("ì²´ì§€ë°©"),
            },
            "ì²´ì¤‘ê´€ë¦¬": {
                "ì²´ì¤‘": results.get("ì²´ì¤‘"),
                "ê³¨ê²©ê·¼ëŸ‰": results.get("ê³¨ê²©ê·¼ëŸ‰"),
                "ì²´ì§€ë°©ëŸ‰": results.get("ì²´ì§€ë°©ëŸ‰"),
                "ì ì •ì²´ì¤‘": results.get("ì ì •ì²´ì¤‘"),
                "ì²´ì¤‘ì¡°ì ˆ": results.get("ì²´ì¤‘ì¡°ì ˆ"),
                "ì§€ë°©ì¡°ì ˆ": results.get("ì§€ë°©ì¡°ì ˆ"),
                "ê·¼ìœ¡ì¡°ì ˆ": results.get("ê·¼ìœ¡ì¡°ì ˆ"),
            },
            "ë¹„ë§Œë¶„ì„": {
                "BMI": results.get("BMI"),
                "ì²´ì§€ë°©ë¥ ": results.get("ì²´ì§€ë°©ë¥ "),
                "ë³µë¶€ì§€ë°©ë¥ ": results.get("ë³µë¶€ì§€ë°©ë¥ "),
                "ë‚´ì¥ì§€ë°©ë ˆë²¨": results.get("ë‚´ì¥ì§€ë°©ë ˆë²¨"),
                "ë¹„ë§Œë„": results.get("ë¹„ë§Œë„"),
            },
            "ì—°êµ¬í•­ëª©": {
                "ì œì§€ë°©ëŸ‰": results.get("ì œì§€ë°©ëŸ‰"),
                "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": results.get("ê¸°ì´ˆëŒ€ì‚¬ëŸ‰"),
                "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": results.get("ê¶Œì¥ì„­ì·¨ì—´ëŸ‰"),
            },
            "ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"),
                "ë³µë¶€": results.get("ë³µë¶€ ê·¼ìœ¡"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"),
            },
            "ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"),
                "ë³µë¶€": results.get("ë³µë¶€ ì²´ì§€ë°©"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"),
            }
        }
        
        return structured


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    img_path = sys.argv[1] if len(sys.argv) > 1 else "444.jpg"
    
    try:
        print("=" * 60)
        print("InBody OCR ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        if not os.path.exists(img_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            sys.exit(1)
        
        print(f"âœ“ íŒŒì¼ í™•ì¸: {img_path}")
        
        matcher = InBodyMatcher(
            auto_perspective=True,
            skew_threshold=15.0
        )
        
        print("âœ“ InBodyMatcher ì´ˆê¸°í™” ì™„ë£Œ")
        print()
        
        result = matcher.extract_and_match(img_path)
        
        if not result:
            print("\nâŒ OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            sys.exit(1)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print(f"{'í•­ëª©':<15} | {'ê²°ê³¼'}")
        print("-" * 50)
        
        has_data = False
        for key, val in result.items():
            if val and val != "ë¯¸ê²€ì¶œ":
                has_data = True
            print(f"{key:<15} | {val if val else 'ë¯¸ê²€ì¶œ'}")
        
        print("=" * 50)
        
        if not has_data:
            print("\nâš ï¸ ëª¨ë“  í•­ëª©ì´ ë¯¸ê²€ì¶œì…ë‹ˆë‹¤!")
        else:
            structured = matcher.get_structured_results(result)
            
            print("\n" + "=" * 50)
            print("ğŸ“¦ ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬")
            print("=" * 50)
            print(json.dumps(structured, ensure_ascii=False, indent=2))
            print("=" * 50)
            
            print("\nâœ… ì™„ë£Œ")
        
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()