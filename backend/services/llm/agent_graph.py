from typing import TypedDict, Optional, Annotated, Dict
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# Add paths for imports
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from shared.llm_clients import create_llm_client, OpenAIClient, OllamaClient
from schemas.llm import StatusAnalysisInput, GoalPlanInput
from .prompt_generator import create_inbody_analysis_prompt
from shared.models import InBodyMeasurements

# LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì œë¡œëŠ” ì„œë¹„ìŠ¤ì—ì„œ ì£¼ì…ë°›ëŠ” ê²ƒì´ ì¢‹ìŒ)
llm_client = create_llm_client("gpt-4o-mini")


# --- 1. ìƒíƒœ ì •ì˜ ---
class AnalysisState(TypedDict):
    """LLM1 (ê±´ê°• ìƒíƒœ ë¶„ì„ / Q&A) ì—ì´ì „íŠ¸ì˜ ìƒíƒœ"""
    # ì…ë ¥: ê±´ê°• ê¸°ë¡ ë°ì´í„°
    analysis_input: StatusAnalysisInput
    # ëŒ€í™” ê¸°ë¡ (HumanMessage, AIMessageì˜ ë¦¬ìŠ¤íŠ¸)
    # add_messagesëŠ” ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
    messages: Annotated[list, add_messages]
    # ìƒì„±ëœ ì„ë² ë”© ë²¡í„°
    embedding: Optional[Dict[str, list]]
    
    
# --- 2. ë…¸ë“œ(ê·¸ë˜í”„ì˜ ê° ë‹¨ê³„) ì •ì˜ ---
def generate_initial_analysis(state: AnalysisState) -> dict:
    """Node 1: ìµœì´ˆ ë¶„ì„ ê²°ê³¼ ìƒì„± ë° ì„ë² ë”©"""
    print("--- LLM1: ìµœì´ˆ ë¶„ì„ ìƒì„± ---")
    analysis_input = state["analysis_input"]

    # 1. InBodyMeasurements ëª¨ë¸ë¡œ ë³€í™˜ (prompt_generatorê°€ ìš”êµ¬í•˜ëŠ” íƒ€ì…)
    measurements_dict = analysis_input.measurements.copy()
    measurements_dict["stage2_ê·¼ìœ¡ë³´ì •ì²´í˜•"] = analysis_input.body_type1
    measurements_dict["stage3_ìƒí•˜ì²´ë°¸ëŸ°ìŠ¤"] = analysis_input.body_type2
    measurements = InBodyMeasurements(**measurements_dict)

    # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
    system_prompt, user_prompt = create_inbody_analysis_prompt(measurements)
    response = llm_client.generate_chat(system_prompt, user_prompt)
    
    # --- 3. ì„ë² ë”© ìƒì„± (embedder.py ë¡œì§ ë°˜ì˜) ---
    # ì´ ë‹¨ê³„ì—ì„œëŠ” ë²¡í„°ë§Œ ìƒì„±í•©ë‹ˆë‹¤.
    # ì‹¤ì œ DB ì €ì¥ì€ ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ì´ ë…¸ë“œì˜ ê²°ê³¼(response, embedding)ë¥¼ ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    print("\nğŸ”¢ ì„ë² ë”© ìƒì„± ì¤‘...")
    embedding_1536 = None
    embedding_1024 = None

    # 3-1. OpenAI ì„ë² ë”© ìƒì„± (1536ì°¨ì›)
    try:
        openai_client = OpenAIClient()
        embedding_1536 = openai_client.create_embedding(text=response)
        print(f"  âœ“ OpenAI ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding_1536)})")
    except Exception as e:
        print(f"  âš ï¸  OpenAI ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")

    # 3-2. Ollama bge-m3 ì„ë² ë”© ìƒì„± (1024ì°¨ì›)
    try:
        ollama_client = OllamaClient(model="bge-m3:latest", embedding_model="bge-m3:latest")
        embedding_1024 = ollama_client.create_embedding(text=response)
        print(f"  âœ“ Ollama bge-m3 ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding_1024)})")
    except Exception as e:
        print(f"  âš ï¸  Ollama ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        
    final_embedding = {
        "embedding_1536": embedding_1536,
        "embedding_1024": embedding_1024,
    }

    # AIì˜ ì²« ë‹µë³€ê³¼ ìƒì„±ëœ ì„ë² ë”©ì„ ìƒíƒœì— ì¶”ê°€
    # ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œëŠ” ì´ ì‘ë‹µ(response)ì— ë§ë¶™ì—¬ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    return {
        "messages": [("ai", response)],
        "embedding": final_embedding
    }

def _generate_qa_response(state: AnalysisState, category_name: str, system_prompt: str) -> dict:
    """ê³µí†µ Q&A ë‹µë³€ ìƒì„± ë¡œì§"""
    print(f"--- LLM1: Q&A ë‹µë³€ ìƒì„± ({category_name}) ---")

    # ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸
    user_question = state["messages"][-1].content
    
    # LLM í´ë¼ì´ì–¸íŠ¸ê°€ ëŒ€í™” ê¸°ë¡ì„ ì§€ì›í•œë‹¤ê³  ê°€ì •
    # system_promptì™€ ì „ì²´ ëŒ€í™” ê¸°ë¡(messages)ì„ í•¨ê»˜ ì „ë‹¬
    # TODO: generate_chat_with_history ë©”ì„œë“œë¥¼ LLM í´ë¼ì´ì–¸íŠ¸ì— êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
    # response = llm_client.generate_chat_with_history(
    #     system_prompt=system_prompt, 
    #     messages=state["messages"]
    # )

    # ì„ì‹œ Mock ì‘ë‹µ
    response = f"'{user_question}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ '{category_name}' ì£¼ì œì— ë§ì¶° ìƒì„±ë©ë‹ˆë‹¤. (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©ë¨)"

    return {"messages": [("ai", response)]}


def qa_strength_weakness(state: AnalysisState) -> dict:
    """Node 2-1: ê°•ì /ì•½ì  Q&A"""
    system_prompt = """ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ì˜ ì²´ì„±ë¶„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ìì‹ ì˜ ì‹ ì²´ ê°•ì ê³¼ ì•½ì ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
    ì´ì „ ëŒ€í™”ì—ì„œ ì œê³µëœ ì¸ë°”ë”” ë°ì´í„°ì™€ ìµœì´ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ í•­ëª©ì— ëŒ€í•´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - **ê°•ì **: í‘œì¤€ ë²”ìœ„ ì´ìƒì´ê±°ë‚˜ ê¸ì •ì ì¸ ì§€í‘œ (ì˜ˆ: ë†’ì€ ê³¨ê²©ê·¼ëŸ‰, ì ì • ì²´ìˆ˜ë¶„ ë“±)
    - **ì•½ì **: ê°œì„ ì´ í•„ìš”í•œ ì§€í‘œ (ì˜ˆ: ë†’ì€ ì²´ì§€ë°©ë¥ , ë¶€ìœ„ë³„ ë¶ˆê· í˜•, ë‚®ì€ ê¸°ì´ˆëŒ€ì‚¬ëŸ‰ ë“±)
    - **ì¢…í•© í‰ê°€**: í˜„ì¬ ì‹ ì²´ì˜ ê°€ì¥ í° íŠ¹ì§•ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."""
    return _generate_qa_response(state, "ê°•ì /ì•½ì ", system_prompt)

def qa_health_status(state: AnalysisState) -> dict:
    """Node 2-2: ê±´ê°• ìƒíƒœ Q&A"""
    system_prompt = """ë‹¹ì‹ ì€ ì˜ˆë°© ì˜í•™ ê´€ì ì—ì„œ ì¡°ì–¸í•˜ëŠ” ê±´ê°• ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ í˜„ì¬ ìì‹ ì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ê±´ê°• ê´€ì ì—ì„œ ê¸ì •ì ì¸ ë¶€ë¶„ê³¼ ì ì¬ì ì¸ ìœ„í—˜ ìš”ì†Œë¥¼ ë‚˜ëˆ„ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - **ê¸ì •ì  ì‹ í˜¸**: ì •ìƒ ë²”ìœ„ì— ìˆëŠ” BMI, ê·¼ìœ¡ëŸ‰, í˜ˆì•• ê´€ë ¨ ì§€í‘œ ë“±
    - **ì£¼ì˜/ê²½ê³  ì‹ í˜¸**: ë³µë¶€ì§€ë°©ë¥ , ë‚´ì¥ì§€ë°©ë ˆë²¨ ë“± ê±´ê°• ìœ„í—˜ë„ì™€ ì§ê²°ë˜ëŠ” ì§€í‘œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ì–´ë–¤ ì§ˆë³‘ì˜ ìœ„í—˜ì„ ë†’ì¼ ìˆ˜ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”. (ì˜í•™ì  ì§„ë‹¨ì´ ì•„ë‹˜ì„ ëª…ì‹œ)
    - **ê²°ë¡ **: í˜„ì¬ ìƒíƒœê°€ 'ë§¤ìš° ê±´ê°•', 'ê±´ê°•í•œ í¸', 'ì£¼ì˜ í•„ìš”', 'ê´€ë¦¬ í•„ìš”' ì¤‘ ì–´ë””ì— ê°€ê¹Œìš´ì§€ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”."""
    return _generate_qa_response(state, "ê±´ê°• ìƒíƒœ", system_prompt)

def qa_impact(state: AnalysisState) -> dict:
    """Node 2-3: ì¼ìƒ/ìš´ë™ ì˜í–¥ Q&A"""
    system_prompt = """ë‹¹ì‹ ì€ ìš´ë™ìƒë¦¬í•™ìì´ì ë¼ì´í”„ìŠ¤íƒ€ì¼ ì½”ì¹˜ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ í˜„ì¬ ì‹ ì²´ ìƒíƒœê°€ ì¼ìƒê³¼ ìš´ë™ ìˆ˜í–‰ëŠ¥ë ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í˜„ì¬ ì²´ì„±ë¶„ ìƒíƒœê°€ ì–´ë–¤ ê²°ê³¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - **ìš´ë™ ìˆ˜í–‰ëŠ¥ë ¥**: í˜„ì¬ ê·¼ìœ¡ëŸ‰ê³¼ ì²´ì§€ë°©ëŸ‰ì´ ê·¼ë ¥, ì§€êµ¬ë ¥, ìˆœë°œë ¥ ë“±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ì˜ˆ: 'í•˜ì²´ ê·¼ìœ¡ì´ ë°œë‹¬í•˜ì—¬ ìŠ¤ì¿¼íŠ¸ë‚˜ ë“±ì‚°ì— ìœ ë¦¬í•˜ì§€ë§Œ, ì²´ì¤‘ ëŒ€ë¹„ ìƒì²´ ê·¼ë ¥ì´ ë¶€ì¡±í•˜ì—¬ í„±ê±¸ì´ ê°™ì€ ìš´ë™ì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
    - **ì¼ìƒ ìƒí™œ**: ê¸°ì´ˆëŒ€ì‚¬ëŸ‰, ì²´ë ¥ ìˆ˜ì¤€ì´ ì¼ìƒì ì¸ í”¼ë¡œë„, í™œë™ì„±, ìì„¸ ìœ ì§€ ë“±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ì˜ˆ: 'ê¸°ì´ˆëŒ€ì‚¬ëŸ‰ì´ ë‚®ì•„ ì‰½ê²Œ í”¼ë¡œê°ì„ ëŠë‚„ ìˆ˜ ìˆìœ¼ë©°, ì½”ì–´ ê·¼ìœ¡ ë¶€ì¡±ìœ¼ë¡œ ì˜¤ë˜ ì•‰ì•„ìˆì„ ë•Œ í—ˆë¦¬ í†µì¦ì„ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')"""
    return _generate_qa_response(state, "ì¼ìƒ/ìš´ë™ ì˜í–¥", system_prompt)

def qa_priority(state: AnalysisState) -> dict:
    """Node 2-4: ê°œì„  ìš°ì„ ìˆœìœ„ Q&A"""
    system_prompt = """ë‹¹ì‹ ì€ ë™ê¸°ë¶€ì—¬ê°€ ë›°ì–´ë‚œ í˜„ì‹¤ì ì¸ í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ê°€ì¥ ë¨¼ì € ê°œì„ í•´ì•¼ í•  ìš°ì„ ìˆœìœ„ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤.
    ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬, ê°€ì¥ ì‹œê¸‰í•˜ê³  íš¨ê³¼ê°€ í° 'ì•¡ì…˜ ì•„ì´í…œ'ì„ 3ê°€ì§€ ìš°ì„ ìˆœìœ„ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
    - **1ìˆœìœ„ (ê°€ì¥ ì‹œê¸‰)**: ê±´ê°• ìœ„í—˜ì„ ë‚®ì¶”ê±°ë‚˜, ê°€ì¥ í° ë¶ˆê· í˜•ì„ í•´ì†Œí•˜ê¸° ìœ„í•œ ê²ƒ (ì˜ˆ: ë‚´ì¥ì§€ë°© ê°ì†Œë¥¼ ìœ„í•œ ìœ ì‚°ì†Œ ìš´ë™ ì‹œì‘)
    - **2ìˆœìœ„ (ì²´ê° íš¨ê³¼ê°€ í° ê²ƒ)**: ë‹¨ê¸°ê°„ì— ë³€í™”ë¥¼ ëŠë¼ê±°ë‚˜, ë‹¤ë¥¸ ìš´ë™ ëŠ¥ë ¥ í–¥ìƒì— ê¸°ë°˜ì´ ë˜ëŠ” ê²ƒ (ì˜ˆ: ì½”ì–´ ê·¼ë ¥ ê°•í™”)
    - **3ìˆœìœ„ (ì¥ê¸°ì  ê´€ì )**: ê¾¸ì¤€íˆ ê°œì„ í•´ë‚˜ê°€ì•¼ í•  ìƒí™œ ìŠµê´€ì´ë‚˜ ë³´ì¡°ì ì¸ ìš´ë™ (ì˜ˆ: ì‹ë‹¨ ê¸°ë¡ ì‹œì‘, ìˆ˜ë©´ ì‹œê°„ í™•ë³´)
    ê° í•­ëª©ì— ëŒ€í•´ 'ì™œ' ê·¸ê²ƒì´ ì¤‘ìš”í•œì§€ ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
    return _generate_qa_response(state, "ê°œì„  ìš°ì„ ìˆœìœ„", system_prompt)

def qa_general(state: AnalysisState) -> dict:
    """Node 2-5: ì¼ë°˜ Q&A"""
    system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ í”¼íŠ¸ë‹ˆìŠ¤ ì½”ì¹˜ì…ë‹ˆë‹¤. 
    ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ë©´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""
    return _generate_qa_response(state, "ì¼ë°˜", system_prompt)


def route_qa(state: AnalysisState) -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ì ì ˆí•œ Q&A ë…¸ë“œë¡œ ë¼ìš°íŒ…"""
    user_question = state["messages"][-1].content.strip()

    if user_question.startswith("1"):
        return "qa_strength_weakness"
    elif user_question.startswith("2"):
        return "qa_health_status"
    elif user_question.startswith("3"):
        return "qa_impact"
    elif user_question.startswith("4"):
        return "qa_priority"
    else:
        # ì‚¬ìš©ìê°€ ì¹´í…Œê³ ë¦¬ ì„ íƒì´ ì•„ë‹Œ ì¼ë°˜ ì§ˆë¬¸ì„ í•œ ê²½ìš°
        # ë˜ëŠ” ì´ì „ ì¹´í…Œê³ ë¦¬ ëŒ€í™”ì— ì´ì–´ì„œ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°,
        # ë§ˆì§€ë§‰ AI ë‹µë³€ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  íŒë‹¨í•  ìˆ˜ë„ ìˆì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì¼ë°˜ìœ¼ë¡œ ë³´ëƒ…ë‹ˆë‹¤.
        return "qa_general"


# --- 3. ê·¸ë˜í”„ ìƒì„± ---
def create_analysis_agent():
    """
    ê±´ê°• ë¶„ì„ ë° íœ´ë¨¼ í”¼ë“œë°± Q&A ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤.
    
    - `interrupt_after`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° AI ì‘ë‹µ í›„ì— ë©ˆì¶”ê³  ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    - ì‚¬ìš©ìê°€ '5. ê´œì°®ìŠµë‹ˆë‹¤'ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì€ ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ì²˜ë¦¬í•˜ë©°,
      ë” ì´ìƒ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤.
    """
    workflow = StateGraph(AnalysisState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("initial_analysis", generate_initial_analysis)
    workflow.add_node("qa_strength_weakness", qa_strength_weakness)
    workflow.add_node("qa_health_status", qa_health_status)
    workflow.add_node("qa_impact", qa_impact)
    workflow.add_node("qa_priority", qa_priority)
    workflow.add_node("qa_general", qa_general)
    
    # ì§„ì…ì  ì„¤ì •
    workflow.set_entry_point("initial_analysis")
    
    # ì—£ì§€ ì—°ê²°
    # ìµœì´ˆ ë¶„ì„ í›„ì—ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
    workflow.add_conditional_edges(
        "initial_analysis",
        route_qa,
        {
            "qa_strength_weakness": "qa_strength_weakness",
            "qa_health_status": "qa_health_status",
            "qa_impact": "qa_impact",
            "qa_priority": "qa_priority",
            "qa_general": "qa_general",
        }
    )
    
    # ê° Q&A ë…¸ë“œëŠ” ë‹¤ì‹œ ë¼ìš°í„°ë¥¼ ê±°ì³ ë‹¤ìŒ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ë£¨í”„)
    workflow.add_conditional_edges("qa_strength_weakness", route_qa, {
        "qa_strength_weakness": "qa_strength_weakness", "qa_health_status": "qa_health_status", "qa_impact": "qa_impact", "qa_priority": "qa_priority", "qa_general": "qa_general"
    })
    workflow.add_conditional_edges("qa_health_status", route_qa, {
        "qa_strength_weakness": "qa_strength_weakness", "qa_health_status": "qa_health_status", "qa_impact": "qa_impact", "qa_priority": "qa_priority", "qa_general": "qa_general"
    })
    workflow.add_conditional_edges("qa_impact", route_qa, {
        "qa_strength_weakness": "qa_strength_weakness", "qa_health_status": "qa_health_status", "qa_impact": "qa_impact", "qa_priority": "qa_priority", "qa_general": "qa_general"
    })
    workflow.add_conditional_edges("qa_priority", route_qa, {
        "qa_strength_weakness": "qa_strength_weakness", "qa_health_status": "qa_health_status", "qa_impact": "qa_impact", "qa_priority": "qa_priority", "qa_general": "qa_general"
    })
    workflow.add_conditional_edges("qa_general", route_qa, {
        "qa_strength_weakness": "qa_strength_weakness", "qa_health_status": "qa_health_status", "qa_impact": "qa_impact", "qa_priority": "qa_priority", "qa_general": "qa_general"
    })


    # íœ´ë¨¼ í”¼ë“œë°±ì„ ìœ„í•´, LLMì´ ë‹µë³€ì„ ìƒì„±í•œ í›„ì—ëŠ” í•­ìƒ ë©ˆì¶¥ë‹ˆë‹¤.
    # ì„œë¹„ìŠ¤(API)ëŠ” ì´ ë©ˆì¶˜ ì§€ì ì—ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    agent = workflow.compile(interrupt_after=["initial_analysis", "qa_strength_weakness", "qa_health_status", "qa_impact", "qa_priority", "qa_general"])
    
    return agent


### ì‚¬ìš© ì˜ˆì‹œ (FastAPI ë¼ìš°í„°ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë ì§€ì— ëŒ€í•œ ê°œë…) ###
# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ì„œë¹„ìŠ¤ ì½”ë“œì—ëŠ” í¬í•¨ë˜ì§€ ì•Šìœ¼ë©°, ê·¸ë˜í”„ì˜ ë™ì‘ì„ ì„¤ëª…í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
if __name__ == "__main__":
    from datetime import datetime
    
    # 1. ì—ì´ì „íŠ¸ ìƒì„±
    analysis_agent = create_analysis_agent()
    
    # 2. ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ìµœì´ˆ ë¶„ì„ ì‹¤í–‰
    # ì‚¬ìš©ìì˜ health_recordì—ì„œ analysis_inputì„ ì¤€ë¹„í–ˆë‹¤ê³  ê°€ì •
    mock_analysis_input = StatusAnalysisInput(
        record_id=1, user_id=1, measured_at=datetime.now(),
        measurements={"ì„±ë³„": "ë‚¨ì„±", "ë‚˜ì´": 30, "ì‹ ì¥": 175, "ì²´ì¤‘": 75, "BMI": 24.5, "ì²´ì§€ë°©ë¥ ": 20.1, "ê³¨ê²©ê·¼ëŸ‰": 35.2, "ê·¼ìœ¡_ë¶€ìœ„ë³„ë“±ê¸‰": {"ì™¼íŒ”": "í‘œì¤€", "ì˜¤ë¥¸íŒ”": "í‘œì¤€", "ë³µë¶€": "í‘œì¤€", "ì™¼ë‹¤ë¦¬": "í‘œì¤€ì´ìƒ", "ì˜¤ë¥¸ë‹¤ë¦¬": "í‘œì¤€ì´ìƒ"}},
        body_type1="í‘œì¤€í˜•", body_type2="í•˜ì²´ë°œë‹¬í˜•"
    )
    config = {"configurable": {"thread_id": "user_123_thread"}}
    
    # ìµœì´ˆ ë¶„ì„ ì‹¤í–‰ -> `initial_analysis` ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    # ì´ ì‹œì ì—ì„œëŠ” ì•„ì§ ë‹¤ìŒ ë…¸ë“œë¡œ ê°€ì§€ ì•ŠìŒ.
    initial_state = analysis_agent.invoke(
        {"analysis_input": mock_analysis_input}, 
        config=config
    )
    initial_response = initial_state['messages'][-1].content
    print(f"AI (Initial): {initial_response[:200]}...")
    
    # ì„ë² ë”© ìƒì„± í™•ì¸
    if initial_state.get("embedding"):
        print("\n[ì„ë² ë”© ìƒì„± í™•ì¸]")
        if initial_state["embedding"].get("embedding_1536"):
            print("  âœ“ OpenAI (1536d) ì„ë² ë”© ìƒì„±ë¨")
        if initial_state["embedding"].get("embedding_1024"):
            print("  âœ“ Ollama (1024d) ì„ë² ë”© ìƒì„±ë¨")
            
    print("\n[í”„ë¡ íŠ¸ì—”ë“œ: ì‚¬ìš©ìì—ê²Œ 5ê°€ì§€ ì„ íƒì§€ í‘œì‹œ]")
    
    # 3. ì‚¬ìš©ìê°€ '1ë²ˆ' ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí–ˆë‹¤ê³  ê°€ì •
    user_choice = "1. ì–´ë””ê°€ ë¶€ì¡±í•˜ê³ , ì–´ë””ê°€ ê´œì°®ì€ê°€ìš”?"
    print(f"\nUser: {user_choice}")
    
    # `route_qa`ê°€ 'qa_strength_weakness'ë¥¼ ì„ íƒí•˜ê³ , í•´ë‹¹ ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    qa_state_1 = analysis_agent.invoke(
        {"messages": [("human", user_choice)]}, 
        config=config
    )
    qa_response_1 = qa_state_1['messages'][-1].content
    print(f"AI (Q&A - ê°•ì /ì•½ì ): {qa_response_1}")
    
    # 4. ì‚¬ìš©ìê°€ 1ë²ˆ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ í›„ì† ì§ˆë¬¸ì„ í•œë‹¤ê³  ê°€ì •
    follow_up_question = "ê·¸ëŸ¼ í•˜ì²´ ê·¼ìœ¡ì„ í‚¤ìš°ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
    print(f"\nUser: {follow_up_question}")
    
    # `route_qa`ê°€ 'qa_general' ë˜ëŠ” 'qa_strength_weakness'ë¡œ ê°€ì„œ, í•´ë‹¹ ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    qa_state_2 = analysis_agent.invoke(
        {"messages": [("human", follow_up_question)]}, 
        config=config
    )
    qa_response_2 = qa_state_2['messages'][-1].content
    print(f"AI (Q&A - ì¼ë°˜): {qa_response_2}")

    # 5. ì‚¬ìš©ìê°€ '2ë²ˆ' ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí–ˆë‹¤ê³  ê°€ì •
    user_choice_2 = "2. ì§€ê¸ˆ ê±´ê°•ì ìœ¼ë¡œ ê´œì°®ì€ ìƒíƒœì¸ê°€ìš”?"
    print(f"\nUser: {user_choice_2}")

    # `route_qa`ê°€ 'qa_health_status'ë¥¼ ì„ íƒí•˜ê³ , í•´ë‹¹ ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    qa_state_3 = analysis_agent.invoke(
        {"messages": [("human", user_choice_2)]},
        config=config
    )
    qa_response_3 = qa_state_3['messages'][-1].content
    print(f"AI (Q&A - ê±´ê°• ìƒíƒœ): {qa_response_3}")
    
    # 6. ì‚¬ìš©ìê°€ '5ë²ˆ'ì„ ì„ íƒí•˜ë©´, ì„œë¹„ìŠ¤ëŠ” ë” ì´ìƒ invokeë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¢…ë£Œ.
    
    # ì„ì‹œ Mock ì‘ë‹µ
    response = f"'{user_question}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ '{category_keywords.get(chosen_category, 'ì¼ë°˜')}' ì£¼ì œì— ë§ì¶° ìƒì„±ë©ë‹ˆë‹¤."

    return {"messages": [("ai", response)]}


# --- 3. ê·¸ë˜í”„ ìƒì„± ---
def create_analysis_agent():
    """
    ê±´ê°• ë¶„ì„ ë° íœ´ë¨¼ í”¼ë“œë°± Q&A ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤.
    
    - `interrupt_after`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° AI ì‘ë‹µ í›„ì— ë©ˆì¶”ê³  ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    - ì‚¬ìš©ìê°€ '5. ê´œì°®ìŠµë‹ˆë‹¤'ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì€ ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ì²˜ë¦¬í•˜ë©°,
      ë” ì´ìƒ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤.
    """
    workflow = StateGraph(AnalysisState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("initial_analysis", generate_initial_analysis)
    workflow.add_node("qa_response", generate_qa_response)
    
    # ì§„ì…ì  ì„¤ì •
    workflow.set_entry_point("initial_analysis")
    
    # ì—£ì§€ ì—°ê²°
    # ìµœì´ˆ ë¶„ì„ í›„ì—ëŠ” Q&A ë…¸ë“œë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
    workflow.add_edge("initial_analysis", "qa_response")
    # Q&A ì‘ë‹µ í›„ì—ëŠ” ë‹¤ì‹œ Q&A ë…¸ë“œë¡œ ëŒì•„ì™€ ì—°ì†ì ì¸ ëŒ€í™”(ë£¨í”„)ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    workflow.add_edge("qa_response", "qa_response")

    # íœ´ë¨¼ í”¼ë“œë°±ì„ ìœ„í•´, LLMì´ ë‹µë³€ì„ ìƒì„±í•œ í›„ì—ëŠ” í•­ìƒ ë©ˆì¶¥ë‹ˆë‹¤.
    # ì„œë¹„ìŠ¤(API)ëŠ” ì´ ë©ˆì¶˜ ì§€ì ì—ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    agent = workflow.compile(interrupt_after=["initial_analysis", "qa_response"])
    
    return agent


### ì‚¬ìš© ì˜ˆì‹œ (FastAPI ë¼ìš°í„°ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë ì§€ì— ëŒ€í•œ ê°œë…) ###
# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ì„œë¹„ìŠ¤ ì½”ë“œì—ëŠ” í¬í•¨ë˜ì§€ ì•Šìœ¼ë©°, ê·¸ë˜í”„ì˜ ë™ì‘ì„ ì„¤ëª…í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
if __name__ == "__main__":
    from datetime import datetime
    
    # 1. ì—ì´ì „íŠ¸ ìƒì„±
    analysis_agent = create_analysis_agent()
    
    # 2. ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ìµœì´ˆ ë¶„ì„ ì‹¤í–‰
    # ì‚¬ìš©ìì˜ health_recordì—ì„œ analysis_inputì„ ì¤€ë¹„í–ˆë‹¤ê³  ê°€ì •
    mock_analysis_input = StatusAnalysisInput(
        record_id=1, user_id=1, measured_at=datetime.now(),
        measurements={"ì„±ë³„": "ë‚¨ì„±", "ë‚˜ì´": 30, "ì‹ ì¥": 175, "ì²´ì¤‘": 75, "BMI": 24.5, "ì²´ì§€ë°©ë¥ ": 20.1, "ê³¨ê²©ê·¼ëŸ‰": 35.2, "ê·¼ìœ¡_ë¶€ìœ„ë³„ë“±ê¸‰": {"ì™¼íŒ”": "í‘œì¤€", "ì˜¤ë¥¸íŒ”": "í‘œì¤€", "ë³µë¶€": "í‘œì¤€", "ì™¼ë‹¤ë¦¬": "í‘œì¤€ì´ìƒ", "ì˜¤ë¥¸ë‹¤ë¦¬": "í‘œì¤€ì´ìƒ"}},
        body_type1="í‘œì¤€í˜•", body_type2="í•˜ì²´ë°œë‹¬í˜•"
    )
    config = {"configurable": {"thread_id": "user_123_thread"}}
    
    # ìµœì´ˆ ë¶„ì„ ì‹¤í–‰ -> `initial_analysis` ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    initial_state = analysis_agent.invoke(
        {"analysis_input": mock_analysis_input}, 
        config=config
    )
    initial_response = initial_state['messages'][-1].content
    print(f"AI (Initial): {initial_response[:200]}...")
    
    # ì„ë² ë”© ìƒì„± í™•ì¸
    if initial_state.get("embedding"):
        print("\n[ì„ë² ë”© ìƒì„± í™•ì¸]")
        if initial_state["embedding"].get("embedding_1536"):
            print("  âœ“ OpenAI (1536d) ì„ë² ë”© ìƒì„±ë¨")
        if initial_state["embedding"].get("embedding_1024"):
            print("  âœ“ Ollama (1024d) ì„ë² ë”© ìƒì„±ë¨")
            
    print("\n[í”„ë¡ íŠ¸ì—”ë“œ: ì‚¬ìš©ìì—ê²Œ 5ê°€ì§€ ì„ íƒì§€ í‘œì‹œ]")
    
    # 3. ì‚¬ìš©ìê°€ '1ë²ˆ' ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí–ˆë‹¤ê³  ê°€ì •
    user_choice = "1. ì–´ë””ê°€ ë¶€ì¡±í•˜ê³ , ì–´ë””ê°€ ê´œì°®ì€ê°€ìš”?"
    print(f"\nUser: {user_choice}")
    
    # `qa_response` ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤
    qa_state_1 = analysis_agent.invoke(
        {"messages": [("human", user_choice)]}, 
        config=config
    )
    qa_response_1 = qa_state_1['messages'][-1].content
    print(f"AI (Q&A): {qa_response_1}")
    
    # 4. ì‚¬ìš©ìê°€ í›„ì† ì§ˆë¬¸ì„ í•œë‹¤ê³  ê°€ì •
    follow_up_question = "ê·¸ëŸ¼ í•˜ì²´ ê·¼ìœ¡ì„ í‚¤ìš°ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
    print(f"\nUser: {follow_up_question}")
    
    # ë‹¤ì‹œ `qa_response` ë…¸ë“œ ì‹¤í–‰ í›„ ë©ˆì¶¤ (ë£¨í”„)
    qa_state_2 = analysis_agent.invoke(
        {"messages": [("human", follow_up_question)]}, 
        config=config
    )
    qa_response_2 = qa_state_2['messages'][-1].content
    print(f"AI (Q&A): {qa_response_2}")
    
    # 5. ì‚¬ìš©ìê°€ '5ë²ˆ'ì„ ì„ íƒí•˜ë©´, ì„œë¹„ìŠ¤ëŠ” ë” ì´ìƒ invokeë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì¢…ë£Œ.
