import asyncio
from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv

load_dotenv()

# --- ìˆ˜ì •ëœ ë¶€ë¶„ 1: ëª¨ë“  ì˜ì¡´ì„±ì„ íŒŒì¼ ìƒë‹¨ìœ¼ë¡œ í†µí•© ---
from schemas.llm import GoalPlanInput
from schemas.inbody import InBodyData as InBodyMeasurements
# ë¡œì»¬ ê²½ë¡œì˜ rule_based_promptsì—ì„œ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ì„ ì§ì ‘ ì„í¬íŠ¸
from .rule_based_prompts import (
    create_summary_prompt,
    create_workout_prompt,
    create_diet_prompt,
    create_lifestyle_prompt,
)


# --- ìƒíƒœ ì •ì˜ ---
class PlanState(TypedDict):
    """LLM2 (ì£¼ê°„ ê³„íš / Q&A) ì—ì´ì „íŠ¸ì˜ ìƒíƒœ"""
    plan_input: GoalPlanInput
    messages: Annotated[list, add_messages]


# --- ìˆ˜ì •ëœ ë¶€ë¶„ 2: initial_plan_node.pyì˜ ë‚´ìš©ì„ íŒŒì¼ ë‚´ ìµœìƒë‹¨ìœ¼ë¡œ ì´ë™ ---
async def generate_initial_plan_concurrently(state: PlanState, llm_client) -> dict:
    """
    Node: ì£¼ê°„ ê³„íš ì´ˆì•ˆ ë³‘ë ¬ ìƒì„±
    4ê°œì˜ LLM Call(ìš”ì•½, ìš´ë™, ì‹ë‹¨, ë¼ì´í”„ìŠ¤íƒ€ì¼)ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì·¨í•©í•©ë‹ˆë‹¤.
    """
    plan_input = state["plan_input"]

    # InBody ë°ì´í„° ëª¨ë¸ ë³€í™˜
    measurements = InBodyMeasurements(**plan_input.measurements)
    # GoalPlanInputì— user_profileì´ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    user_profile = plan_input.user_profile if hasattr(plan_input, 'user_profile') else {}

    # --- 4ê°€ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ---
    prompts = {
        "summary": create_summary_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "workout": create_workout_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "diet": create_diet_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "lifestyle": create_lifestyle_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
    }

    # --- LLM ë¹„ë™ê¸° í˜¸ì¶œ íƒœìŠ¤í¬ ìƒì„± ---
    # llm_clientì— `agenerate_chat` ë¹„ë™ê¸° ë©”ì„œë“œê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    tasks = []
    for key, (system_prompt, user_prompt) in prompts.items():
        task = llm_client.agenerate_chat(system_prompt, user_prompt, key)
        tasks.append(task)

    # --- ëª¨ë“  LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ ---
    results = await asyncio.gather(*tasks)
    
    # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì¬êµ¬ì„±
    plan_results = {res['key']: res['content'] for res in results}
    summary_result = plan_results.get("summary", "ì£¼ê°„ ëª©í‘œ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    workout_result = plan_results.get("workout", "ìš´ë™ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    diet_result = plan_results.get("diet", "ì‹ë‹¨ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    lifestyle_result = plan_results.get("lifestyle", "ìƒí™œ ìŠµê´€ ë° ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # --- ìµœì¢… ê²°ê³¼ í¬ë§·íŒ… ---
    combined_response = f"""### ğŸ“ ì£¼ê°„ ëª©í‘œ í•µì‹¬ ì „ëµ
{summary_result}

### ğŸ‹ï¸â€â™€ï¸ ìš”ì¼ë³„ ìš´ë™ ê³„íš
{workout_result}

### ğŸ½ï¸ ì¼ì¼ ì‹ë‹¨ ê³„íš
{diet_result}

### ğŸ’¡ ìƒí™œ ìŠµê´€ ë° ë™ê¸°ë¶€ì—¬
{lifestyle_result}

---
ìœ„ ê³„íšì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆê±°ë‚˜ ìˆ˜ì •ì„ ì›í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”!
"""

    # ì´ˆê¸° ì‚¬ìš©ì ì§ˆë¬¸ì„ "human" ë©”ì‹œì§€ë¡œ ì¶”ê°€
    initial_user_message = state["messages"][-1].content if state["messages"] and state["messages"][-1].type == "human" else "ì£¼ê°„ ê³„íšì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."

    return {"messages": [("human", initial_user_message), ("ai", combined_response)]}


# --- ê·¸ë˜í”„ ìƒì„± ---
def create_weekly_plan_agent(llm_client):
    """ì£¼ê°„ ê³„íš ìƒì„± ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    
    # --- ë…¸ë“œ ì •ì˜ ---
    def _generate_qa_response(state: PlanState, category_name: str, system_prompt: str) -> dict:
        """ê³µí†µ Q&A ë‹µë³€ ìƒì„± ë¡œì§"""
        print(f"--- LLM2: ì£¼ê°„ ê³„íš Q&A ({category_name}) ---")
        history = []
        for msg in state["messages"]:
            role = "user" if msg.type == "human" else "assistant"
            history.append((role, msg.content))

        response = llm_client.generate_chat_with_history(
            system_prompt=system_prompt,
            messages=history
        )
        return {"messages": [("ai", response)]}

    def qa_exercise_guide(state: PlanState) -> dict:
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ íŠ¹ì • ìš´ë™ ë™ì‘ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤. 
        í•´ë‹¹ ìš´ë™ì˜ ì˜¬ë°”ë¥¸ ìì„¸, ìê·¹ ë¶€ìœ„, í˜¸í¡ë²•, ê·¸ë¦¬ê³  ì£¼ì˜ì‚¬í•­ì„ ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        return _generate_qa_response(state, "ìš´ë™ ê°€ì´ë“œ", system_prompt)

    def qa_plan_adjustment(state: PlanState) -> dict:
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ ìš´ë™ í”Œëœ(ì¼ì •, ì¢…ëª©, ë¶„í•  ë°©ì‹ ë“±)ì˜ ì¡°ì •ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ ìš”ì²­ ì‚¬í•­ì„ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •ëœ êµ¬ì²´ì ì¸ ìš´ë™ ê³„íšì„ ì œì‹œí•´ì£¼ì„¸ìš”. 
        ìˆ˜ì •ëœ ì´ìœ ë„ í•¨ê»˜ ì„¤ëª…í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."""
        return _generate_qa_response(state, "í”Œëœ ì¡°ì •", system_prompt)

    def qa_diet_adjustment(state: PlanState) -> dict:
        system_prompt = """ë‹¹ì‹ ì€ ì˜ì–‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ ì‹ë‹¨ ê³„íšì˜ ì¡°ì •ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
        ì‚¬ìš©ìì˜ ê¸°í˜¸, ì•Œë ˆë¥´ê¸°, ë˜ëŠ” ìƒí™©(ì™¸ì‹, í¸ì˜ì  ë“±)ì„ ê³ ë ¤í•˜ì—¬ ëŒ€ì²´ ì‹ë‹¨ì´ë‚˜ ìˆ˜ì •ëœ ë©”ë‰´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”. 
        ì¹¼ë¡œë¦¬ì™€ ì˜ì–‘ ë°¸ëŸ°ìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ì¡°ì–¸í•´ì£¼ì„¸ìš”."""
        return _generate_qa_response(state, "ì‹ë‹¨ ì¡°ì •", system_prompt)

    def qa_intensity_adjustment(state: PlanState) -> dict:
        system_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ ìš´ë™ ê°•ë„(ë¬´ê²Œ, íšŸìˆ˜, ì„¸íŠ¸, íœ´ì‹ ì‹œê°„ ë“±)ì˜ ì¡°ì •ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
        ì‚¬ìš©ìê°€ ëŠë¼ëŠ” ë‚œì´ë„ì— ë§ì¶° ê°•ë„ë¥¼ ë†’ì´ê±°ë‚˜ ë‚®ì¶”ëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. 
        ë¶€ìƒ ë°©ì§€ë¥¼ ìœ„í•œ ì¡°ì–¸ë„ í¬í•¨í•´ì£¼ì„¸ìš”."""
        return _generate_qa_response(state, "ê°•ë„ ì¡°ì •", system_prompt)

    def qa_general(state: PlanState) -> dict:
        system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì£¼ê°„ ìš´ë™ ë° ì‹ë‹¨ ê³„íšì„ ë‹´ë‹¹í•˜ëŠ” í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ìƒì„±ëœ ê³„íšì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©´, ì „ë¬¸ì ì´ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì´ì „ ëŒ€í™” ë§¥ë½(ì‚¬ìš©ìì˜ ì‹ ì²´ ì •ë³´, ëª©í‘œ, ìƒì„±ëœ ê³„íš)ì„ ëª¨ë‘ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤."""
        return _generate_qa_response(state, "ì¼ë°˜", system_prompt)

    def finalize_plan(state: PlanState) -> dict:
        print("--- LLM2: ê³„íš í™•ì • ---")
        return {"messages": [("ai", "ë„¤, í˜„ì¬ ê³„íšìœ¼ë¡œ í™•ì •í•˜ì—¬ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. ì¼ì£¼ì¼ ë™ì•ˆ í™”ì´íŒ…í•˜ì„¸ìš”!")]}

    def route_qa(state: PlanState) -> str:
        user_question = state["messages"][-1].content.strip()
        if user_question.startswith("1"): return "qa_exercise_guide"
        elif user_question.startswith("2"): return "qa_plan_adjustment"
        elif user_question.startswith("3"): return "qa_diet_adjustment"
        elif user_question.startswith("4"): return "qa_intensity_adjustment"
        elif user_question.startswith("5"): return "finalize_plan"
        else: return "qa_general"

    workflow = StateGraph(PlanState)

    # --- ìˆ˜ì •ëœ ë¶€ë¶„ 3: lambdaë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‚´ì˜ ë¹„ë™ê¸° ë…¸ë“œ ì¶”ê°€ ---
    workflow.add_node(
        "initial_plan",
        lambda state: generate_initial_plan_concurrently(state, llm_client)
    )
     # Q&A ë…¸ë“œ ì¶”ê°€
    workflow.add_node("qa_exercise_guide", qa_exercise_guide)
    workflow.add_node("qa_plan_adjustment", qa_plan_adjustment)
    workflow.add_node("qa_diet_adjustment", qa_diet_adjustment)
    workflow.add_node("qa_intensity_adjustment", qa_intensity_adjustment)
    workflow.add_node("qa_general", qa_general)
    workflow.add_node("finalize_plan", finalize_plan)

    workflow.set_entry_point("initial_plan")

    # ë¼ìš°íŒ… ë§µ ì •ì˜
    qa_routing_map = {
        "qa_exercise_guide": "qa_exercise_guide",
        "qa_plan_adjustment": "qa_plan_adjustment",
        "qa_diet_adjustment": "qa_diet_adjustment",
        "qa_intensity_adjustment": "qa_intensity_adjustment",
        "qa_general": "qa_general",
        "finalize_plan": "finalize_plan",
        END: END
    }

    # 1. ì´ˆê¸° ê³„íš ìƒì„± í›„ ë¼ìš°íŒ…
    workflow.add_conditional_edges("initial_plan", route_qa, qa_routing_map)

    # 2. ê° Q&A ë…¸ë“œ ì‹¤í–‰ í›„ ë‹¤ì‹œ ë¼ìš°íŒ… (ëŒ€í™” ë£¨í”„)
    for node_name in ["qa_exercise_guide", "qa_plan_adjustment", "qa_diet_adjustment", "qa_intensity_adjustment", "qa_general"]:
        workflow.add_conditional_edges(node_name, route_qa, qa_routing_map)

    # í™•ì • í›„ ì¢…ë£Œ
    workflow.add_edge("finalize_plan", END)

    memory = MemorySaver()
    
    # ê° ë‹¨ê³„ í›„ ì¤‘ë‹¨í•˜ì—¬ ì‚¬ìš©ì í”¼ë“œë°± ëŒ€ê¸°
    return workflow.compile(
        checkpointer=memory, 
        interrupt_after=[
            "initial_plan", 
            "qa_exercise_guide", 
            "qa_plan_adjustment", 
            "qa_diet_adjustment", 
            "qa_intensity_adjustment", 
            "qa_general"
        ]
    )