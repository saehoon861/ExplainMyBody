"""
Graph RAG ë°ì´í„° Import Script
- graph_rag_*.json íŒŒì¼ì„ PostgreSQL (pgvector) ë° Neo4jì— ë¡œë“œ
- PaperNode í…Œì´ë¸”ì— ë…¼ë¬¸ ë°ì´í„° ì‚½ì…
- PaperConceptRelation í…Œì´ë¸”ì— ê´€ê³„ ë°ì´í„° ì‚½ì…
- ì„ íƒì ìœ¼ë¡œ Neo4jì— ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±

Usage:
    python backend/utils/scripts/import_graph_rag.py [--json-path PATH] [--neo4j] [--clear]

Options:
    --json-path: graph_rag JSON íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ìµœì‹  íŒŒì¼ ìë™ íƒìƒ‰)
    --neo4j: Neo4jì—ë„ ë°ì´í„° ë¡œë“œ (ê¸°ë³¸: False)
    --clear: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ë¡œë“œ (ê¸°ë³¸: False)
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (backend/ ë””ë ‰í† ë¦¬)
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from sqlalchemy import text
from sqlalchemy.exc import IntegrityError
from database import engine, SessionLocal
from models.paper_node import PaperNode
from models.paper_concept_relation import PaperConceptRelation
from repositories.neo4j_repository import Neo4jRepository


def find_latest_graph_rag_json(base_path: str = "src/llm/ragdb_collect/outputs") -> Optional[str]:
    """ìµœì‹  graph_rag JSON íŒŒì¼ ì°¾ê¸°"""
    # backend/utils/scripts/ â†’ backend/utils/ â†’ backend/ â†’ project_root
    project_root = Path(__file__).parent.parent.parent.parent
    outputs_dir = project_root / base_path

    if not outputs_dir.exists():
        print(f"âŒ ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {outputs_dir}")
        return None

    # graph_rag_*papers_*.json íŒ¨í„´ íŒŒì¼ ì°¾ê¸° (stats íŒŒì¼ ì œì™¸)
    json_files = list(outputs_dir.glob("graph_rag_*papers_*.json"))

    # stats íŒŒì¼ ì œì™¸
    json_files = [f for f in json_files if 'stats' not in f.name]

    if not json_files:
        print(f"âŒ graph_rag JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {outputs_dir}")
        return None

    # ìµœì‹  íŒŒì¼ ì„ íƒ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
    print(f"âœ… ìµœì‹  JSON íŒŒì¼ ë°œê²¬: {latest_file}")
    return str(latest_file)


def load_graph_rag_json(file_path: str) -> Dict[str, Any]:
    """graph_rag JSON íŒŒì¼ ë¡œë“œ"""
    print(f"\nğŸ“‚ JSON íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    num_nodes = len(data.get('nodes', []))
    num_edges = len(data.get('edges', []))

    print(f"  âœ“ Nodes: {num_nodes:,}ê°œ")
    print(f"  âœ“ Edges: {num_edges:,}ê°œ")

    return data


def enable_pgvector_extension():
    """pgvector extension í™œì„±í™”"""
    print("\nğŸ”§ pgvector extension í™•ì¸ ì¤‘...")

    try:
        with engine.connect() as conn:
            conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            conn.commit()
            print("  âœ“ pgvector extension í™œì„±í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸  pgvector extension í™œì„±í™” ì‹¤íŒ¨: {e}")
        print("     ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: sudo apt-get install postgresql-<version>-pgvector")


def create_tables():
    """í…Œì´ë¸” ìƒì„±"""
    print("\nğŸ”§ í…Œì´ë¸” ìƒì„± ì¤‘...")

    from database import Base

    try:
        Base.metadata.create_all(bind=engine, tables=[
            PaperNode.__table__,
            PaperConceptRelation.__table__
        ])
        print("  âœ“ í…Œì´ë¸” ìƒì„± ì™„ë£Œ (paper_nodes, paper_concept_relations)")
    except Exception as e:
        print(f"  âš ï¸  í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")


def clear_existing_data(session):
    """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ"""
    print("\nğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")

    try:
        # CASCADE ì‚­ì œë¡œ ê´€ê³„ ë°ì´í„°ë„ ìë™ ì‚­ì œë¨
        deleted_relations = session.query(PaperConceptRelation).delete()
        deleted_papers = session.query(PaperNode).delete()
        session.commit()

        print(f"  âœ“ ì‚­ì œ ì™„ë£Œ: {deleted_papers:,}ê°œ ë…¼ë¬¸, {deleted_relations:,}ê°œ ê´€ê³„")
    except Exception as e:
        session.rollback()
        print(f"  âŒ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise


def import_papers_to_postgres(nodes: List[Dict[str, Any]], session) -> Dict[str, int]:
    """ë…¼ë¬¸ ë°ì´í„°ë¥¼ PostgreSQLì— bulk insert"""
    # Paper ë…¸ë“œë§Œ í•„í„°ë§ (Concept ë…¸ë“œ ì œì™¸)
    paper_nodes = [n for n in nodes if n.get('node_type') == 'paper']
    concept_nodes = [n for n in nodes if n.get('node_type') != 'paper']

    print(f"\nğŸ“¥ PostgreSQLì— {len(paper_nodes):,}ê°œ ë…¼ë¬¸ ì‚½ì… ì¤‘... (ì´ {len(nodes):,}ê°œ ë…¸ë“œ ì¤‘ {len(concept_nodes):,}ê°œ ê°œë… ë…¸ë“œ ì œì™¸)")

    paper_id_map = {}  # paper_id -> db_id ë§¤í•‘
    batch_size = 500
    total_inserted = 0
    total_skipped = 0

    for i in range(0, len(paper_nodes), batch_size):
        batch = paper_nodes[i:i + batch_size]
        paper_objects = []

        for node in batch:
            try:
                # embedding_koë¥¼ embedding_ko_openaië¡œ ë§¤í•‘
                embedding_ko_openai = node.get('embedding_ko')

                # PaperNode ê°ì²´ ìƒì„±
                paper = PaperNode(
                    paper_id=node['id'],
                    title=node['title'],
                    chunk_text=node['chunk_text'],
                    lang=node['lang'],
                    chunk_ko_summary=node.get('chunk_ko_summary'),
                    domain=node.get('domain'),
                    source=node.get('source', 'unknown'),
                    year=node.get('year'),
                    pmid=node.get('pmid'),
                    doi=node.get('doi'),
                    authors=None,  # JSON íŒŒì¼ì— ì—†ìŒ
                    journal=None,  # JSON íŒŒì¼ì— ì—†ìŒ
                    keywords=None,  # JSON íŒŒì¼ì— ì—†ìŒ
                    embedding_ko_openai=embedding_ko_openai,
                    embedding_openai=None,  # ë‚˜ì¤‘ì— ìƒì„±
                    embedding_ollama=None,  # ë‚˜ì¤‘ì— ìƒì„±
                    embedding_provider=node.get('embedding_provider', 'openai'),
                )

                paper_objects.append(paper)

            except Exception as e:
                print(f"    âš ï¸  Paper {node.get('id')} íŒŒì‹± ì‹¤íŒ¨: {e}")
                total_skipped += 1
                continue

        # Bulk insert
        if paper_objects:
            try:
                session.bulk_save_objects(paper_objects, return_defaults=True)
                session.commit()

                # ID ë§¤í•‘ ìƒì„± (ë‚˜ì¤‘ì— ê´€ê³„ ì‚½ì… ì‹œ ì‚¬ìš©)
                for paper in paper_objects:
                    # re-query to get DB ID
                    db_paper = session.query(PaperNode).filter(
                        PaperNode.paper_id == paper.paper_id
                    ).first()
                    if db_paper:
                        paper_id_map[paper.paper_id] = db_paper.id

                total_inserted += len(paper_objects)
                # 5 ë°°ì¹˜ë§ˆë‹¤ ë˜ëŠ” ì™„ë£Œ ì‹œ ì§„í–‰ë¥  ì¶œë ¥ (ì¶œë ¥ ìµœì†Œí™”)
                batch_num = i // batch_size
                if batch_num % 5 == 0 or total_inserted >= len(paper_nodes):
                    print(f"  âœ“ ì§„í–‰: {total_inserted:,}/{len(paper_nodes):,} ({100*total_inserted/len(paper_nodes):.1f}%)")

            except IntegrityError as e:
                session.rollback()
                print(f"    âš ï¸  ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨ (ì¤‘ë³µ ê°€ëŠ¥ì„±): {e}")
                total_skipped += len(paper_objects)
            except Exception as e:
                session.rollback()
                print(f"    âŒ ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
                total_skipped += len(paper_objects)

    print(f"\n  âœ… ë…¼ë¬¸ ì‚½ì… ì™„ë£Œ: {total_inserted:,}ê°œ ì„±ê³µ, {total_skipped:,}ê°œ ìŠ¤í‚µ")
    return paper_id_map


def import_relations_to_postgres(
    edges: List[Dict[str, Any]],
    paper_id_map: Dict[str, int],
    session
):
    """ê´€ê³„ ë°ì´í„°ë¥¼ PostgreSQLì— bulk insert"""
    print(f"\nğŸ“¥ PostgreSQLì— {len(edges):,}ê°œ ê´€ê³„ ì‚½ì… ì¤‘...")

    batch_size = 1000
    total_inserted = 0
    total_skipped = 0
    missing_papers = set()  # ëˆ„ë½ëœ paper_id ì¶”ì 

    for i in range(0, len(edges), batch_size):
        batch = edges[i:i + batch_size]
        relation_objects = []

        for edge in batch:
            source_paper_id = edge['source']
            target_concept_id = edge['target']

            # paper_idë¥¼ DB IDë¡œ ë³€í™˜
            db_paper_id = paper_id_map.get(source_paper_id)

            if not db_paper_id:
                total_skipped += 1
                missing_papers.add(source_paper_id)
                continue

            try:
                relation = PaperConceptRelation(
                    paper_id=db_paper_id,
                    concept_id=target_concept_id,
                    relation_type=edge.get('type', 'MENTIONS'),
                    confidence=edge.get('confidence') or 0.5,
                    matched_term=edge.get('matched_term'),
                    count=edge.get('count', 1),
                    evidence_level=None,  # ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
                    magnitude=None,  # ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
                    concept_name_ko=None,  # ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
                    concept_name_en=None,  # ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
                    concept_type=None,  # ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥
                )

                relation_objects.append(relation)

            except Exception as e:
                print(f"    âš ï¸  Relation {edge} íŒŒì‹± ì‹¤íŒ¨: {e}")
                total_skipped += 1
                continue

        # Bulk insert
        if relation_objects:
            try:
                session.bulk_save_objects(relation_objects)
                session.commit()

                total_inserted += len(relation_objects)
                # 10 ë°°ì¹˜ë§ˆë‹¤ ë˜ëŠ” ì™„ë£Œ ì‹œ ì§„í–‰ë¥  ì¶œë ¥ (ì¶œë ¥ ìµœì†Œí™”)
                batch_num = i // batch_size
                if batch_num % 10 == 0 or total_inserted >= len(edges):
                    print(f"  âœ“ ì§„í–‰: {total_inserted:,}/{len(edges):,} ({100*total_inserted/len(edges):.1f}%)")

            except Exception as e:
                session.rollback()
                print(f"    âŒ ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
                total_skipped += len(relation_objects)

    print(f"\n  âœ… ê´€ê³„ ì‚½ì… ì™„ë£Œ: {total_inserted:,}ê°œ ì„±ê³µ, {total_skipped:,}ê°œ ìŠ¤í‚µ")

    if missing_papers:
        print(f"  â„¹ï¸  ìŠ¤í‚µ ì´ìœ : {len(missing_papers):,}ê°œ ë…¼ë¬¸ì´ DBì— ì—†ìŒ (ë…¼ë¬¸ ì‚½ì… ì‹¤íŒ¨ ë˜ëŠ” JSONì— ëˆ„ë½)")
        if len(missing_papers) <= 10:
            print(f"     ëˆ„ë½ëœ paper_id: {', '.join(list(missing_papers)[:10])}")
        else:
            print(f"     ëˆ„ë½ëœ paper_id ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {', '.join(list(missing_papers)[:10])}")


def import_to_neo4j(data: Dict[str, Any]):
    """Neo4jì— ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ (ì„ íƒì )"""
    print("\nğŸ”· Neo4jì— ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ ì¤‘...")

    try:
        neo4j_repo = Neo4jRepository()

        if not neo4j_repo.driver:
            print("  âš ï¸  Neo4j ì—°ê²° ì‹¤íŒ¨. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return

        nodes = data.get('nodes', [])
        edges = data.get('edges', [])

        # Paperì™€ Concept ë…¸ë“œ ë¶„ë¦¬
        paper_nodes = [n for n in nodes if n.get('node_type') == 'paper']
        concept_nodes = [n for n in nodes if n.get('node_type') != 'paper']

        print(f"  - {len(paper_nodes):,}ê°œ Paper ë…¸ë“œ ìƒì„± ì¤‘...")

        # Paper ë…¸ë“œ ìƒì„±
        batch_size = 500
        with neo4j_repo.driver.session() as session:
            for i in range(0, len(paper_nodes), batch_size):
                batch = paper_nodes[i:i + batch_size]

                for node in batch:
                    session.run("""
                        MERGE (p:Paper {id: $id})
                        SET p.title = $title,
                            p.lang = $lang,
                            p.domain = $domain,
                            p.source = $source,
                            p.year = $year,
                            p.pmid = $pmid,
                            p.doi = $doi
                    """,
                        id=node['id'],
                        title=node['title'],
                        lang=node['lang'],
                        domain=node.get('domain'),
                        source=node.get('source'),
                        year=node.get('year'),
                        pmid=node.get('pmid'),
                        doi=node.get('doi')
                    )

                if (i // batch_size) % 3 == 0 or i + batch_size >= len(paper_nodes):
                    print(f"    âœ“ Paper ë…¸ë“œ: {min(i+batch_size, len(paper_nodes)):,}/{len(paper_nodes):,}")

        # Concept ë…¸ë“œ ìƒì„±
        print(f"  - {len(concept_nodes):,}ê°œ Concept ë…¸ë“œ ìƒì„± ì¤‘...")
        with neo4j_repo.driver.session() as session:
            for node in concept_nodes:
                session.run("""
                    MERGE (c:Concept {id: $id})
                    SET c.name = $id
                """,
                    id=node['id']
                )

            print(f"    âœ“ Concept ë…¸ë“œ: {len(concept_nodes):,}ê°œ ìƒì„± ì™„ë£Œ")

        print(f"  - {len(edges):,}ê°œ ê´€ê³„ ìƒì„± ì¤‘...")

        # ê´€ê³„ ìƒì„± (ë°°ì¹˜)
        with neo4j_repo.driver.session() as session:
            for i in range(0, len(edges), batch_size):
                batch = edges[i:i + batch_size]

                for edge in batch:
                    # ê´€ê³„ ìƒì„± (ë™ì  íƒ€ì…)
                    relation_type = edge.get('type', 'MENTIONS')
                    source_id = edge['source']
                    target_id = edge['target']

                    # sourceê°€ Paperì¸ì§€ Conceptì¸ì§€ êµ¬ë¶„ (paper_ ì ‘ë‘ì‚¬ë¡œ íŒë‹¨)
                    if source_id.startswith('paper_'):
                        # Paper â†’ Concept ê´€ê³„
                        session.run(f"""
                            MATCH (p:Paper {{id: $source_id}})
                            MATCH (c:Concept {{id: $target_id}})
                            MERGE (p)-[r:{relation_type}]->(c)
                            SET r.confidence = $confidence,
                                r.matched_term = $matched_term,
                                r.count = $count
                        """,
                            source_id=source_id,
                            target_id=target_id,
                            confidence=edge.get('confidence') or 0.5,
                            matched_term=edge.get('matched_term'),
                            count=edge.get('count', 1)
                        )
                    else:
                        # Concept â†’ Concept ê´€ê³„
                        session.run(f"""
                            MATCH (c1:Concept {{id: $source_id}})
                            MATCH (c2:Concept {{id: $target_id}})
                            MERGE (c1)-[r:{relation_type}]->(c2)
                            SET r.confidence = $confidence,
                                r.matched_term = $matched_term,
                                r.count = $count
                        """,
                            source_id=source_id,
                            target_id=target_id,
                            confidence=edge.get('confidence') or 0.5,
                            matched_term=edge.get('matched_term'),
                            count=edge.get('count', 1)
                        )

                # 10 ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ë¥  ì¶œë ¥
                if (i // batch_size) % 10 == 0 or i + batch_size >= len(edges):
                    print(f"    âœ“ ê´€ê³„: {min(i+batch_size, len(edges)):,}/{len(edges):,}")

        print("  âœ… Neo4j ë¡œë“œ ì™„ë£Œ")
        neo4j_repo.close()

    except Exception as e:
        print(f"  âŒ Neo4j ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(description="Graph RAG ë°ì´í„°ë¥¼ PostgreSQL ë° Neo4jì— ë¡œë“œ")
    parser.add_argument(
        "--json-path",
        type=str,
        help="graph_rag JSON íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ìµœì‹  íŒŒì¼ ìë™ íƒìƒ‰)"
    )
    parser.add_argument(
        "--neo4j",
        action="store_true",
        help="Neo4jì—ë„ ë°ì´í„° ë¡œë“œ"
    )
    parser.add_argument(
        "--clear",
        action="store_true",
        help="ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ë¡œë“œ"
    )

    args = parser.parse_args()

    print("\n" + "="*60)
    print("  Graph RAG Data Import Script")
    print("="*60)

    # 1. JSON íŒŒì¼ ì°¾ê¸°
    json_path = args.json_path or find_latest_graph_rag_json()

    if not json_path:
        print("\nâŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   --json-path ì˜µì…˜ìœ¼ë¡œ ì§ì ‘ ì§€ì •í•˜ì„¸ìš”.")
        return

    # 2. JSON ë¡œë“œ
    data = load_graph_rag_json(json_path)

    # 3. pgvector extension í™œì„±í™”
    enable_pgvector_extension()

    # 4. í…Œì´ë¸” ìƒì„±
    create_tables()

    # 5. PostgreSQL ë°ì´í„° ì‚½ì…
    session = SessionLocal()

    try:
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì„ íƒì )
        if args.clear:
            clear_existing_data(session)

        # ë…¼ë¬¸ ì‚½ì…
        paper_id_map = import_papers_to_postgres(data['nodes'], session)

        # ê´€ê³„ ì‚½ì…
        import_relations_to_postgres(data['edges'], paper_id_map, session)

    except Exception as e:
        print(f"\nâŒ PostgreSQL ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        session.close()

    # 6. Neo4j ë¡œë“œ (ì„ íƒì )
    if args.neo4j:
        import_to_neo4j(data)

    print("\n" + "="*60)
    print("  âœ… Graph RAG ë°ì´í„° Import ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“Š ìš”ì•½:")
    print(f"  - ì´ ë…¼ë¬¸: {len(data['nodes']):,}ê°œ")
    print(f"  - ì´ ê´€ê³„: {len(data['edges']):,}ê°œ")
    print(f"  - PostgreSQL: paper_nodes, paper_concept_relations í…Œì´ë¸”")
    if args.neo4j:
        print(f"  - Neo4j: Paper, Concept ë…¸ë“œ ë° ê´€ê³„ ê·¸ë˜í”„")
    print()


if __name__ == "__main__":
    main()
