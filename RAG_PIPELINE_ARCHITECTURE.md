# ExplainMyBody RAG íŒŒì´í”„ë¼ì¸ ì „ì²´ êµ¬ì¡°

**ì‘ì„±ì¼:** 2026-02-02
**ë…¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘ â†’ ê°€ê³µ â†’ ì„ë² ë”© â†’ Neo4j/PostgreSQL ì €ì¥ â†’ ì‹¤ì œ ì‚¬ìš©ê¹Œì§€ ì „ ê³¼ì •**

---

## ğŸ“Š ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

```
[1] ë…¼ë¬¸ ìˆ˜ì§‘
    â”œâ”€ PubMed API (ì˜ì–´ ë…¼ë¬¸)
    â”œâ”€ KCI API (í•œêµ­ì–´ ë…¼ë¬¸)
    â””â”€ Google Scholar (í•œêµ­ì–´ ë³´ì¶©)
        â†“
    ğŸ“ outputs/papers/*.json (ê°œë³„ ìˆ˜ì§‘ íŒŒì¼)
        â†“
[2] ì¤‘ë³µ ì œê±° ë° ë³‘í•©
    â†’ merge_korean_corpus.py
        â†“
    ğŸ“ ragdb_final_corpus_20260129_195141.json (2,577ê°œ ë…¼ë¬¸)
        â†“
[3] Graph RAG êµ¬ì¶•
    â†’ build_graph_rag.py
    â”œâ”€ ê°œë… ì¶”ì¶œ (ìŠ¤í‚¤ë§ˆ ê¸°ë°˜)
    â”œâ”€ ê´€ê³„ íƒì§€ (MENTIONS, INCREASES, SUPPORTS)
    â”œâ”€ í•œêµ­ì–´ ì„ë² ë”© ìƒì„± (OpenAI text-embedding-3-small)
    â””â”€ Neo4j Cypher ìƒì„±
        â†“
    ğŸ“ graph_rag_2577papers_20260130_211829.json (120MB, ë…¼ë¬¸+ê´€ê³„+ì„ë² ë”©)
    ğŸ“ graph_rag_neo4j_2577papers_20260130_211829.cypher (1.3MB, Neo4j importìš©)
        â†“
[4] PostgreSQL + Neo4j Import
    â†’ import_graph_rag.py
    â”œâ”€ PostgreSQL (paper_nodes í…Œì´ë¸”)
    â”‚   â”œâ”€ ë©”íƒ€ë°ì´í„° ì €ì¥
    â”‚   â”œâ”€ embedding_ko_openai (pgvector, 1536D)
    â”‚   â””â”€ Vector ê²€ìƒ‰ ì¤€ë¹„
    â””â”€ Neo4j (Graph Database)
        â”œâ”€ Paper ë…¸ë“œ ìƒì„±
        â”œâ”€ Concept ë…¸ë“œ ìƒì„±
        â””â”€ ê´€ê³„ ìƒì„± (MENTIONS, INCREASES, SUPPORTS)
            â†“
[5] ëŸ°íƒ€ì„ ê²€ìƒ‰
    â†’ graph_rag_retriever.py
    â”œâ”€ InBody ë°ì´í„° â†’ ê°œë… ì¶”ì¶œ
    â”œâ”€ Vector Search (PostgreSQL pgvector)
    â”œâ”€ Graph Traversal (Neo4j, optional)
    â””â”€ Hybrid Reranking (0.7*vector + 0.3*graph)
        â†“
[6] Prompt ìƒì„± + LLM ë¶„ì„
    â†’ prompt_generator.py
    â”œâ”€ InBody ì¸¡ì • ë°ì´í„° í¬ë§·íŒ…
    â”œâ”€ ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (10ê°œ)
    â””â”€ gpt-4o-mini ë¶„ì„ ìƒì„±
        â†“
[7] ê²°ê³¼ ì¶œë ¥
    ğŸ“„ InBody ë¶„ì„ ë¦¬í¬íŠ¸ (ë…¼ë¬¸ ê·¼ê±° í¬í•¨)
```

---

## 1ï¸âƒ£ ë…¼ë¬¸ ìˆ˜ì§‘ (Paper Collection)

### ğŸ“ ìœ„ì¹˜
```
src/llm/ragdb_collect/
â”œâ”€â”€ config.py                      # ê²€ìƒ‰ ì¿¼ë¦¬ ì •ì˜
â”œâ”€â”€ pubmed_collector.py            # PubMed API ìˆ˜ì§‘
â”œâ”€â”€ kci_api_collector.py           # KCI API ìˆ˜ì§‘
â”œâ”€â”€ riss_api_collector.py          # RISS API ìˆ˜ì§‘
â”œâ”€â”€ google_scholar_korean_collector.py
â””â”€â”€ main.py                        # í†µí•© ì‹¤í–‰
```

### ğŸ¯ ìˆ˜ì§‘ ì „ëµ

**4ê°œ ì¶• ë™ë“± ë¶„ë°° (ì´ 3,000ê°œ ëª©í‘œ)**

| ì¶• | ë„ë©”ì¸ | ëª©í‘œ | ì†ŒìŠ¤ | ì–¸ì–´ |
|---|--------|------|------|------|
| 1 | ë‹¨ë°±ì§ˆ/ê·¼ìœ¡ ì¦ê°€ | 800ê°œ | PubMed | ì˜ì–´ |
| 2 | ì²´ì§€ë°© ê°ëŸ‰ | 800ê°œ | PubMed | ì˜ì–´ |
| 3 | í•œêµ­í˜• ì‹ë‹¨ | 600ê°œ | KCI/RISS | í•œêµ­ì–´ |
| 4 | ì²´í˜• ë¶„ì„/ì¸ë°”ë”” | 800ê°œ | PubMed+KCI | ì˜ì–´+í•œêµ­ì–´ |

### ğŸ” ì‹¤ì œ ìˆ˜ì§‘ ì¿¼ë¦¬ ì˜ˆì‹œ

```python
# config.py
PROTEIN_HYPERTROPHY_QUERIES = [
    "(resistance training) AND (protein intake) AND hypertrophy",
    "muscle protein synthesis AND leucine",
    "whey supplementation AND strength gain",
    # ... ì´ 10ê°œ ì¿¼ë¦¬
]

FAT_LOSS_QUERIES = [
    "calorie deficit AND fat loss AND body composition",
    "high protein diet AND weight loss AND lean mass",
    # ... ì´ 10ê°œ ì¿¼ë¦¬
]

BODY_COMPOSITION_QUERIES_KO = [
    "ê·¼ê°ì†Œì¦ í•œêµ­ì¸",
    "ì²´ì„±ë¶„ ë¶„ì„ ì¸ë°”ë””",
    "ê³¨ê²©ê·¼ëŸ‰ ì¸¡ì • ë°©ë²•",
    # ... ì´ 6ê°œ ì¿¼ë¦¬
]
```

### ğŸ“„ ìˆ˜ì§‘ëœ íŒŒì¼ êµ¬ì¡°

```bash
outputs/papers/
â”œâ”€â”€ protein_hypertrophy_20260128_204302.json    # 936KB
â”œâ”€â”€ fat_loss_20260128_204302.json               # 1.7MB
â”œâ”€â”€ korean_diet_20260128_204302.json            # 631KB
â”œâ”€â”€ body_composition_20260128_204302.json       # 1.0MB
â”œâ”€â”€ google_scholar_korean_20260129_120122.json  # 287KB
â””â”€â”€ ... (ë„ë©”ì¸ë³„ ë¶„ë¦¬ íŒŒì¼)
```

### ğŸ“Š JSON ë°ì´í„° êµ¬ì¡°

```json
{
  "domain": "protein_hypertrophy",
  "language": "en",
  "title": "Resistance training-induced appendicular lean tissue...",
  "abstract": "We sought to determine if pre-intervention bone...",
  "keywords": ["hypertrophy", "lean tissue mass", "resistance training"],
  "source": "PubMed",
  "year": 2025,
  "pmid": "41415307",
  "doi": "10.1519/JSC.0000000000001049",
  "authors": ["Dakota R Tiede", "Daniel L Plotkin", ...],
  "journal": "Frontiers in physiology"
}
```

**ì£¼ìš” í•„ë“œ:**
- `abstract`: ì´ˆë¡ ì „ë¬¸ (í‰ê·  1,000-2,000ì) â† RAGì˜ í•µì‹¬ ë°ì´í„°
- `domain`: 4ê°œ ì¶• ë¶„ë¥˜ (`protein_hypertrophy`, `fat_loss`, `korean_diet`, `body_composition`)
- `language`: `en` (ì˜ì–´) ë˜ëŠ” `ko` (í•œêµ­ì–´)
- `pmid`: PubMed ID (ì˜ì–´ ë…¼ë¬¸ë§Œ)

---

## 2ï¸âƒ£ ì¤‘ë³µ ì œê±° ë° ë³‘í•© (Deduplication & Merge)

### ğŸ“ ìŠ¤í¬ë¦½íŠ¸
```
src/llm/ragdb_collect/merge_korean_corpus.py
```

### ğŸ¯ ì‘ì—… ë‚´ìš©

1. **ê°œë³„ ìˆ˜ì§‘ íŒŒì¼ ë¡œë“œ**
   ```python
   # ëª¨ë“  JSON íŒŒì¼ ì½ê¸°
   papers = []
   for file in glob("outputs/papers/*.json"):
       with open(file) as f:
           papers.extend(json.load(f))
   ```

2. **ì¤‘ë³µ ì œê±° (PMID/ì œëª© ê¸°ë°˜)**
   ```python
   seen_pmids = set()
   seen_titles = set()
   unique_papers = []

   for paper in papers:
       # PMID ì¤‘ë³µ ì²´í¬
       if paper.get('pmid') and paper['pmid'] in seen_pmids:
           continue

       # ì œëª© ìœ ì‚¬ë„ ì²´í¬ (í•œêµ­ì–´ ë…¼ë¬¸)
       if paper['title'] in seen_titles:
           continue

       seen_pmids.add(paper.get('pmid'))
       seen_titles.add(paper['title'])
       unique_papers.append(paper)
   ```

3. **ë³‘í•© ë° ì €ì¥**
   ```bash
   # ì‹¤í–‰
   python merge_korean_corpus.py

   # ê²°ê³¼
   outputs/ragdb_final_corpus_20260129_195141.json (5.1MB, 2,577ê°œ ë…¼ë¬¸)
   ```

### ğŸ“Š ìµœì¢… Corpus í†µê³„

```json
{
  "total_papers": 2577,
  "by_language": {
    "en": 2127,  // ì˜ì–´ 82.5%
    "ko": 450    // í•œêµ­ì–´ 17.5%
  },
  "by_domain": {
    "protein_hypertrophy": 800,
    "fat_loss": 780,
    "korean_diet": 450,
    "body_composition": 547
  }
}
```

**íŒŒì¼ í¬ê¸°:** 5.1MB (66,620ì¤„)
**êµ¬ì¡°:** JSON Array `[{paper1}, {paper2}, ...]`

---

## 3ï¸âƒ£ Graph RAG êµ¬ì¶• (Graph RAG Building)

### ğŸ“ ìŠ¤í¬ë¦½íŠ¸
```
src/llm/ragdb_collect/build_graph_rag.py
```

### ğŸ¯ í•µì‹¬ ì—­í• 

**ë…¼ë¬¸ ì´ˆë¡ â†’ ê°œë… ì¶”ì¶œ â†’ ê´€ê³„ íƒì§€ â†’ ì„ë² ë”© ìƒì„± â†’ Graph êµ¬ì¡°í™”**

### ğŸ“‹ ì…ë ¥ íŒŒì¼

1. **ë…¼ë¬¸ Corpus**
   ```
   outputs/ragdb_final_corpus_20260129_195141.json (2,577ê°œ ë…¼ë¬¸)
   ```

2. **Graph ìŠ¤í‚¤ë§ˆ** (ê°œë… ì •ì˜)
   ```
   src/llm/ragdb_collect/graph_rag_schema.json
   ```
   ```json
   {
     "graph_rag_schema": {
       "concepts": [
         {
           "id": "muscle_hypertrophy",
           "name": "Muscle Hypertrophy",
           "aliases": ["ê·¼ë¹„ëŒ€", "muscle growth", "muscle mass gain"],
           "type": "Outcome",
           "description": "ê·¼ìœ¡ í¬ê¸° ë° ì§ˆëŸ‰ ì¦ê°€"
         },
         {
           "id": "protein_intake",
           "name": "Protein Intake",
           "aliases": ["ë‹¨ë°±ì§ˆ ì„­ì·¨", "protein consumption"],
           "type": "Intervention",
           "description": "ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ ë° íƒ€ì´ë°"
         },
         // ... ì´ 21ê°œ ê°œë…
       ]
     }
   }
   ```

### ğŸ”§ ì²˜ë¦¬ ê³¼ì •

#### Step 1: ê°œë… ì¶”ì¶œ (Concept Extraction)

```python
class GraphRAGBuilder:
    def extract_concepts_from_paper(self, paper: dict) -> List[str]:
        """ë…¼ë¬¸ ì´ˆë¡ì—ì„œ ê°œë… ì¶”ì¶œ"""
        text = f"{paper['title']} {paper['abstract']}".lower()
        found_concepts = []

        for concept in self.schema['concepts']:
            # ê°œë… ID ë˜ëŠ” aliases ê²€ìƒ‰
            if concept['id'] in text or any(alias.lower() in text for alias in concept['aliases']):
                found_concepts.append(concept['id'])

        return found_concepts
```

**ì˜ˆì‹œ:**
```
ë…¼ë¬¸: "Effects of Resistance Training on Muscle Hypertrophy"
ì´ˆë¡: "...resistance training...protein intake...muscle growth..."

â†’ ì¶”ì¶œëœ ê°œë…:
  - resistance_training
  - protein_intake
  - muscle_hypertrophy
```

#### Step 2: ê´€ê³„ íƒì§€ (Relationship Detection)

```python
def detect_relationships(self, paper: dict, concepts: List[str]) -> List[dict]:
    """ê°œë… ê°„ ê´€ê³„ íƒì§€"""
    relationships = []
    text = paper['abstract'].lower()

    for concept in concepts:
        # MENTIONS (ë‹¨ìˆœ ì–¸ê¸‰)
        relationships.append({
            'type': 'MENTIONS',
            'source': f"paper_{paper['pmid']}",
            'target': concept,
            'confidence': self._calculate_confidence(text, concept)
        })

        # INCREASES (ì¦ê°€ ê´€ê³„)
        if any(keyword in text for keyword in ['increase', 'enhance', 'improve']):
            if f"{concept}" in text:
                relationships.append({
                    'type': 'INCREASES',
                    'source': 'resistance_training',
                    'target': concept,
                    'confidence': 0.8
                })

    return relationships
```

**ê´€ê³„ íƒ€ì…:**
- **MENTIONS**: ë…¼ë¬¸ì´ ê°œë…ì„ ì–¸ê¸‰ (ëª¨ë“  ê²½ìš°)
- **INCREASES**: Aê°€ Bë¥¼ ì¦ê°€ì‹œí‚´ (`resistance_training INCREASES muscle_hypertrophy`)
- **SUPPORTS**: ì—°êµ¬ê°€ ê°œë…ì„ ì§€ì§€ (`paper SUPPORTS protein_intake`)
- **REDUCES**: Aê°€ Bë¥¼ ê°ì†Œì‹œí‚´ (`caloric_deficit REDUCES body_fat`)

#### Step 3: ì‹ ë¢°ë„ ê³„ì‚° (Confidence Scoring)

```python
def _calculate_confidence(self, text: str, concept: str) -> float:
    """Term frequency ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
    count = text.lower().count(concept.replace('_', ' '))

    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ì ìˆ˜
    if count >= 5:
        return 1.0
    elif count >= 3:
        return 0.8
    elif count >= 1:
        return 0.6
    else:
        return 0.5  # ê¸°ë³¸ê°’
```

#### Step 4: í•œêµ­ì–´ ì„ë² ë”© ìƒì„± (OpenAI)

**âš ï¸ ì¤‘ìš”: ëª¨ë“  ë…¼ë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ ì„ë² ë”© ìƒì„±!**

```python
# build_graph_rag.py
def generate_korean_embedding(self, text: str) -> List[float]:
    """OpenAI text-embedding-3-smallë¡œ ì„ë² ë”© ìƒì„±"""

    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (24,000ì)
    MAX_CHARS = 24000
    if len(text) > MAX_CHARS:
        text = text[:MAX_CHARS]

    # OpenAI API í˜¸ì¶œ
    response = self.openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )

    return response.data[0].embedding  # 1536ì°¨ì› ë²¡í„°
```

**ì„ë² ë”© ëŒ€ìƒ:**
- ì˜ì–´ ë…¼ë¬¸: ì œëª© + ì´ˆë¡ (ì˜ì–´ ê·¸ëŒ€ë¡œ)
- í•œêµ­ì–´ ë…¼ë¬¸: ì œëª© + ì´ˆë¡ (í•œêµ­ì–´ ê·¸ëŒ€ë¡œ)
- **ëª¨ë¸:** `text-embedding-3-small` (1536ì°¨ì›)
- **ì €ì¥ ìœ„ì¹˜:** `embedding_ko_openai` í•„ë“œ

**ì²˜ë¦¬ëŸ‰:**
```
ì´ 2,577ê°œ ë…¼ë¬¸
â”œâ”€ ì˜ì–´: 2,127ê°œ (ì„ë² ë”© ìƒì„±)
â”œâ”€ í•œêµ­ì–´: 450ê°œ (ì„ë² ë”© ìƒì„±)
â””â”€ ì„±ê³µ: 2,575ê°œ (99.92%)
    ì‹¤íŒ¨: 2ê°œ (í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼)
```

### ğŸ“Š ì¶œë ¥ íŒŒì¼

#### A. JSON íŒŒì¼ (ì „ì²´ ë°ì´í„°)

```
outputs/graph_rag_2577papers_20260130_211829.json (120MB!)
```

**êµ¬ì¡°:**
```json
{
  "papers": [
    {
      "paper_id": "paper_41415307",
      "title": "...",
      "abstract": "...",
      "domain": "protein_hypertrophy",
      "language": "en",
      "year": 2025,
      "pmid": "41415307",
      "doi": "10.1519/JSC.0000000000001049",
      "concepts": ["resistance_training", "muscle_hypertrophy"],
      "embedding_ko_openai": [0.123, -0.456, ...],  // 1536ì°¨ì›
      "chunk_ko_summary": null  // í•œêµ­ì–´ ìš”ì•½ (ì„ íƒ)
    },
    // ... 2,577ê°œ
  ],
  "concepts": [
    {
      "id": "muscle_hypertrophy",
      "name": "Muscle Hypertrophy",
      "type": "Outcome",
      "paper_count": 856  // ì´ ê°œë…ì„ ì–¸ê¸‰í•œ ë…¼ë¬¸ ìˆ˜
    },
    // ... 21ê°œ ê°œë…
  ],
  "relationships": [
    {
      "type": "MENTIONS",
      "source": "paper_41415307",
      "target": "muscle_hypertrophy",
      "confidence": 1.0
    },
    {
      "type": "INCREASES",
      "source": "resistance_training",
      "target": "muscle_hypertrophy",
      "confidence": 0.9
    },
    // ... 5,715ê°œ ê´€ê³„
  ],
  "stats": {
    "total_papers": 2577,
    "total_concepts": 21,
    "total_relationships": 5715,
    "embeddings_generated": 2575
  }
}
```

#### B. Neo4j Cypher íŒŒì¼ (Graph DB importìš©)

```
outputs/graph_rag_neo4j_2577papers_20260130_211829.cypher (1.3MB)
```

**êµ¬ì¡°:**
```cypher
// Paper ë…¸ë“œ ìƒì„±
CREATE (:Paper {
  id: 'paper_41415307',
  title: '...',
  abstract: '...',
  domain: 'protein_hypertrophy',
  language: 'en',
  year: 2025,
  pmid: '41415307'
});

// Concept ë…¸ë“œ ìƒì„±
CREATE (:Concept {
  id: 'muscle_hypertrophy',
  name: 'Muscle Hypertrophy',
  type: 'Outcome'
});

// ê´€ê³„ ìƒì„±
MATCH (p:Paper {id: 'paper_41415307'})
MATCH (c:Concept {id: 'muscle_hypertrophy'})
CREATE (p)-[:MENTIONS {confidence: 1.0}]->(c);

MATCH (c1:Concept {id: 'resistance_training'})
MATCH (c2:Concept {id: 'muscle_hypertrophy'})
CREATE (c1)-[:INCREASES {confidence: 0.9}]->(c2);

// ... 5,715ê°œ ê´€ê³„
```

### ğŸ“Š Graph í†µê³„

```json
{
  "total_papers": 2577,
  "total_concepts": 21,
  "total_relationships": 5715,
  "relationship_breakdown": {
    "MENTIONS": 3192,      // ë…¼ë¬¸ â†’ ê°œë…
    "CORRELATES_WITH": 2514,
    "INCREASES": 2,
    "SUPPORTS": 3,
    "REDUCES": 4
  },
  "papers_by_language": {
    "en": 2127,
    "ko": 450
  },
  "papers_with_embeddings": 2575
}
```

---

## 4ï¸âƒ£ PostgreSQL + Neo4j Import

### ğŸ“ ìŠ¤í¬ë¦½íŠ¸
```
backend/utils/scripts/import_graph_rag.py
```

### ğŸ¯ ì—­í• 

**Graph RAG JSON â†’ PostgreSQL (Vector ê²€ìƒ‰) + Neo4j (Graph íƒìƒ‰)**

### A. PostgreSQL Import

#### í…Œì´ë¸” êµ¬ì¡°

```sql
-- backend/models/paper_node.py
CREATE TABLE paper_nodes (
    id SERIAL PRIMARY KEY,
    paper_id VARCHAR(100) UNIQUE NOT NULL,  -- "paper_41415307"
    title TEXT NOT NULL,
    chunk_text TEXT NOT NULL,               -- ì´ˆë¡ ì „ë¬¸
    chunk_ko_summary TEXT,                  -- í•œêµ­ì–´ ìš”ì•½ (optional)
    domain VARCHAR(50),                     -- "protein_hypertrophy"
    lang VARCHAR(10),                       -- "en", "ko"
    source VARCHAR(50),                     -- "PubMed"
    year INTEGER,
    pmid VARCHAR(20),
    doi VARCHAR(100),

    -- ì„ë² ë”© (pgvector)
    embedding_ko_openai vector(1536),      -- OpenAI embedding
    embedding_ko_ollama vector(1024),      -- Ollama embedding (optional)

    created_at TIMESTAMP DEFAULT NOW()
);

-- Vector ê²€ìƒ‰ìš© ì¸ë±ìŠ¤
CREATE INDEX idx_paper_embedding_ko_openai
ON paper_nodes USING ivfflat (embedding_ko_openai vector_cosine_ops);
```

#### Import ê³¼ì •

```python
# import_graph_rag.py
def import_to_postgresql(json_data: dict):
    """PostgreSQLì— ë…¼ë¬¸ ë°ì´í„° import"""

    for paper in json_data['papers']:
        # PaperNode ëª¨ë¸ ìƒì„±
        paper_node = PaperNode(
            paper_id=paper['paper_id'],
            title=paper['title'],
            chunk_text=paper['abstract'],
            chunk_ko_summary=paper.get('chunk_ko_summary'),
            domain=paper.get('domain'),
            lang=paper.get('language'),
            source=paper.get('source'),
            year=paper.get('year'),
            pmid=paper.get('pmid'),
            doi=paper.get('doi'),

            # ì„ë² ë”© (1536ì°¨ì› vector)
            embedding_ko_openai=paper.get('embedding_ko_openai'),
            embedding_ko_ollama=paper.get('embedding_ko_ollama')
        )

        session.add(paper_node)

    session.commit()
```

**ì €ì¥ ë°ì´í„°:**
- ì´ 2,577ê°œ ë…¼ë¬¸
- 2,575ê°œ ì„ë² ë”© (OpenAI text-embedding-3-small, 1536D)
- Vector ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ

### B. Neo4j Import

#### Graph êµ¬ì¡°

```
(Paper) -[MENTIONS]-> (Concept)
(Paper) -[SUPPORTS]-> (Concept)
(Concept) -[INCREASES]-> (Concept)
(Concept) -[REDUCES]-> (Concept)
```

#### Import ê³¼ì •

```python
# import_graph_rag.py
def import_to_neo4j(json_data: dict):
    """Neo4jì— Graph ë°ì´í„° import"""

    # 1. Paper ë…¸ë“œ ìƒì„±
    for paper in json_data['papers']:
        query = """
        CREATE (:Paper {
            id: $paper_id,
            title: $title,
            domain: $domain,
            year: $year,
            pmid: $pmid
        })
        """
        session.run(query, paper_id=paper['paper_id'], ...)

    # 2. Concept ë…¸ë“œ ìƒì„±
    for concept in json_data['concepts']:
        query = """
        CREATE (:Concept {
            id: $concept_id,
            name: $name,
            type: $type
        })
        """
        session.run(query, concept_id=concept['id'], ...)

    # 3. ê´€ê³„ ìƒì„±
    for rel in json_data['relationships']:
        if rel['source'].startswith('paper_'):
            # Paper â†’ Concept
            query = """
            MATCH (p:Paper {id: $source})
            MATCH (c:Concept {id: $target})
            CREATE (p)-[:MENTIONS {confidence: $confidence}]->(c)
            """
        else:
            # Concept â†’ Concept
            query = """
            MATCH (c1:Concept {id: $source})
            MATCH (c2:Concept {id: $target})
            CREATE (c1)-[:INCREASES {confidence: $confidence}]->(c2)
            """

        session.run(query, source=rel['source'], target=rel['target'], ...)
```

**ì €ì¥ ë°ì´í„°:**
- 2,577ê°œ Paper ë…¸ë“œ
- 21ê°œ Concept ë…¸ë“œ
- 5,715ê°œ ê´€ê³„ (MENTIONS, INCREASES, SUPPORTS, REDUCES)

### ğŸ“Š Import ê²°ê³¼ í™•ì¸

```bash
# PostgreSQL í™•ì¸
psql -U sgkim -d explainmybody
> SELECT COUNT(*) FROM paper_nodes;
  2577

> SELECT COUNT(*) FROM paper_nodes WHERE embedding_ko_openai IS NOT NULL;
  2575

# Neo4j í™•ì¸
http://localhost:7474 (Neo4j Browser)

MATCH (p:Paper) RETURN COUNT(p);
// 2577

MATCH ()-[r:MENTIONS]->() RETURN COUNT(r);
// 3192
```

---

## 5ï¸âƒ£ ëŸ°íƒ€ì„ ê²€ìƒ‰ (Runtime Retrieval)

### ğŸ“ ì½”ë“œ
```
src/llm/pipeline_weekly_plan_rag/graph_rag_retriever.py
```

### ğŸ¯ Hybrid Search: Vector + Graph

#### Step 1: InBody ë°ì´í„° â†’ ê°œë… ì¶”ì¶œ

```python
# analyzer.py
def _extract_concepts_from_measurements(measurements):
    """InBody ì¸¡ì •ê°’ â†’ ê²€ìƒ‰ ê°œë…"""
    concepts = set()

    if measurements.ì²´ì§€ë°©ë¥  > 25:  # ë‚¨ì„± ê¸°ì¤€
        concepts.add("fat_loss")
        concepts.add("body_fat_percentage")

    if measurements.ê·¼ìœ¡ì¡°ì ˆ > 0:
        concepts.add("muscle_hypertrophy")
        concepts.add("protein_intake")
        concepts.add("resistance_training")

    return list(concepts)

# ì˜ˆì‹œ ê²°ê³¼
# InBody: ì²´ì§€ë°©ë¥  28%, ê·¼ìœ¡ì¡°ì ˆ +2.5kg
# â†’ concepts = ["fat_loss", "muscle_hypertrophy", "protein_intake", "resistance_training"]
```

#### Step 2: Vector Search (PostgreSQL)

```python
# graph_rag_retriever.py
def retrieve_relevant_papers(query: str, concepts: List[str], top_k: int = 10):
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = openai_client.create_embedding(
        text="ê·¼ìœ¡ ì¦ê°€ ì²´ì§€ë°© ê°ì†Œ ë°©ë²• ë° íš¨ê³¼"
    )  # â†’ 1536ì°¨ì› ë²¡í„°

    # 2. PostgreSQL Vector ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    vector_papers = paper_repo.search_similar_papers(
        query_embedding=query_embedding,
        top_k=20,  # í›„ë³´ í™•ì¥
        use_ko_embedding=True  # embedding_ko_openai ì‚¬ìš©
    )
```

**SQL ì¿¼ë¦¬:**
```sql
SELECT
    paper_id,
    title,
    chunk_text,
    1 - (embedding_ko_openai <=> $query_embedding) AS similarity
FROM paper_nodes
WHERE embedding_ko_openai IS NOT NULL
ORDER BY embedding_ko_openai <=> $query_embedding
LIMIT 20;
```

**ê²°ê³¼:**
```python
[
    {
        'paper_id': 'paper_41415307',
        'title': 'Resistance training-induced...',
        'similarity': 0.89  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    },
    # ... 20ê°œ
]
```

#### Step 3: Graph Traversal (Neo4j)

```python
# graph_rag_retriever.py
def _expand_by_concepts(concepts: List[str], limit: int = 10):
    """ê°œë… ê¸°ë°˜ ê·¸ë˜í”„ íƒìƒ‰"""

    for concept_id in concepts:  # ["muscle_hypertrophy", "protein_intake"]
        # Neo4j Cypher ì¿¼ë¦¬
        query = """
        MATCH (p:Paper)-[r:MENTIONS|INCREASES|SUPPORTS]->(c:Concept {id: $concept_id})
        RETURN p.id AS paper_id,
               p.title AS title,
               type(r) AS relation_type,
               r.confidence AS confidence
        ORDER BY r.confidence DESC
        LIMIT $limit
        """

        results = neo4j_session.run(query, concept_id=concept_id, limit=limit)
```

**ê²°ê³¼:**
```python
[
    {
        'paper_id': 'paper_12345',
        'title': 'Protein requirements for muscle gain',
        'relation_type': 'INCREASES',
        'confidence': 0.9
    },
    # ... 10ê°œ (ê°œë…ë‹¹)
]
```

#### Step 4: Hybrid Reranking

```python
# graph_rag_retriever.py
def _merge_and_rerank(vector_papers, graph_papers, top_k: int):
    """Vector + Graph ê²°ê³¼ ë³‘í•© ë° ì¬ì •ë ¬"""

    VECTOR_WEIGHT = 0.7  # Vector ê²€ìƒ‰ ê°€ì¤‘ì¹˜
    GRAPH_WEIGHT = 0.3   # Graph ê²€ìƒ‰ ê°€ì¤‘ì¹˜

    paper_map = {}

    # Vector ê²°ê³¼ ì¶”ê°€
    for paper in vector_papers:
        paper_map[paper['paper_id']] = {
            'vector_score': paper['similarity'],
            'graph_score': 0.0
        }

    # Graph ê²°ê³¼ ì¶”ê°€/ë³‘í•©
    for paper in graph_papers:
        if paper['paper_id'] in paper_map:
            # ì¤‘ë³µ: graph_score ì—…ë°ì´íŠ¸
            paper_map[paper['paper_id']]['graph_score'] = max(
                paper_map[paper['paper_id']]['graph_score'],
                paper['confidence']
            )
        else:
            # ìƒˆë¡œìš´ ë…¼ë¬¸
            paper_map[paper['paper_id']] = {
                'vector_score': 0.0,
                'graph_score': paper['confidence']
            }

    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    for paper_id, scores in paper_map.items():
        final_score = (
            VECTOR_WEIGHT * scores['vector_score'] +
            GRAPH_WEIGHT * scores['graph_score']
        )
        paper_map[paper_id]['final_score'] = final_score

    # ì ìˆ˜ ì •ë ¬
    sorted_papers = sorted(
        paper_map.items(),
        key=lambda x: x[1]['final_score'],
        reverse=True
    )

    return sorted_papers[:top_k]  # ìƒìœ„ 10ê°œ
```

**ìµœì¢… ê²°ê³¼:**
```python
[
    {
        'paper_id': 'paper_41415307',
        'title': 'Resistance training-induced...',
        'vector_score': 0.89,
        'graph_score': 0.0,
        'final_score': 0.623  # 0.7*0.89 + 0.3*0.0
    },
    {
        'paper_id': 'paper_12345',
        'title': 'Protein requirements...',
        'vector_score': 0.75,
        'graph_score': 0.9,
        'final_score': 0.795  # 0.7*0.75 + 0.3*0.9 â† ë” ë†’ìŒ!
    },
    # ... 10ê°œ
]
```

---

## 6ï¸âƒ£ Prompt ìƒì„± + LLM ë¶„ì„

### ğŸ“ ì½”ë“œ
```
src/llm/pipeline_inbody_analysis_rag/prompt_generator.py
```

### ğŸ¯ ë…¼ë¬¸ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…

```python
def _format_paper_context(papers: List[dict]) -> str:
    """ê²€ìƒ‰ëœ ë…¼ë¬¸ â†’ Prompt í˜•ì‹"""

    formatted_text = "## ğŸ“š ê³¼í•™ì  ê·¼ê±° (ìµœì‹  ì—°êµ¬ ë…¼ë¬¸)\n\n"

    for i, paper in enumerate(papers, 1):
        formatted_text += f"""### ë…¼ë¬¸ {i}: {paper['title']}
- ì¶œì²˜: {paper['source']} ({paper['year']})
- ê´€ë ¨ë„: {paper['final_score']:.2f}
- í•µì‹¬ ë‚´ìš©: {paper['chunk_text'][:400]}...

"""

    formatted_text += "\n**ë¶„ì„ ì‹œ ì£¼ì˜ì‚¬í•­:**\n"
    formatted_text += "- ìœ„ ë…¼ë¬¸ì˜ ë‚´ìš©ì„ InBody ì¸¡ì • ìˆ˜ì¹˜ì™€ ì§ì ‘ ì—°ê²°í•˜ì„¸ìš”\n"

    return formatted_text
```

**User Prompt ìµœì¢… í˜•íƒœ:**
```
# InBody ì¸¡ì • ë°ì´í„°

## ê¸°ë³¸ ì •ë³´
- ì„±ë³„: ë‚¨ì„±
- ë‚˜ì´: 28ì„¸
- ì²´ì¤‘: 75kg
...

## ğŸ“š ê³¼í•™ì  ê·¼ê±° (ìµœì‹  ì—°êµ¬ ë…¼ë¬¸)

### ë…¼ë¬¸ 1: Resistance training-induced appendicular lean tissue...
- ì¶œì²˜: PubMed (2025)
- ê´€ë ¨ë„: 0.89
- í•µì‹¬ ë‚´ìš©: We sought to determine if pre-intervention bone...

### ë…¼ë¬¸ 2: The Role of mTOR and AMPK Signaling...
- ì¶œì²˜: PubMed (2025)
- ê´€ë ¨ë„: 0.85
- í•µì‹¬ ë‚´ìš©: Maintaining skeletal muscle mass is fundamental...

(10ê°œ ë…¼ë¬¸ ê³„ì†...)
```

### ğŸ¤– LLM ë¶„ì„ (gpt-4o-mini)

```python
# analyzer.py
analysis_text = llm_client.generate_chat(
    system_prompt=system_prompt,  # ë¶„ì„ ê°€ì´ë“œë¼ì¸
    user_prompt=user_prompt        # InBody ë°ì´í„° + ë…¼ë¬¸ 10ê°œ
)
```

**LLM ì¶œë ¥ ì˜ˆì‹œ:**
```
### [ì²´ì„±ë¶„ ìƒì„¸ ë¶„ì„]

**ê·¼ìœ¡ëŸ‰ ìƒíƒœ**
ê³¨ê²©ê·¼ëŸ‰ 32.5kgì€ [ë…¼ë¬¸1]ì˜ ì—°êµ¬ ëŒ€ìƒ(30-40ì„¸ ë‚¨ì„±, n=119) í‰ê· 
33.2kgÂ±3.1ê³¼ ë¹„êµí•˜ì—¬ í‰ê·  ë²”ìœ„ì— ì†í•©ë‹ˆë‹¤.

ê·¼ìœ¡ì¡°ì ˆ ëª©í‘œ +2.5kgëŠ” [ë…¼ë¬¸2]ì˜ 12ì£¼ ì €í•­ì„± ìš´ë™ í”„ë¡œê·¸ë¨ì—ì„œ
ë³´ê³ ëœ í‰ê·  ê·¼ìœ¡ ì¦ê°€ëŸ‰ +2.8kgÂ±0.6ê³¼ ë¹„êµí•˜ì—¬ í˜„ì‹¤ì ì¸ ëª©í‘œì…ë‹ˆë‹¤.

[ë…¼ë¬¸2]ì— ë”°ë¥´ë©´, ì£¼ 3-4íšŒ ì €í•­ì„± ìš´ë™ê³¼ ë‹¨ë°±ì§ˆ 1.6-2.2g/kg ì„­ì·¨ ì‹œ
12ì£¼ ë‚´ ì´ ì •ë„ ê·¼ìœ¡ ì¦ê°€ê°€ ê°€ëŠ¥í•˜ë©°...
```

---

## 7ï¸âƒ£ ì „ì²´ ë°ì´í„° íë¦„ ìš”ì•½

### ğŸ“Š íŒŒì¼ í¬ê¸° ë° ë°ì´í„°ëŸ‰

| ë‹¨ê³„ | íŒŒì¼ | í¬ê¸° | ë°ì´í„° |
|------|------|------|--------|
| ìˆ˜ì§‘ | papers/*.json | 3.7MB | 2,577ê°œ ë…¼ë¬¸ (ê°œë³„) |
| ë³‘í•© | ragdb_final_corpus.json | 5.1MB | 2,577ê°œ ë…¼ë¬¸ (ì¤‘ë³µ ì œê±°) |
| Graph êµ¬ì¶• | graph_rag_2577papers.json | 120MB | ë…¼ë¬¸+ê°œë…+ê´€ê³„+ì„ë² ë”© |
| Neo4j | *.cypher | 1.3MB | 5,715ê°œ ê´€ê³„ |
| PostgreSQL | paper_nodes í…Œì´ë¸” | ~150MB | 2,577í–‰ + 2,575 ë²¡í„° |

### ğŸ”¢ ì„ë² ë”© í†µê³„

| í•­ëª© | ìˆ˜ì¹˜ |
|------|------|
| ì´ ë…¼ë¬¸ ìˆ˜ | 2,577ê°œ |
| ì„ë² ë”© ìƒì„± | 2,575ê°œ (99.92%) |
| ì„ë² ë”© ì‹¤íŒ¨ | 2ê°œ (0.08%, í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼) |
| ì„ë² ë”© ëª¨ë¸ | OpenAI text-embedding-3-small |
| ì„ë² ë”© ì°¨ì› | 1536D |
| ì €ì¥ ìœ„ì¹˜ | PostgreSQL `embedding_ko_openai` ì»¬ëŸ¼ |
| Vector ì¸ë±ìŠ¤ | IVFFlat (ì½”ì‚¬ì¸ ìœ ì‚¬ë„) |

### ğŸ¯ ê²€ìƒ‰ ì„±ëŠ¥

| í•­ëª© | ê°’ |
|------|-----|
| Vector Search ì†ë„ | ~50ms (top 20) |
| Graph Traversal ì†ë„ | ~30ms (ê°œë…ë‹¹ 10ê°œ) |
| Hybrid Reranking | ~10ms |
| **ì´ ê²€ìƒ‰ ì‹œê°„** | **~100ms** |
| ê²€ìƒ‰ ê²°ê³¼ | 10ê°œ ë…¼ë¬¸ (ê´€ë ¨ë„ 0.4-1.0) |

---

## ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸

### 1ï¸âƒ£ ë…¼ë¬¸ ë°ì´í„° íë¦„
```
PubMed/KCI API
    â†“ (JSON)
ê°œë³„ ìˆ˜ì§‘ íŒŒì¼ (3.7MB)
    â†“ (ì¤‘ë³µ ì œê±°)
í†µí•© Corpus (5.1MB, 2,577ê°œ)
    â†“ (ê°œë… ì¶”ì¶œ + ì„ë² ë”©)
Graph RAG (120MB, ë…¼ë¬¸+ê´€ê³„+ë²¡í„°)
    â†“ (Import)
PostgreSQL (Vector ê²€ìƒ‰) + Neo4j (Graph íƒìƒ‰)
    â†“ (ëŸ°íƒ€ì„ ê²€ìƒ‰)
InBody ë¶„ì„ Prompt (10ê°œ ë…¼ë¬¸)
    â†“ (LLM)
ê³¼í•™ì  ê·¼ê±° ê¸°ë°˜ ë¶„ì„ ë¦¬í¬íŠ¸
```

### 2ï¸âƒ£ ì„ë² ë”© ìƒì„± ë°©ì‹

- **ì‹œì **: Graph RAG êµ¬ì¶• ì‹œ (build_graph_rag.py)
- **ëª¨ë¸**: OpenAI text-embedding-3-small (1536D)
- **ëŒ€ìƒ**: ëª¨ë“  ë…¼ë¬¸ (ì˜ì–´ + í•œêµ­ì–´)
- **ì…ë ¥**: ì œëª© + ì´ˆë¡ (ìµœëŒ€ 24,000ì)
- **ì €ì¥**: JSON `embedding_ko_openai` + PostgreSQL `embedding_ko_openai` ì»¬ëŸ¼
- **ìš©ë„**: Vector Search (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)

### 3ï¸âƒ£ ê²€ìƒ‰ ë©”ì»¤ë‹ˆì¦˜

- **Vector Search**: ì¿¼ë¦¬ ì„ë² ë”© â†” ë…¼ë¬¸ ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„
- **Graph Traversal**: ê°œë… IDë¡œ ê´€ë ¨ ë…¼ë¬¸ íƒìƒ‰ (Neo4j Cypher)
- **Hybrid**: 0.7*vector + 0.3*graph ê°€ì¤‘ í‰ê· 
- **ìµœì¢… ê²°ê³¼**: ìƒìœ„ 10ê°œ ë…¼ë¬¸ (ê´€ë ¨ë„ ìˆœ)

### 4ï¸âƒ£ ì‹¤ì œ ì‚¬ìš© íë¦„

```
ì‚¬ìš©ì: InBody ë°ì´í„° ì…ë ¥
    â†“
1. ê°œë… ì¶”ì¶œ (ì²´ì§€ë°©ë¥  28% â†’ "fat_loss", "muscle_hypertrophy")
2. ì¿¼ë¦¬ ìƒì„± ("ê·¼ìœ¡ ì¦ê°€ ì²´ì§€ë°© ê°ì†Œ ë°©ë²•")
3. Vector Search (PostgreSQL, ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
4. Graph Traversal (Neo4j, ê°œë… ê¸°ë°˜)
5. Hybrid Reranking (0.7*vector + 0.3*graph)
6. ìƒìœ„ 10ê°œ ë…¼ë¬¸ ì„ íƒ
7. Prompt ìƒì„± (InBody ë°ì´í„° + ë…¼ë¬¸ 10ê°œ)
8. LLM ë¶„ì„ (gpt-4o-mini)
9. ê²°ê³¼ ì¶œë ¥ (ë…¼ë¬¸ ê·¼ê±° í¬í•¨ ë¦¬í¬íŠ¸)
```

---

**ì™„ì„±ëœ RAG íŒŒì´í”„ë¼ì¸!** ğŸ‰
