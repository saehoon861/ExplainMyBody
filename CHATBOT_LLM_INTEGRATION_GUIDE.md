# ğŸ¤– ì±—ë´‡ ë°±ì—”ë“œ ì—°ê²° ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ExplainMyBodyì˜ ì±—ë´‡ í˜ì´ì§€ë¥¼ ë°±ì—”ë“œ APIì™€ ì—°ê²°í•˜ëŠ” í†µí•© ê°€ì´ë“œì…ë‹ˆë‹¤.

**ì‘ì—… ì¼ì**: 2026-01-30
**ìƒíƒœ**: âœ… ì„ì‹œ êµ¬í˜„ ì™„ë£Œ (í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ)
**í–¥í›„ ê³„íš**: ë°±ì—”ë“œ ë‹´ë‹¹ìê°€ ì‹¤ì œ LLM/LangGraph ì—°ê²° ì˜ˆì •

---

## ğŸ¯ êµ¬í˜„ ëª©í‘œ

### Before (ê¸°ì¡´)
- í”„ë¡ íŠ¸ì—”ë“œì—ì„œ Mock ì‘ë‹µ ì‚¬ìš©
- í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ ì‘ë‹µ
- ëŒ€í™” ì´ë ¥ ì—†ìŒ

### After (ë³€ê²½ í›„)
- ë°±ì—”ë“œ API í˜¸ì¶œ (í˜„ì¬: Mock ì‘ë‹µ)
- Thread ID ê¸°ë°˜ êµ¬ì¡° ì¤€ë¹„
- í–¥í›„ ì‹¤ì œ LLM ì—°ê²° ê°€ëŠ¥ (OpenAI API ì§ì ‘ ì—°ê²° ë˜ëŠ” LangGraph)

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
í”„ë¡ íŠ¸ì—”ë“œ (React)
    â†“
Chatbot.jsx â†’ sendChatbotMessage()
    â†“
/api/chatbot/chat (ë°±ì—”ë“œ API)
    â†“
chatbot_router.py â†’ LLMService
    â†“
llm_service.py â†’ chatbot_conversation()
    â†“
í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ (í˜„ì¬)
ë˜ëŠ”
ì‹¤ì œ LLM API (í–¥í›„ êµ¬í˜„ - OpenAI, Claude ë“±)
```

---

## ğŸ“ ìˆ˜ì •ëœ íŒŒì¼ ëª©ë¡

### ë°±ì—”ë“œ (Python/FastAPI)
1. **schemas/llm.py** - ì±—ë´‡ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
2. **services/llm/llm_service.py** - ì±—ë´‡ ëŒ€í™” ë©”ì„œë“œ ì¶”ê°€
3. **routers/chatbot.py** - ì±—ë´‡ ë¼ìš°í„° ì‹ ê·œ ìƒì„±
4. **routers/__init__.py** - ì±—ë´‡ ë¼ìš°í„° export ì¶”ê°€
5. **main.py** - ì±—ë´‡ ë¼ìš°í„° ë“±ë¡

### í”„ë¡ íŠ¸ì—”ë“œ (React)
1. **services/chatService.js** - sendChatbotMessage() API í•¨ìˆ˜ ì¶”ê°€
2. **pages/Chatbot/Chatbot.jsx** - Mock ì‘ë‹µ â†’ ì‹¤ì œ API í˜¸ì¶œë¡œ ë³€ê²½

---

## ğŸ’» ë°±ì—”ë“œ ë³€ê²½ ì‚¬í•­ (ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬)

### 1. schemas/llm.py - ìŠ¤í‚¤ë§ˆ ì¶”ê°€

**ìœ„ì¹˜**: `backend/schemas/llm.py` íŒŒì¼ ëì— ì¶”ê°€

**ë³€ê²½ ë‚´ìš©**:
```python
# ============================================================================
# Chatbot Schemas - ì±—ë´‡ ëŒ€í™”
# ============================================================================

class ChatbotRequest(BaseModel):
    """ì±—ë´‡ ëŒ€í™” ìš”ì²­"""
    bot_type: str  # "inbody-analyst" ë˜ëŠ” "workout-planner"
    message: str
    user_id: Optional[int] = None  # ì˜µì…˜: ì‚¬ìš©ìë³„ ëŒ€í™” ì´ë ¥ ê´€ë¦¬
    thread_id: Optional[str] = None  # ì˜µì…˜: ì´ì „ ëŒ€í™” ì´ì–´ì„œ í•˜ê¸°


class ChatbotResponse(BaseModel):
    """ì±—ë´‡ ëŒ€í™” ì‘ë‹µ"""
    response: str
    thread_id: str  # ëŒ€í™” ì´ë ¥ ì¶”ì ìš©
```

**ì—­í• **:
- í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ ê°„ ë°ì´í„° í˜•ì‹ ì •ì˜
- Pydanticì„ í†µí•œ ë°ì´í„° ê²€ì¦

---

### 2. services/llm/llm_service.py - ì±—ë´‡ ë©”ì„œë“œ ì¶”ê°€

**ìœ„ì¹˜**: `backend/services/llm/llm_service.py` íŒŒì¼ ëì— ì¶”ê°€

**ë³€ê²½ ë‚´ìš©** (í˜„ì¬: í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ):
```python
async def chatbot_conversation(
    self,
    bot_type: str,
    user_message: str,
    thread_id: Optional[str] = None,
    user_id: Optional[int] = None
) -> Dict[str, Any]:
    """
    ì±—ë´‡ ëŒ€í™” ì²˜ë¦¬

    Args:
        bot_type: ì±—ë´‡ ìœ í˜• ("inbody-analyst" ë˜ëŠ” "workout-planner")
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        thread_id: ê¸°ì¡´ ëŒ€í™” ìŠ¤ë ˆë“œ ID (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
        user_id: ì‚¬ìš©ì ID (ì˜µì…˜)

    Returns:
        {
            "response": str,  # AI ì‘ë‹µ
            "thread_id": str  # ëŒ€í™” ìŠ¤ë ˆë“œ ID
        }
    """
    # ìŠ¤ë ˆë“œ ID ìƒì„± ë˜ëŠ” ì¬ì‚¬ìš©
    if not thread_id:
        import uuid
        thread_id = f"chatbot_{bot_type}_{user_id or 'guest'}_{uuid.uuid4().hex[:8]}"

    # ====================================================================
    # TODO: ë°±ì—”ë“œ ë‹´ë‹¹ìê°€ ì‹¤ì œ LLM API ì—°ê²° í•„ìš”
    # í˜„ì¬ëŠ” ì„ì‹œ Mock ì‘ë‹µ ì‚¬ìš© (í‚¤ì›Œë“œ ë§¤ì¹­)
    # ====================================================================

    # ì„ì‹œ Mock ì‘ë‹µ (ì‹¤ì œ LLM êµ¬í˜„ ì „ê¹Œì§€)
    MOCK_RESPONSES = {
        "inbody-analyst": {
            "keywords": {
                "ì²´ì§€ë°©": "ì²´ì§€ë°© ê°ì†Œë¥¼ ìœ„í•´ì„œëŠ” ìœ ì‚°ì†Œ ìš´ë™ê³¼ ê·¼ë ¥ ìš´ë™ì„ ë³‘í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤...",
                "ê·¼ìœ¡": "ê·¼ìœ¡ëŸ‰ ì¦ê°€ë¥¼ ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ ë‹¨ë°±ì§ˆ ì„­ì·¨(ì²´ì¤‘ 1kgë‹¹ 1.6-2g)ì™€...",
                "ì‹ë‹¨": "ê· í˜•ì¡íŒ ì˜ì–‘ ì„­ì·¨ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. íƒ„ìˆ˜í™”ë¬¼:ë‹¨ë°±ì§ˆ:ì§€ë°©ì„ 5:3:2 ë¹„ìœ¨ë¡œ...",
                # ... ë” ë§ì€ í‚¤ì›Œë“œ
            },
            "default": "ì•ˆë…•í•˜ì„¸ìš”! ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ì„±ë¶„ ë°ì´í„° ë¶„ì„, ì‹ë‹¨, ìš´ë™..."
        },
        "workout-planner": {
            "keywords": {
                "ìš´ë™": "íš¨ê³¼ì ì¸ ìš´ë™ ë£¨í‹´ì„ ìœ„í•´ì„œëŠ” ëª©í‘œì™€ í˜„ì¬ ì²´ë ¥ ìˆ˜ì¤€ì„ ê³ ë ¤í•´ì•¼...",
                "í•˜ì²´": "í•˜ì²´ ìš´ë™ì˜ ê¸°ë³¸ì€ ìŠ¤ì¿¼íŠ¸ì…ë‹ˆë‹¤! ì›”ìš”ì¼ê³¼ ëª©ìš”ì¼ì—...",
                # ... ë” ë§ì€ í‚¤ì›Œë“œ
            },
            "default": "ì•ˆë…•í•˜ì„¸ìš”! ìš´ë™ í”Œë˜ë„ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°œì¸ ë§ì¶¤í˜• ìš´ë™ ë£¨í‹´..."
        }
    }

    # ë´‡ íƒ€ì…ì— ë§ëŠ” ì‘ë‹µ ì„ íƒ
    bot_responses = MOCK_RESPONSES.get(bot_type, MOCK_RESPONSES["inbody-analyst"])

    # í‚¤ì›Œë“œ ë§¤ì¹­
    ai_response = bot_responses["default"]
    for keyword, response in bot_responses["keywords"].items():
        if keyword in user_message:
            ai_response = response
            break

    return {
        "response": ai_response,
        "thread_id": thread_id
    }
```

**í˜„ì¬ êµ¬í˜„**:
- âŒ **LangGraph ì‚¬ìš© ì•ˆí•¨** (ë³µì¡ë„ ì œê±°)
- âœ… **í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ** (ê°„ë‹¨í•œ ë¡œì§)
- âœ… **Thread ID ìƒì„±** (í–¥í›„ ëŒ€í™” ì´ë ¥ ì¶”ì ìš©)

**í–¥í›„ ì‹¤ì œ LLM ì—°ê²° ì‹œ**:
ë°±ì—”ë“œ ë‹´ë‹¹ìê°€ Mock ì‘ë‹µ ë¶€ë¶„ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ êµì²´:
1. **OpenAI API ì§ì ‘ í˜¸ì¶œ** (ê°„ë‹¨, ì¶”ì²œ)
2. **LangGraph + OpenAI** (ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° í•„ìš” ì‹œ)
3. **ë‹¤ë¥¸ LLM** (Anthropic Claude, Google Gemini ë“±)

---

### 3. routers/chatbot.py - ì‹ ê·œ ë¼ìš°í„° ìƒì„±

**ìœ„ì¹˜**: `backend/routers/chatbot.py` (ì‹ ê·œ íŒŒì¼)

**ì „ì²´ ì½”ë“œ**:
```python
"""
ì±—ë´‡ ë¼ìš°í„°
/api/chatbot/*
"""

from fastapi import APIRouter, HTTPException
from schemas.llm import ChatbotRequest, ChatbotResponse
from services.llm.llm_service import LLMService

router = APIRouter()
llm_service = LLMService()


@router.post("/chat", response_model=ChatbotResponse)
async def chat_with_bot(request: ChatbotRequest):
    """
    ì±—ë´‡ê³¼ ëŒ€í™”

    - **bot_type**: ì±—ë´‡ ìœ í˜• ("inbody-analyst" ë˜ëŠ” "workout-planner")
    - **message**: ì‚¬ìš©ì ë©”ì‹œì§€
    - **user_id**: ì‚¬ìš©ì ID (ì˜µì…˜)
    - **thread_id**: ê¸°ì¡´ ëŒ€í™” ì´ì–´ê°€ê¸° (ì˜µì…˜)
    """
    # ì§€ì›ë˜ëŠ” ì±—ë´‡ ìœ í˜• í™•ì¸
    SUPPORTED_BOT_TYPES = ["inbody-analyst", "workout-planner"]
    if request.bot_type not in SUPPORTED_BOT_TYPES:
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì±—ë´‡ ìœ í˜•ì…ë‹ˆë‹¤. {SUPPORTED_BOT_TYPES} ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”."
        )

    try:
        # LLM ì„œë¹„ìŠ¤ í˜¸ì¶œ
        result = await llm_service.chatbot_conversation(
            bot_type=request.bot_type,
            user_message=request.message,
            thread_id=request.thread_id,
            user_id=request.user_id
        )

        return ChatbotResponse(
            response=result["response"],
            thread_id=result["thread_id"]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
```

**ì—­í• **:
- `/api/chatbot/chat` ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
- ìš”ì²­ ë°ì´í„° ê²€ì¦ (bot_type, message)
- LLM ì„œë¹„ìŠ¤ í˜¸ì¶œ ë° ì‘ë‹µ ë°˜í™˜

---

### 4. routers/__init__.py - Export ì¶”ê°€

**ìœ„ì¹˜**: `backend/routers/__init__.py`

**ë³€ê²½ ì „**:
```python
from .common import auth_router, users_router
from .ocr import health_records_router
from .llm import analysis_router, goals_router

__all__ = ["auth_router", "users_router", "health_records_router", "analysis_router", "goals_router"]
```

**ë³€ê²½ í›„**:
```python
from .common import auth_router, users_router
from .ocr import health_records_router
from .llm import analysis_router, goals_router, weekly_plans_router
from .chatbot import router as chatbot_router

__all__ = [
    "auth_router",
    "users_router",
    "health_records_router",
    "analysis_router",
    "goals_router",
    "weekly_plans_router",
    "chatbot_router"
]
```

---

### 5. main.py - ë¼ìš°í„° ë“±ë¡

**ìœ„ì¹˜**: `backend/main.py`

**ë³€ê²½ ë‚´ìš©**:

1. Import ì¶”ê°€:
```python
from routers import chatbot_router
```

2. ë¼ìš°í„° ë“±ë¡ ì¶”ê°€:
```python
app.include_router(chatbot_router, prefix="/api/chatbot", tags=["ì±—ë´‡"])
```

**ì „ì²´ ë¼ìš°í„° ë“±ë¡ ë¶€ë¶„**:
```python
# ë¼ìš°í„° ë“±ë¡
app.include_router(auth_router, prefix="/api/auth", tags=["ì¸ì¦"])
app.include_router(users_router, prefix="/api/users", tags=["ì‚¬ìš©ì"])
app.include_router(health_records_router, prefix="/api/health-records", tags=["ê±´ê°• ê¸°ë¡"])
app.include_router(analysis_router, prefix="/api/analysis", tags=["ë¶„ì„"])
app.include_router(goals_router, prefix="/api/goals", tags=["ëª©í‘œ"])
app.include_router(weekly_plans_router, prefix="/api/weekly-plans", tags=["ì£¼ê°„ ê³„íš"])
app.include_router(chatbot_router, prefix="/api/chatbot", tags=["ì±—ë´‡"])  # ì‹ ê·œ
```

---

## ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ ì‚¬í•­

### 1. services/chatService.js - API í•¨ìˆ˜ ì¶”ê°€

**ìœ„ì¹˜**: `frontend/src/services/chatService.js` íŒŒì¼ ëì— ì¶”ê°€

**ë³€ê²½ ë‚´ìš©**:
```javascript
/**
 * ì±—ë´‡ ëŒ€í™” (ì‹ ê·œ)
 *
 * ğŸ“ ì‚¬ìš© ìœ„ì¹˜: pages/Chatbot/Chatbot.jsx
 *
 * ê¸°ëŠ¥:
 * - ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ ë˜ëŠ” ìš´ë™ í”Œë˜ë„ˆ ì „ë¬¸ê°€ì™€ ëŒ€í™”
 * - ë°±ì—”ë“œ APIë¥¼ í†µí•œ ì‘ë‹µ ìƒì„± (í˜„ì¬: Mock, í–¥í›„: ì‹¤ì œ LLM)
 * - ëŒ€í™” ì´ë ¥ ìë™ ì¶”ì  (thread_id ì‚¬ìš©)
 *
 * @param {Object} data - ì±—ë´‡ ëŒ€í™” ìš”ì²­ ë°ì´í„°
 * @param {string} data.bot_type - ì±—ë´‡ ìœ í˜• ("inbody-analyst" | "workout-planner")
 * @param {string} data.message - ì‚¬ìš©ì ë©”ì‹œì§€
 * @param {number} [data.user_id] - ì‚¬ìš©ì ID (ì˜µì…˜)
 * @param {string} [data.thread_id] - ëŒ€í™” ìŠ¤ë ˆë“œ ID (ì´ì „ ëŒ€í™” ì´ì–´ê°€ê¸°ìš©, ì˜µì…˜)
 *
 * @returns {Promise<Object>} ì±—ë´‡ ì‘ë‹µ
 * @returns {string} return.response - AI ì‘ë‹µ ë©”ì‹œì§€
 * @returns {string} return.thread_id - ëŒ€í™” ìŠ¤ë ˆë“œ ID (ë‹¤ìŒ ìš”ì²­ì— ì‚¬ìš©)
 *
 * @example
 * // ì²« ëŒ€í™” ì‹œì‘
 * const result1 = await sendChatbotMessage({
 *   bot_type: "inbody-analyst",
 *   message: "ì²´ì§€ë°©ì„ ì¤„ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?",
 *   user_id: 1
 * });
 * console.log(result1.response);
 * console.log(result1.thread_id); // "chatbot_inbody-analyst_1_abc123"
 *
 * // ì´ì „ ëŒ€í™” ì´ì–´ì„œ í•˜ê¸°
 * const result2 = await sendChatbotMessage({
 *   bot_type: "inbody-analyst",
 *   message: "ìœ ì‚°ì†Œ ìš´ë™ì€ ì–¼ë§ˆë‚˜ í•´ì•¼ í•´?",
 *   thread_id: result1.thread_id // ì´ì „ ëŒ€í™” ID ì „ë‹¬
 * });
 * console.log(result2.response); // ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•˜ì—¬ ë‹µë³€
 */
export const sendChatbotMessage = async (data) => {
    return await apiRequest('/chatbot/chat', {
        method: 'POST',
        body: JSON.stringify(data),
    });
};
```

---

### 2. pages/Chatbot/Chatbot.jsx - API ì—°ê²°

**ì£¼ìš” ë³€ê²½ ì‚¬í•­**:

#### 1) Import ì¶”ê°€
```javascript
import { sendChatbotMessage } from '../../services/chatService';
```

#### 2) State ì¶”ê°€ (Thread ID ê´€ë¦¬)
```javascript
const [threadId, setThreadId] = useState(null); // LangGraph ëŒ€í™” ìŠ¤ë ˆë“œ ID
```

#### 3) handleSend í•¨ìˆ˜ ë³€ê²½ (Mock â†’ ì‹¤ì œ API)

**ë³€ê²½ ì „** (Mock ì‘ë‹µ):
```javascript
const handleSend = (e) => {
    e.preventDefault();
    if (!inputValue.trim()) return;

    const userMessage = {
        id: Date.now(),
        text: inputValue,
        sender: 'user'
    };

    setMessages(prev => [...prev, userMessage]);
    setInputValue('');
    setIsTyping(true);

    // ì‹œë®¬ë ˆì´ì…˜ëœ AI ì‘ë‹µ
    setTimeout(() => {
        const botMessage = {
            id: Date.now() + 1,
            text: getMockResponse(inputValue),
            sender: 'bot'
        };
        setMessages(prev => [...prev, botMessage]);
        setIsTyping(false);
    }, 1500);
};
```

**ë³€ê²½ í›„** (ì‹¤ì œ API í˜¸ì¶œ):
```javascript
const handleSend = async (e) => {
    e.preventDefault();
    if (!inputValue.trim()) return;

    const userMessage = {
        id: Date.now(),
        text: inputValue,
        sender: 'user'
    };

    setMessages(prev => [...prev, userMessage]);
    const currentInput = inputValue;
    setInputValue('');
    setIsTyping(true);

    try {
        // ë°±ì—”ë“œ LLM API í˜¸ì¶œ
        const result = await sendChatbotMessage({
            bot_type: botType,
            message: currentInput,
            thread_id: threadId, // ì´ì „ ëŒ€í™” ì´ë ¥ ì¶”ì 
            user_id: 1 // TODO: ì‹¤ì œ ì‚¬ìš©ì IDë¡œ ë³€ê²½ (ë¡œê·¸ì¸ êµ¬í˜„ í›„)
        });

        // Thread ID ì €ì¥ (ëŒ€í™” ì´ë ¥ ìœ ì§€)
        if (result.thread_id) {
            setThreadId(result.thread_id);
        }

        const botMessage = {
            id: Date.now() + 1,
            text: result.response,
            sender: 'bot'
        };
        setMessages(prev => [...prev, botMessage]);
    } catch (error) {
        console.error('ì±—ë´‡ ì‘ë‹µ ì˜¤ë¥˜:', error);
        // ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
        const errorMessage = {
            id: Date.now() + 1,
            text: "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            sender: 'bot'
        };
        setMessages(prev => [...prev, errorMessage]);
    } finally {
        setIsTyping(false);
    }
};
```

#### 4) BOT_CONFIG ê°„ì†Œí™” (responses ì œê±°)

Mock ì‘ë‹µ ë¡œì§ì„ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ BOT_CONFIGì—ì„œ `responses` í•„ë“œ ì œê±°:

```javascript
const BOT_CONFIG = {
    'inbody-analyst': {
        name: 'ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€',
        icon: 'ğŸ§‘â€âš•ï¸',
        greeting: "ì•ˆë…•í•˜ì„¸ìš”! ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì²´ì„±ë¶„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê±´ê°•í•œ ì‹ ì²´ë¥¼ ìœ„í•œ ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
        color: '#667eea',
        gradient: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)'
    },
    'workout-planner': {
        name: 'ìš´ë™ í”Œë˜ë„ˆ ì „ë¬¸ê°€',
        icon: 'ğŸ‹ï¸',
        greeting: "ì•ˆë…•í•˜ì„¸ìš”! ìš´ë™ í”Œë˜ë„ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ëª©í‘œì— ë§ëŠ” ìµœì ì˜ ìš´ë™ ë£¨í‹´ì„ ì œì•ˆí•˜ê³ , ì˜¬ë°”ë¥¸ ìì„¸ì™€ ë™ê¸°ë¶€ì—¬ë¥¼ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ìš´ë™ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
        color: '#f5576c',
        gradient: 'linear-gradient(135deg, #f093fb 0%, #f5576c 100%)'
    }
};
```

---

## ğŸ”„ API í”Œë¡œìš°

### 1ï¸âƒ£ í˜„ì¬ êµ¬í˜„ (Mock ì‘ë‹µ)

```
ì‚¬ìš©ì ì…ë ¥: "ì²´ì§€ë°©ì„ ì¤„ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?"
    â†“
Chatbot.jsx: sendChatbotMessage({
    bot_type: "inbody-analyst",
    message: "ì²´ì§€ë°©ì„ ì¤„ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?",
    user_id: 1,
    thread_id: null  // ì²« ëŒ€í™”ì´ë¯€ë¡œ null
})
    â†“
Backend /api/chatbot/chat
    â†“
LLMService.chatbot_conversation()
    - thread_id ìë™ ìƒì„±: "chatbot_inbody-analyst_1_abc123"
    - "ì²´ì§€ë°©" í‚¤ì›Œë“œ ê°ì§€
    - MOCK_RESPONSESì—ì„œ ë§¤ì¹­ë˜ëŠ” ì‘ë‹µ ë°˜í™˜
    â†“
ì‘ë‹µ ë°˜í™˜: {
    response: "ì²´ì§€ë°© ê°ì†Œë¥¼ ìœ„í•´ì„œëŠ” ìœ ì‚°ì†Œ ìš´ë™ê³¼ ê·¼ë ¥ ìš´ë™ì„ ë³‘í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤...",
    thread_id: "chatbot_inbody-analyst_1_abc123"
}
    â†“
Chatbot.jsx
    - threadId stateì— ì €ì¥
    - í™”ë©´ì— ì‘ë‹µ í‘œì‹œ
```

**í˜„ì¬ í•œê³„**:
- í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µë§Œ ì œê³µ
- ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•˜ì§€ ëª»í•¨ (thread_idëŠ” ìƒì„±ë˜ì§€ë§Œ í™œìš© ì•ˆ ë¨)

### 2ï¸âƒ£ í–¥í›„ ì‹¤ì œ LLM ì—°ê²° ì‹œ

```
ì‚¬ìš©ì ì…ë ¥: "ì²´ì§€ë°©ì„ ì¤„ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?"
    â†“
Chatbot.jsx: sendChatbotMessage({...})
    â†“
Backend /api/chatbot/chat
    â†“
LLMService.chatbot_conversation()
    - thread_id ìë™ ìƒì„±
    - OpenAI API í˜¸ì¶œ (ë˜ëŠ” ë‹¤ë¥¸ LLM)
    - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: "ë‹¹ì‹ ì€ ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤..."
    â†“
OpenAI GPT-4
    - ì‚¬ìš©ì ì§ˆë¬¸ ì´í•´
    - ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ë¡œ ì‘ë‹µ ìƒì„±
    â†“
ì‘ë‹µ ë°˜í™˜: {
    response: "ì²´ì§€ë°© ê°ì†Œë¥¼ ìœ„í•œ ë§ì¶¤í˜• ì¡°ì–¸...",
    thread_id: "chatbot_inbody-analyst_1_abc123"
}
```

**ì‹¤ì œ LLM ì‚¬ìš© ì‹œ ì¥ì **:
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°€ëŠ¥
- ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘
- ëŒ€í™” ë§¥ë½ ê¸°ì–µ (thread_id í™œìš©)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰
```bash
cd backend
uvicorn main:app --reload
```

### 2. API ë¬¸ì„œ í™•ì¸
```
http://localhost:8000/docs
```

**í™•ì¸ ì‚¬í•­**:
- `/api/chatbot/chat` ì—”ë“œí¬ì¸íŠ¸ê°€ ë³´ì´ëŠ”ì§€
- Request Body ìŠ¤í‚¤ë§ˆê°€ ì˜¬ë°”ë¥¸ì§€
- Try it outìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥

### 3. Swagger UI í…ŒìŠ¤íŠ¸

Request Body:
```json
{
  "bot_type": "inbody-analyst",
  "message": "ì²´ì§€ë°©ì„ ì¤„ì´ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•´?",
  "user_id": 1
}
```

Expected Response:
```json
{
  "response": "ì²´ì§€ë°© ê°ì†Œë¥¼ ìœ„í•´ì„œëŠ” ìœ ì‚°ì†Œ ìš´ë™ê³¼...",
  "thread_id": "chatbot_inbody-analyst_1_abc123"
}
```

### 4. í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸

```bash
cd frontend
npm run dev
```

**í™•ì¸ ì‚¬í•­**:
1. `/chatbot` í˜ì´ì§€ ì ‘ì†
2. ì±—ë´‡ ì„ íƒ (ì¸ë°”ë”” ë¶„ì„ ë˜ëŠ” ìš´ë™ í”Œë˜ë„ˆ)
3. ë©”ì‹œì§€ ì „ì†¡ â†’ AI ì‘ë‹µ í™•ì¸
4. ì—°ì† ëŒ€í™” â†’ ë§¥ë½ ìœ ì§€ í™•ì¸
5. ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ thread_id í™•ì¸

---

## ğŸ”§ ì‹¤ì œ LLM API ì—°ê²° ë°©ë²• (ë°±ì—”ë“œ ë‹´ë‹¹ììš©)

í˜„ì¬ëŠ” **í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ**ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ LLMì„ ì—°ê²°í•˜ë ¤ë©´ ì•„ë˜ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.

---

### ë°©ë²• 1: OpenAI API ì§ì ‘ ì—°ê²° (ì¶”ì²œ â­)

**ì¥ì **:
- ê°„ë‹¨í•œ êµ¬í˜„
- ë¹ ë¥¸ ì‘ë‹µ ì†ë„
- LangGraph ì—†ì´ë„ ëŒ€í™” ê°€ëŠ¥

**ë‹¨ì **:
- ëŒ€í™” ì´ë ¥ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•¨
- ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì–´ë ¤ì›€

#### 1ï¸âƒ£ ì‚¬ì „ ì¤€ë¹„ í™•ì¸

**OpenAI íŒ¨í‚¤ì§€**ëŠ” ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤ (`llm_clients.py`ì—ì„œ ì‚¬ìš© ì¤‘).

#### 2ï¸âƒ£ .env íŒŒì¼ì— API í‚¤ ì¶”ê°€

`backend/.env` íŒŒì¼ì— OpenAI API í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸:

```bash
OPENAI_API_KEY="sk-..."
```

ì—†ìœ¼ë©´ ì¶”ê°€í•˜ì„¸ìš”.

#### 3ï¸âƒ£ llm_service.py ìˆ˜ì •

í”„ë¡œì íŠ¸ì—ëŠ” ì´ë¯¸ `OpenAIClient` í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤ ([llm_clients.py](backend/services/llm/llm_clients.py:26-67)).
ì´ë¥¼ í™œìš©í•˜ì—¬ `chatbot_conversation()` ë©”ì„œë“œì˜ Mock ì‘ë‹µ ë¶€ë¶„ì„ ì•„ë˜ ì½”ë“œë¡œ êµì²´:

```python
async def chatbot_conversation(
    self,
    bot_type: str,
    user_message: str,
    thread_id: Optional[str] = None,
    user_id: Optional[int] = None
) -> Dict[str, Any]:
    """ì±—ë´‡ ëŒ€í™” ì²˜ë¦¬ (OpenAI API ì—°ê²°)"""

    # 1. Thread ID ìƒì„± ë˜ëŠ” ì¬ì‚¬ìš©
    if not thread_id:
        import uuid
        thread_id = f"chatbot_{bot_type}_{user_id or 'guest'}_{uuid.uuid4().hex[:8]}"

    # 2. ë´‡ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    SYSTEM_PROMPTS = {
        "inbody-analyst": """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì²´ì„±ë¶„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ê±´ê°•í•œ ì‹ ì²´ë¥¼ ìœ„í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.
        ì‹ë‹¨, ìš´ë™, ìƒí™œìŠµê´€ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
        ë‹µë³€ì€ ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”.""",

        "workout-planner": """ë‹¹ì‹ ì€ ì—´ì •ì ì´ê³  ì „ë¬¸ì ì¸ ìš´ë™ í”Œë˜ë„ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ëª©í‘œì™€ í˜„ì¬ ì²´ë ¥ ìˆ˜ì¤€ì— ë§ëŠ” ìµœì ì˜ ìš´ë™ ë£¨í‹´ì„ ì œì•ˆí•©ë‹ˆë‹¤.
        ì˜¬ë°”ë¥¸ ìì„¸, ìš´ë™ ë¹ˆë„, ê°•ë„ ì¡°ì ˆì— ëŒ€í•´ êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
        ë‹µë³€ì€ ë™ê¸°ë¶€ì—¬ê°€ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”."""
    }

    system_prompt = SYSTEM_PROMPTS.get(bot_type, SYSTEM_PROMPTS["inbody-analyst"])

    # 3. ê¸°ì¡´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (self.llm_clientëŠ” __init__ì—ì„œ ì´ë¯¸ ìƒì„±ë¨)
    try:
        # OpenAIClientì˜ generate_chat ë©”ì„œë“œ ì‚¬ìš©
        ai_response = self.llm_client.generate_chat(
            system_prompt=system_prompt,
            user_prompt=user_message
        )

        return {
            "response": ai_response,
            "thread_id": thread_id
        }

    except Exception as e:
        # ì˜¤ë¥˜ ì‹œ í´ë°± ì‘ë‹µ
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "thread_id": thread_id
        }
```

**ì„¤ëª…**:
- `self.llm_client`ëŠ” `LLMService.__init__()`ì—ì„œ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- `generate_chat()` ë©”ì„œë“œëŠ” [llm_clients.py:33-42](backend/services/llm/llm_clients.py:33-42)ì— êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- ì´ë¯¸ ìˆëŠ” í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¬ì‚¬ìš©í•˜ë¯€ë¡œ ì¶”ê°€ import ë¶ˆí•„ìš”

#### 4ï¸âƒ£ ëŒ€í™” ì´ë ¥ ì¶”ê°€ (ì„ íƒì‚¬í•­)

ìœ„ ì½”ë“œëŠ” **ë‹¨ë°œì„± ëŒ€í™”**ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ë ¤ë©´:

```python
# llm_service.pyì˜ __init__ì— ëŒ€í™” ì´ë ¥ ì €ì¥ì†Œ ì¶”ê°€
def __init__(self):
    self.model_version = "gpt-4o-mini"
    self.llm_client = create_llm_client(self.model_version)
    self.analysis_agent = create_analysis_agent(self.llm_client)

    # ëŒ€í™” ì´ë ¥ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬)
    self.conversation_history = {}  # {thread_id: [("user", "ë©”ì‹œì§€"), ("assistant", "ì‘ë‹µ")]}

async def chatbot_conversation(self, bot_type, user_message, thread_id=None, user_id=None):
    # ... (thread_id ìƒì„±, SYSTEM_PROMPTS ì½”ë“œ ë™ì¼)

    # ëŒ€í™” ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸°
    if thread_id not in self.conversation_history:
        self.conversation_history[thread_id] = []

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (íŠœí”Œ í˜•íƒœ: role, content)
    self.conversation_history[thread_id].append(("user", user_message))

    try:
        # OpenAIClientì˜ generate_chat_with_history ë©”ì„œë“œ ì‚¬ìš©
        ai_response = self.llm_client.generate_chat_with_history(
            system_prompt=SYSTEM_PROMPTS[bot_type],
            messages=self.conversation_history[thread_id]
        )

        # AI ì‘ë‹µ ì €ì¥
        self.conversation_history[thread_id].append(("assistant", ai_response))

        return {"response": ai_response, "thread_id": thread_id}

    except Exception as e:
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "thread_id": thread_id
        }
```

**ì„¤ëª…**:
- `generate_chat_with_history()` ë©”ì„œë“œëŠ” [llm_clients.py:44-58](backend/services/llm/llm_clients.py:44-58)ì— êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- ë©”ì‹œì§€ëŠ” `(role, content)` íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤
- í´ë¼ì´ì–¸íŠ¸ê°€ ìë™ìœ¼ë¡œ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤

**ì£¼ì˜ì‚¬í•­**:
- ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ì„œë²„ ì¬ì‹œì‘ ì‹œ ëŒ€í™” ì´ë ¥ ì†Œì‹¤
- í”„ë¡œë•ì…˜ì—ì„œëŠ” Redis ë˜ëŠ” PostgreSQLì— ì €ì¥ ê¶Œì¥ (ì•„ë˜ "í–¥í›„ ê°œì„  ì‚¬í•­" ì°¸ê³ )

---

### ë°©ë²• 2: LangGraph + OpenAI (ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ìš©)

**ì¥ì **:
- ë³µì¡í•œ ëŒ€í™” íë¦„ ê´€ë¦¬ ê°€ëŠ¥
- ëŒ€í™” ì´ë ¥ ìë™ ê´€ë¦¬
- ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—… ê°€ëŠ¥

**ë‹¨ì **:
- êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ
- ì¶”ê°€ í•™ìŠµ í•„ìš”

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**:
- ì±—ë´‡ì´ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ê±°ì³ ì‘ë‹µí•´ì•¼ í•  ë•Œ
- ì™¸ë¶€ API í˜¸ì¶œì´ í•„ìš”í•  ë•Œ (ì˜ˆ: ì¸ë°”ë”” ë°ì´í„° ì¡°íšŒ)
- ì—¬ëŸ¬ ì „ë¬¸ê°€ ë´‡ì´ í˜‘ì—…í•´ì•¼ í•  ë•Œ

(LangGraph êµ¬í˜„ì€ ë³µì¡í•˜ë¯€ë¡œ í•„ìš” ì‹œ ë³„ë„ ë¬¸ì„œ ì‘ì„±)

---

### ë°©ë²• 3: ë‹¤ë¥¸ LLM ì‚¬ìš© (Claude, Gemini ë“±)

OpenAI ëŒ€ì‹  ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•˜ë ¤ë©´:

**Anthropic Claude**:
```bash
pip install anthropic
```

```python
from anthropic import AsyncAnthropic

client = AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
response = await client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=500,
    system=system_prompt,
    messages=[{"role": "user", "content": user_message}]
)
ai_response = response.content[0].text
```

**Google Gemini**:
```bash
pip install google-generativeai
```

```python
import google.generativeai as genai

genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
model = genai.GenerativeModel("gemini-pro")
response = model.generate_content(user_message)
ai_response = response.text
```

---

### âš ï¸ ì£¼ì˜ì‚¬í•­

#### 1. API í‚¤ ë³´ì•ˆ
- `.env` íŒŒì¼ì— ì €ì¥ (ì ˆëŒ€ Gitì— ì»¤ë°‹ ê¸ˆì§€)
- `.gitignore`ì— `.env` ì¶”ê°€ í™•ì¸

#### 2. ë¹„ìš© ê´€ë¦¬
- OpenAI GPT-4o-mini: ì…ë ¥ $0.15/1M í† í°, ì¶œë ¥ $0.60/1M í† í°
- ëŒ€í™” ê¸¸ì´ ì œí•œ (max_tokens) ì„¤ì • ê¶Œì¥
- ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (OpenAI Dashboard)

#### 3. ì‚¬ìš©ì ì¸ì¦
í˜„ì¬ `user_id: 1` í•˜ë“œì½”ë”©ë¨.

**TODO**:
- JWT í† í°ì—ì„œ user_id ì¶”ì¶œ
- í”„ë¡ íŠ¸ì—”ë“œì—ì„œ localStorageì˜ ì‚¬ìš©ì ì •ë³´ í™œìš©

#### 4. Rate Limiting
- OpenAI APIì—ëŠ” ë¶„ë‹¹ ìš”ì²­ ì œí•œ ìˆìŒ
- í”„ë¡œë•ì…˜ì—ì„œëŠ” Rate Limiter ì¶”ê°€ ê¶Œì¥

---

## ğŸ“ í•™ìŠµ í¬ì¸íŠ¸

### 1. FastAPI ë¼ìš°í„° êµ¬ì¡°
```
routers/
â”œâ”€â”€ chatbot.py       # ì‹ ê·œ ë¼ìš°í„° (ì±—ë´‡ ì „ìš©)
â”œâ”€â”€ __init__.py      # Export ê´€ë¦¬
â””â”€â”€ llm/
    â”œâ”€â”€ analysis.py  # ê±´ê°• ë¶„ì„ ë¼ìš°í„°
    â””â”€â”€ ...

main.py â†’ app.include_router()ë¡œ ë“±ë¡
```

**í•µì‹¬ ê°œë…**:
- ê¸°ëŠ¥ë³„ ë¼ìš°í„° ë¶„ë¦¬ (chatbot, analysis, goals ë“±)
- `__init__.py`ì—ì„œ ì¤‘ì•™ ê´€ë¦¬
- `main.py`ì—ì„œ prefixë¡œ API ê²½ë¡œ êµ¬ì„±

### 2. Pydantic ìŠ¤í‚¤ë§ˆ (Request/Response)
```python
class ChatbotRequest(BaseModel):
    bot_type: str
    message: str
    user_id: Optional[int] = None
    thread_id: Optional[str] = None

class ChatbotResponse(BaseModel):
    response: str
    thread_id: str
```

**ì—­í• **:
- ë°ì´í„° ê²€ì¦ ìë™í™” (íƒ€ì…, í•„ìˆ˜ê°’ ì²´í¬)
- OpenAPI ë¬¸ì„œ ìë™ ìƒì„± (`/docs`)
- íƒ€ì… ì•ˆì „ì„± ë³´ì¥

### 3. Thread ID íŒ¨í„´
```python
# ë°±ì—”ë“œ: Thread ID ìƒì„±
thread_id = f"chatbot_{bot_type}_{user_id}_{uuid.uuid4().hex[:8]}"
# ì˜ˆ: "chatbot_inbody-analyst_1_a3b7c9d2"

# í”„ë¡ íŠ¸ì—”ë“œ: Thread ID ì €ì¥ ë° ì¬ì‚¬ìš©
const [threadId, setThreadId] = useState(null);
```

**ë™ì‘ ì›ë¦¬**:
- ì²« ëŒ€í™”: `thread_id=null` â†’ ë°±ì—”ë“œê°€ ìƒì„±í•˜ì—¬ ë°˜í™˜
- ì´ì–´ì„œ ëŒ€í™”: ë°›ì€ `thread_id` ì¬ì‚¬ìš© â†’ ëŒ€í™” ì´ë ¥ ìœ ì§€
- ì‹¤ì œ LLM ì—°ê²° ì‹œ ì´ IDë¡œ ëŒ€í™” ë§¥ë½ ì¶”ì 

### 4. React Async ìƒíƒœ ê´€ë¦¬
```javascript
const handleSend = async (e) => {
    e.preventDefault();
    setIsTyping(true); // ë¡œë”© ìƒíƒœ

    try {
        const result = await sendChatbotMessage({...});
        // ì„±ê³µ ì²˜ë¦¬
    } catch (error) {
        // ì—ëŸ¬ ì²˜ë¦¬ (í´ë°± ë©”ì‹œì§€ í‘œì‹œ)
    } finally {
        setIsTyping(false); // ë¡œë”© í•´ì œ
    }
};
```

**í•µì‹¬ íŒ¨í„´**:
- `async/await`ë¡œ ë¹„ë™ê¸° API í˜¸ì¶œ
- `try-catch-finally`ë¡œ ì—ëŸ¬ ì²˜ë¦¬
- ë¡œë”© ìƒíƒœ ê´€ë¦¬ (`isTyping`)

### 5. í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ë§¤ì¹­ (í˜„ì¬ êµ¬í˜„)
```python
MOCK_RESPONSES = {
    "inbody-analyst": {
        "keywords": {"ì²´ì§€ë°©": "...", "ê·¼ìœ¡": "..."},
        "default": "ê¸°ë³¸ ì‘ë‹µ"
    }
}

# í‚¤ì›Œë“œ ë§¤ì¹­
for keyword, response in keywords.items():
    if keyword in user_message:
        return response
```

**í•œê³„**:
- ë‹¨ìˆœ ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ë§Œ í™•ì¸
- ëŒ€í™” ë§¥ë½ ì´í•´ ë¶ˆê°€
- ì‹¤ì œ LLMìœ¼ë¡œ êµì²´ ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°€ëŠ¥

---

## ğŸ”® í–¥í›„ ê°œì„  ì‚¬í•­

### 1ë‹¨ê³„: Mock â†’ ì‹¤ì œ LLM ì—°ê²° (ìš°ì„ ìˆœìœ„ â­â­â­)
- **í˜„ì¬**: í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ
- **ëª©í‘œ**: OpenAI API ì§ì ‘ ì—°ê²°
- **ì‘ì—…**: ìœ„ì˜ "ë°©ë²• 1: OpenAI API ì§ì ‘ ì—°ê²°" ì°¸ê³ 

### 2ë‹¨ê³„: ëŒ€í™” ì´ë ¥ ì €ì¥ (ìš°ì„ ìˆœìœ„ â­â­)
**í˜„ì¬ ìƒíƒœ**:
- Thread IDëŠ” ìƒì„±ë˜ì§€ë§Œ ëŒ€í™” ì´ë ¥ ë¯¸ì €ì¥
- ë©”ëª¨ë¦¬ ê¸°ë°˜ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ì†Œì‹¤)

**ê°œì„  ë°©ì•ˆ**:
```python
# Redis ì‚¬ìš© ì˜ˆì‹œ
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

# ëŒ€í™” ì €ì¥
redis_client.setex(
    f"chat_history:{thread_id}",
    3600,  # 1ì‹œê°„ TTL
    json.dumps(messages)
)

# ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
history = redis_client.get(f"chat_history:{thread_id}")
messages = json.loads(history) if history else []
```

**ë˜ëŠ” PostgreSQL ì €ì¥**:
```sql
CREATE TABLE chat_history (
    id SERIAL PRIMARY KEY,
    thread_id VARCHAR(100),
    role VARCHAR(20),  -- 'user' ë˜ëŠ” 'assistant'
    content TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 3ë‹¨ê³„: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ìš°ì„ ìˆœìœ„ â­)
**í˜„ì¬**: ì „ì²´ ì‘ë‹µ ìƒì„± í›„ í•œ ë²ˆì— ë°˜í™˜
**ëª©í‘œ**: ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼

```python
# ë°±ì—”ë“œ: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
from fastapi.responses import StreamingResponse

async def chatbot_conversation_stream(...):
    async for chunk in client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        stream=True
    ):
        yield chunk.choices[0].delta.content or ""

@router.post("/chat/stream")
async def chat_stream(request: ChatbotRequest):
    return StreamingResponse(
        chatbot_conversation_stream(...),
        media_type="text/event-stream"
    )
```

```javascript
// í”„ë¡ íŠ¸ì—”ë“œ: ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì‹ 
const response = await fetch('/api/chatbot/chat/stream', {...});
const reader = response.body.getReader();

while (true) {
    const {done, value} = await reader.read();
    if (done) break;

    const text = new TextDecoder().decode(value);
    // ì‹¤ì‹œê°„ìœ¼ë¡œ ë©”ì‹œì§€ì— ì¶”ê°€
    setMessages(prev => [...prev.slice(0, -1), {
        ...prev[prev.length - 1],
        text: prev[prev.length - 1].text + text
    }]);
}
```

### 4ë‹¨ê³„: ì¸ë°”ë”” ë°ì´í„° ì—°ë™
ì±—ë´‡ì´ ì‚¬ìš©ìì˜ ì‹¤ì œ ì¸ë°”ë”” ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€:

```python
# ì‚¬ìš©ìì˜ ìµœê·¼ ì¸ë°”ë”” ë°ì´í„° ì¡°íšŒ
from models import HealthRecord

record = db.query(HealthRecord).filter_by(user_id=user_id).order_by(
    HealthRecord.measured_at.desc()
).first()

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë°ì´í„° í¬í•¨
system_prompt = f"""ë‹¹ì‹ ì€ ì¸ë°”ë”” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í˜„ì¬ ì‚¬ìš©ì ì •ë³´:
- ì²´ì¤‘: {record.body_weight}kg
- ê³¨ê²©ê·¼ëŸ‰: {record.skeletal_muscle_mass}kg
- ì²´ì§€ë°©ë¥ : {record.body_fat_percentage}%
...
ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."""
```

### 5ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ (ì´ë¯¸ì§€ ì—…ë¡œë“œ)
ìš´ë™ ìì„¸ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì—¬ í”¼ë“œë°± ë°›ê¸°:

```python
class ChatbotRequest(BaseModel):
    message: str
    image: Optional[str] = None  # Base64 ì´ë¯¸ì§€

# GPT-4o-vision ì‚¬ìš©
response = await client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "user", "content": [
            {"type": "text", "text": "ì´ ìš´ë™ ìì„¸ê°€ ë§ë‚˜ìš”?"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image}"}}
        ]}
    ]
)
```

### 6ë‹¨ê³„: ìŒì„± ì…ë ¥/ì¶œë ¥
- **ì…ë ¥**: Web Speech API (ìŒì„± â†’ í…ìŠ¤íŠ¸)
- **ì¶œë ¥**: Text-to-Speech (AI ì‘ë‹µ ì½ì–´ì£¼ê¸°)

```javascript
// Web Speech API
const recognition = new webkitSpeechRecognition();
recognition.onresult = (event) => {
    const text = event.results[0][0].transcript;
    setInputValue(text);
};
```

---

## ğŸ“ ë¬¸ì˜ ì‚¬í•­

ë°±ì—”ë“œ ë‹´ë‹¹ìê°€ êµ¬í˜„ ì¤‘ ê¶ê¸ˆí•œ ì‚¬í•­:
1. LangGraph ì—ì´ì „íŠ¸ ì„¤ì •
2. Thread ID ì˜êµ¬ ì €ì¥ ë°©ë²•
3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŠœë‹

â†’ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìì—ê²Œ ë¬¸ì˜

---

**ì‘ì„±ì**: Claude Code
**ì‘ì„±ì¼**: 2026-01-30
**ìµœì¢… ìˆ˜ì •**: 2026-01-30
**ìƒíƒœ**: âœ… ì„ì‹œ êµ¬í˜„ ì™„ë£Œ (Mock ì‘ë‹µ)
**ë‹¤ìŒ ë‹¨ê³„**: ë°±ì—”ë“œ ë‹´ë‹¹ìê°€ OpenAI API ì—°ê²° (ìœ„ ê°€ì´ë“œ ì°¸ê³ )
