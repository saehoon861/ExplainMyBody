#!/usr/bin/env python3
"""
ExplainMyBody - í†µí•© ì›Œí¬í”Œë¡œìš° ë©”ì¸ ì‹¤í–‰ íŒŒì¼
íšŒì›ê°€ì…/ë¡œê·¸ì¸ -> OCR ì¶”ì¶œ -> Stage ê³„ì‚° -> DB ì €ì¥ -> LLM ë¦¬í¬íŠ¸ ìƒì„±
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

from database import Database
from workflow import InBodyAnalysisWorkflow, UserAuthManager
from claude_client import ClaudeClient
from openai_client import OpenAIClient
from ollama_client import OllamaClient

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def load_sample_profiles(path="sample_profiles.json"):
    """ìƒ˜í”Œ í”„ë¡œí•„ ë¡œë“œ"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def display_report(db: Database, report_id: int):
    """ë¦¬í¬íŠ¸ ì¶œë ¥"""
    report = db.get_analysis_report(report_id)
    if not report:
        print("ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n" + "=" * 60)
    print("ğŸ“‹ LLM ë¶„ì„ ë¦¬í¬íŠ¸")
    print("=" * 60)
    print(f"Model: {report['model_version']}")
    print(f"Generated at: {report['generated_at']}")
    print("-" * 60)
    print(report['llm_output'])
    print("=" * 60)


def save_report_to_file(db: Database, report_id: int, output_dir: str = "outputs"):
    """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    report = db.get_analysis_report(report_id)
    if not report:
        print("ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    # health_record ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    record = db.get_health_record(report['record_id'])
    username = record['measurements'].get('ì„±ë³„', 'user')
    
    # generated_atì´ datetime ê°ì²´ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
    generated_at = report['generated_at']
    if isinstance(generated_at, datetime):
        timestamp = generated_at.strftime('%Y-%m-%d_%H-%M-%S')
        generated_at_str = generated_at.strftime('%Y-%m-%d %H:%M:%S')
    else:
        timestamp = str(generated_at).replace(':', '').replace(' ', '_')
        generated_at_str = str(generated_at)

    filename = f"report_{report_id}_{timestamp}.txt"
    filepath = output_path / filename

    with open(filepath, "w", encoding="utf-8") as f:
        f.write("=" * 60 + "\n")
        f.write("ExplainMyBody ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"Report ID: {report_id}\n")
        f.write(f"Model: {report['model_version']}\n")
        f.write(f"Generated at: {generated_at_str}\n\n")
        f.write("-" * 60 + "\n\n")
        f.write(report['llm_output'])
        f.write("\n\n" + "=" * 60 + "\n")

    print(f"\nğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filepath}")
    return filepath


def main():
    parser = argparse.ArgumentParser(description="ExplainMyBody í†µí•© ì›Œí¬í”Œë¡œìš°")

    # ì‚¬ìš©ì ì •ë³´
    parser.add_argument("--username", type=str, help="ì‚¬ìš©ìëª…")
    parser.add_argument("--email", type=str, help="ì´ë©”ì¼")

    # í”„ë¡œí•„ ì„ íƒ
    parser.add_argument("--profile-id", type=int, help="Sample profile ID (1-10)")

    # LLM ëª¨ë¸ ì„ íƒ
    parser.add_argument(
        "--model",
        default="gpt-4.1",
        help="Model name (ollama: qwen3:14b, claude: claude-3-5-sonnet-20241022, openai: gpt-4o-mini)"
    )

    # ê¸°íƒ€ ì˜µì…˜
    parser.add_argument("--output-dir", default="outputs", help="Output directory")
    parser.add_argument("--db-url", default=None, help="Database connection URL (PostgreSQL)")
    parser.add_argument("--list-profiles", action="store_true", help="List available profiles")
    parser.add_argument("--list-users", action="store_true", help="List registered users")

    args = parser.parse_args()

    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    db = Database(args.db_url)
    db_info = args.db_url if args.db_url else "í™˜ê²½ë³€ìˆ˜ DATABASE_URL"
    print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {db_info}")

    # ì‚¬ìš©ì ëª©ë¡ ì¶œë ¥
    if args.list_users:
        print("\n=== ë“±ë¡ëœ ì‚¬ìš©ì ëª©ë¡ ===")
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT id, username, email, created_at FROM users")
            users = cursor.fetchall()
            if users:
                for user in users:
                    print(f"  [{user['id']}] {user['username']} ({user['email']}) - {user['created_at']}")
            else:
                print("  ë“±ë¡ëœ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í”„ë¡œí•„ ëª©ë¡ ì¶œë ¥
    profiles = load_sample_profiles()
    if args.list_profiles:
        print("\n=== ìƒ˜í”Œ í”„ë¡œí•„ ëª©ë¡ ===")
        for profile in profiles:
            pid = profile.get("id", 0)
            name = profile.get("name", "")
            desc = profile.get("description", "")
            print(f"  [{pid}] {name} - {desc}")
        return

    # ì‚¬ìš©ì ì •ë³´ í™•ì¸
    if not args.username or not args.email:
        print("ì˜¤ë¥˜: --usernameê³¼ --emailì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        print("\nì‚¬ìš© ì˜ˆì‹œ:")
        print("  python main_workflow.py --username 'í™ê¸¸ë™' --email 'hong@example.com' --profile-id 1")
        sys.exit(1)

    # í”„ë¡œí•„ ID í™•ì¸
    if not args.profile_id:
        print("ì˜¤ë¥˜: --profile-idë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œí•„:")
        for p in profiles:
            print(f"  [{p['id']}] {p['name']} - {p['description']}")
        sys.exit(1)

    # ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    if args.model.startswith("claude-"):
        client = ClaudeClient(model=args.model)
        print(f"ğŸ¤– LLM: Claude ({args.model})")
    elif args.model.startswith("gpt-"):
        client = OpenAIClient(model=args.model)
        print(f"ğŸ¤– LLM: OpenAI ({args.model})")
    else:
        client = OllamaClient(model=args.model)
        if not client.check_connection():
            print("ì˜¤ë¥˜: Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‹¤í–‰: ollama serve")
            sys.exit(1)
        print(f"ğŸ¤– LLM: Ollama ({args.model})")

    # API ì—°ê²° í™•ì¸
    if args.model.startswith("claude-") or args.model.startswith("gpt-"):
        try:
            if not client.check_connection():
                provider = "Claude" if args.model.startswith("claude-") else "OpenAI"
                print(f"ì˜¤ë¥˜: {provider} APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("API í‚¤ë¥¼ .env íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                sys.exit(1)
            print("âœ… API ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
            sys.exit(1)

    # íšŒì›ê°€ì… / ë¡œê·¸ì¸
    auth_manager = UserAuthManager(db)
    user = auth_manager.register_or_login(args.username, args.email)
    user_id = user['id']

    # í”„ë¡œí•„ ì„ íƒ
    profile = next((p for p in profiles if p.get("id") == args.profile_id), None)
    if not profile:
        print(f"ì˜¤ë¥˜: Profile ID {args.profile_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    print(f"\nğŸ“Š ì„ íƒëœ í”„ë¡œí•„: {profile['name']} ({profile['description']})")

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    workflow = InBodyAnalysisWorkflow(
        db=db,
        llm_client=client,
        model_version=args.model
    )

    try:
        result = workflow.run_full_workflow(
            user_id=user_id,
            sample_profile=profile,
            source="sample_profile"
        )

        record_id = result['record_id']
        report_id = result['report_id']

        # ë¦¬í¬íŠ¸ ì¶œë ¥
        display_report(db, report_id)

        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        save_report_to_file(db, report_id, args.output_dir)

        print(f"\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"  - User ID: {user_id}")
        print(f"  - Health Record ID: {record_id}")
        print(f"  - Analysis Report ID: {report_id}")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
