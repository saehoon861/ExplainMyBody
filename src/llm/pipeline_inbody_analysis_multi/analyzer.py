"""
ì¸ë°”ë”” ë¶„ì„ ë¡œì§
"""

from typing import Dict, Any

from shared.models import InBodyMeasurements
from shared.llm_clients import BaseLLMClient
from shared.database import Database
from pipeline_inbody_analysis_multi.prompt_generator import create_multi_part_prompts


class InBodyAnalyzer:
    """ì¸ë°”ë”” ë¶„ì„ê¸°"""

    def __init__(self, db: Database, llm_client: BaseLLMClient, model_version: str):
        """
        Args:
            db: Database ì¸ìŠ¤í„´ìŠ¤
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
            model_version: ëª¨ë¸ ë²„ì „
        """
        self.db = db
        self.llm_client = llm_client
        self.model_version = model_version

    def analyze(
        self,
        user_id: int,
        measurements: InBodyMeasurements,
        source: str = "manual",
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ì¸ë°”ë”” ë¶„ì„ ìˆ˜í–‰

        Args:
            user_id: ì‚¬ìš©ì ID
            measurements: InBody ì¸¡ì • ë°ì´í„°
            source: ë°ì´í„° ì†ŒìŠ¤

        Returns:
            {
                "record_id": int,
                "analysis_id": int,
                "analysis_text": str,
                "embedding": List[float] (optional)
            }
        """
        # ì¶œë ¥ ë©”ì‹œì§€ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸
        output_lines = []
        
        def print_and_capture(*args, **kwargs):
            """print ì¶œë ¥ì„ ìº¡ì²˜í•˜ë©´ì„œ ë™ì‹œì— ì½˜ì†”ì—ë„ ì¶œë ¥"""
            message = ' '.join(str(arg) for arg in args)
            output_lines.append(message)
            print(*args, **kwargs)
        
        print_and_capture("=" * 60)
        print_and_capture(f"InBody ë¶„ì„ ì‹œì‘ (User ID: {user_id})")
        print_and_capture("=" * 60)

        # 1ë‹¨ê³„: ì²´í˜• ì •ë³´ í™•ì¸
        print_and_capture("\nğŸ“Š 1ë‹¨ê³„: ì²´í˜• ì •ë³´ í™•ì¸...")
        if measurements.body_type1:
            print_and_capture(f"  âœ“ Body Type 1: {measurements.body_type1}")
        if measurements.body_type2:
            print_and_capture(f"  âœ“ Body Type 2: {measurements.body_type2}")
        if not measurements.body_type1 and not measurements.body_type2:
            print_and_capture("  âš ï¸  ì²´í˜• ì •ë³´ ì—†ìŒ (body_type1, body_type2 ë¯¸ì…ë ¥)")

        # 2ë‹¨ê³„: health_recordsì— ì €ì¥
        print_and_capture("\nğŸ’¾ 2ë‹¨ê³„: ì¸¡ì • ë°ì´í„° ì €ì¥...")
        m = measurements.model_dump()
        record_id = self.db.save_health_record(
            user_id=user_id,
            measurements=m,
            source=source,
        )
        print_and_capture(f"  âœ“ Record ID: {record_id}")

        # 3ë‹¨ê³„: LLM ë¶„ì„ (3íšŒ í˜¸ì¶œ)
        print_and_capture("\nğŸ¤– 3ë‹¨ê³„: LLM ë¶„ì„ ìƒì„± (3-part ë¶„í• )...")
        prompts = create_multi_part_prompts(measurements)

        analysis_parts = []
        part_names = ["ê¸°ë³¸ ì²´ì„±ë¶„ ë¶„ì„", "ë¶€ìœ„ë³„ ë¶ˆê· í˜• ë¶„ì„", "ê°œì„  ê³¼ì œ ë° ì¢…í•© í‰ê°€"]

        for i, (system_prompt, user_prompt) in enumerate(prompts, 1):
            print_and_capture(f"  - Part {i}/3: {part_names[i-1]} LLM í˜¸ì¶œ ì¤‘...")
            part_text = self.llm_client.generate_chat(system_prompt, user_prompt)
            analysis_parts.append(part_text)
            print_and_capture(f"  âœ“ Part {i} ì™„ë£Œ ({len(part_text)} ê¸€ì)")

        # 3ê°œ íŒŒíŠ¸ë¥¼ í•˜ë‚˜ë¡œ ê²°í•©
        print_and_capture("\n  - 3ê°œ íŒŒíŠ¸ ê²°í•© ì¤‘...")
        analysis_text = "\n\n" + ("=" * 80 + "\n\n").join(analysis_parts)
        print_and_capture(f"  âœ“ ì „ì²´ ë¶„ì„ ì™„ë£Œ ({len(analysis_text)} ê¸€ì)")

        # 4ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ì €ì¥
        print_and_capture("\nğŸ’¾ 4ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ì €ì¥...")
        analysis_id = self.db.save_analysis_report(
            user_id=user_id,
            record_id=record_id,
            llm_output=analysis_text,
            model_version=self.model_version,
        )
        print_and_capture(f"  âœ“ Analysis ID: {analysis_id}")

        # 5ë‹¨ê³„: 2ì°¨ LLM ì •ì œ (ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½)
        print_and_capture("\nâœ¨ 5ë‹¨ê³„: ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½ ìƒì„±...")
        refined_system_prompt = """ë‹¹ì‹ ì€ ì˜ë£Œ ë¦¬í¬íŠ¸ í¸ì§‘ìì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì¸ë°”ë”” ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì¼ë°˜ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•˜ê³  ì •ì œí•´ì£¼ì„¸ìš”.

## ëª©í‘œ
- ì „ë¬¸ ìš©ì–´ë¥¼ ì‰¬ìš´ ë§ë¡œ í’€ì–´ì“°ê¸°
- í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½
- ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„±
- ê¸ì •ì ì´ê³  ë™ê¸°ë¶€ì—¬ê°€ ë˜ëŠ” í†¤

## ì¶œë ¥ í˜•ì‹
### ğŸ“Š í˜„ì¬ ìƒíƒœ í•œëˆˆì— ë³´ê¸°
(ì²´í˜•, ì²´ì§€ë°©, ê·¼ìœ¡ëŸ‰ í•µì‹¬ 3ì¤„ ìš”ì•½)

### ğŸ’ª ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„
(ìš°ì„ ìˆœìœ„ 1-3ê°€ì§€, ê° 1-2ë¬¸ì¥)

### ğŸ¯ ì‹¤ì²œ ê°€ì´ë“œ
(êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ë°©í–¥ 3-5ê°€ì§€)

### âœ… í˜„ì¬ ì˜í•˜ê³  ìˆëŠ” ë¶€ë¶„
(ê¸ì •ì  í”¼ë“œë°± 2-3ê°€ì§€)

ì „ë¬¸ì ì´ì§€ë§Œ ì¹œê·¼í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        refined_user_prompt = f"""ë‹¤ìŒ ì¸ë°”ë”” ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{analysis_text}"""

        print_and_capture("  - 2ì°¨ LLM í˜¸ì¶œ ì¤‘...")
        refined_text = self.llm_client.generate_chat(
            refined_system_prompt, refined_user_prompt
        )
        print_and_capture(f"  âœ“ ìš”ì•½ ì™„ë£Œ ({len(refined_text)} ê¸€ì)")

        # 6ë‹¨ê³„: ì •ì œëœ ê²°ê³¼ DB ì—…ë°ì´íŠ¸
        print_and_capture("\nğŸ’¾ 6ë‹¨ê³„: ì •ì œëœ ìš”ì•½ ì €ì¥...")
        self.db.update_analysis_refined_output(analysis_id, refined_text)
        print_and_capture(f"  âœ“ Refined output ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        print_and_capture("\n" + "=" * 60)
        print_and_capture("âœ¨ InBody ë¶„ì„ ì™„ë£Œ!")
        print_and_capture("=" * 60)

        # ì „ì²´ ì¶œë ¥ ë©”ì‹œì§€ì™€ LLM ë¶„ì„ ê²°ê³¼ë¥¼ ê²°í•©
        full_output = '\n'.join(output_lines) + '\n\n' + '=' * 60 + '\n'
        full_output += 'ğŸ“‹ LLM ë¶„ì„ ë¦¬í¬íŠ¸\n'
        full_output += '=' * 60 + '\n\n'
        full_output += analysis_text

        return {
            "record_id": record_id,
            "analysis_id": analysis_id,
            "analysis_text": full_output,
            "refined_text": refined_text,
        }
