# rule_based_prompts â†’ LangGraph í†µí•© ì„¤ê³„ë¬¸ì„œ

ì‘ì„±ì¼: 2026-02-05
ëŒ€ìƒ ê·¸ë˜í”„: `backend/services/llm/llm_rag/weekly_plan_graph_rag.py`
í†µí•©í•  í”„ë¡¬í”„íŠ¸: `src/llm/llm_prompt_test_sk/rule_based_prompts.py`

---

## 1. ê¸°ì¡´ LangGraph êµ¬ì¡°

### 1.1 íŒŒì¼ êµ¬ì„±

```
backend/services/llm/
â”œâ”€â”€ llm_clients.py                  # OpenAI í´ë¼ì´ì–¸íŠ¸ (í˜„ì¬ sync only)
â”œâ”€â”€ agent_graph.py                  # LLM1 ê·¸ë˜í”„ (ë¹„RAG)
â”œâ”€â”€ weekly_plan_graph.py            # LLM2 ê·¸ë˜í”„ (ë¹„RAG)
â”œâ”€â”€ llm_service.py                  # ì„œë¹„ìŠ¤ ë ˆì´ì–´ (ë¹„RAG)
â”œâ”€â”€ human_feedback.py               # HumanFeedback ORM
â”œâ”€â”€ llm_interaction.py              # LLMInteraction ORM
â””â”€â”€ llm_rag/                        # â† í˜„ì¬ ì‚¬ìš©ì¤‘ (RAG ë²„ì „)
    â”œâ”€â”€ agent_graph_rag.py          # LLM1 ê·¸ë˜í”„
    â”œâ”€â”€ weekly_plan_graph_rag.py    # LLM2 ê·¸ë˜í”„  â† í†µí•© ëŒ€ìƒ
    â”œâ”€â”€ llm_service_rag.py          # ì„œë¹„ìŠ¤ ë ˆì´ì–´
    â”œâ”€â”€ rag_retriever.py            # pgvector ê²€ìƒ‰
    â”œâ”€â”€ prompt_generator_rag.py     # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ìƒì„±
    â””â”€â”€ weekly_plan_service_rag.py  # ì£¼ê°„ ê³„íš ì„œë¹„ìŠ¤
```

### 1.2 ê³µí†µ ê·¸ë˜í”„ íŒ¨í„´

ë‘ ê·¸ë˜í”„(LLM1, LLM2) ëª¨ë‘ ë™ì¼í•œ êµ¬ì¡°:

```
[START]
  â†“
[initial_*]  â”€â”€â†’ interrupt_after â”€â”€â†’ í”„ë¡ íŠ¸ì—ì„œ ê²°ê³¼ í‘œì‹œ
  â†“                                        â†“ ì‚¬ìš©ì ì…ë ¥
  â†“  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ invoke(messages: [user_msg]) â†â”€â”€
  â†“
route_qa()  (ì‚¬ìš©ì ì…ë ¥ ì²« ìˆ«ìë¡œ ì¹´í…Œê³ ë¦¬ íŒë‹¨)
  â†“
[qa_*]      â”€â”€â†’ interrupt_after â”€â”€â†’ í”„ë¡ íŠ¸ì—ì„œ ê²°ê³¼ í‘œì‹œ
  â†“                                        â†“ (ë£¨í”„)
  â†“  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
[finalize_*] â”€â”€â†’ [END]
```

êµ¬ì„± ìš”ì†Œ:
- **State**: `TypedDict` + `messages: Annotated[list, add_messages]` (ë¦¬ë“€ì„œë¡œ ëŒ€í™” ê¸°ë¡ ìë™ ëˆ„ì )
- **Checkpointer**: `MemorySaver()` â€” `thread_id`ë¡œ ì„¸ì…˜ ë‹¨ìœ„ ìƒíƒœ ì €ì¥
- **interrupt_after**: ì§€ì •ëœ ë…¸ë“œ ì‹¤í–‰ í›„ ìë™ ì¤‘ë‹¨ â†’ ì™¸ë¶€ì—ì„œ `invoke()` ì¬í˜¸ì¶œë¡œ ì¬ê°œ
- **route_qa**: conditional edge ë¼ìš°íŒ… í•¨ìˆ˜

### 1.3 LLM1 ê·¸ë˜í”„ (agent_graph_rag.py)

```
State: AnalysisStateRAG
  â”œâ”€ analysis_input: StatusAnalysisInput
  â”œâ”€ messages: Annotated[list, add_messages]
  â”œâ”€ embedding: Optional[Dict]        â† ë¶„ì„ ê²°ê³¼ì˜ ì„ë² ë”© ë²¡í„°
  â””â”€ rag_context: Optional[str]

Nodes:
  initial_analysis       RAG ê²€ìƒ‰ + LLM 1íšŒ + ì„ë² ë”© ìƒì„±
  qa_strength_weakness   ê°•ì /ì•½ì  ë¶„ì„ Q&A
  qa_health_status       ê±´ê°• ìƒíƒœ Q&A
  qa_impact              ì¼ìƒ/ìš´ë™ ì˜í–¥ Q&A
  qa_priority            ê°œì„  ìš°ì„ ìˆœìœ„ Q&A
  qa_general             ê¸°íƒ€ Q&A
  finalize_analysis  â†’   END
```

### 1.4 LLM2 ê·¸ë˜í”„ (weekly_plan_graph_rag.py) â€” í†µí•© ëŒ€ìƒ

```
State: PlanStateRAG
  â”œâ”€ plan_input: GoalPlanInput
  â”œâ”€ messages: Annotated[list, add_messages]
  â””â”€ rag_context: Optional[str]

Nodes:
  initial_plan           RAG ê²€ìƒ‰ + LLM 1íšŒ (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ì „ì²´ ê³„íš ìƒì„±)
  qa_exercise_guide      ìš´ë™ ë°©ë²• ê°€ì´ë“œ Q&A
  qa_plan_adjustment     ìš´ë™ í”Œëœ ì¡°ì • Q&A
  qa_diet_adjustment     ì‹ë‹¨ ì¡°ì • Q&A
  qa_intensity_adjustment ê°•ë„ ì¡°ì • Q&A
  qa_general             ê¸°íƒ€ Q&A
  finalize_plan      â†’   END
```

í˜„ì¬ `initial_plan`ì˜ ë‚´ë¶€ íë¦„ (weekly_plan_graph_rag.py:52~96):
```
1. InBodyMeasurements ëª¨ë¸ ë³€í™˜
2. RAG ê²€ìƒ‰ (_generate_rag_query_from_goal â†’ pgvector)
3. create_weekly_plan_prompt_with_rag() â†’ (system, user)
4. llm_client.generate_chat(system, user)    â† ë‹¨ì¼ sync í˜¸ì¶œ
5. return {messages, rag_context}
```

### 1.5 Human Feedback ë£¨í”„ â€” ì„¸ë¶€ íë¦„

```
â‘  llm_service_rag.py: call_goal_plan_llm(plan_input)
     â†“
â‘¡ thread_id ìƒì„± ("plan_rag_{user_id}_{record_id}_{ts}")
     â†“
â‘¢ weekly_plan_agent.invoke(
       {plan_input, messages: [], rag_context: None},
       config={thread_id}
   )
     â†“
â‘£ initial_plan ì‹¤í–‰ â†’ interrupt_afterì— ì˜í•´ ì¤‘ë‹¨
     â†“ ë°˜í™˜ê°’
â‘¤ í”„ë¡ íŠ¸ì—”ë“œì— plan_text í‘œì‹œ, thread_id ì €ì¥
     â†“ ì‚¬ìš©ìê°€ ì§ˆë¬¸/ìˆ˜ì • ìš”ì²­
â‘¥ llm_service_rag.py: chat_with_plan(thread_id, user_message)
     â†“
â‘¦ weekly_plan_agent.invoke(
       {messages: [("human", user_message)]},
       config={thread_id}            â† ë™ì¼ threadë¡œ ìƒíƒœ ë³µì›
   )
     â†“
â‘§ route_qa() â†’ Q&A ë…¸ë“œ ì‹¤í–‰ â†’ interrupt (ë£¨í”„ â†’ â‘¤)
     â†“ "5" ì…ë ¥ ì‹œ
â‘¨ finalize_plan â†’ END
```

**í•µì‹¬**: `invoke()` ì¬í˜¸ì¶œ ì‹œ `thread_id`ë¥¼ í†µí•´ ì´ì „ ìƒíƒœ(messages ì „ì²´)ê°€ ë³µì›ë¨.
Q&A ë…¸ë“œëŠ” `state["messages"]` ì „ì²´ë¥¼ íˆìŠ¤í† ë¦¬ë¡œ LLMì— ì „ë‹¬í•˜ë¯€ë¡œ,
`initial_plan`ì—ì„œ ìƒì„±ëœ ê³„íš í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¡œ ê°€ì§‘ë‹ˆë‹¤.

---

## 2. í˜„ì¬ initial_planì˜ ë¬¸ì œì 

| ë¬¸ì œ | ì›ì¸ |
|------|------|
| ë‹¨ì¼ ì‹¤íŒ¨ì  | LLM 1íšŒ í˜¸ì¶œë¡œ ìš´ë™Â·ì‹ë‹¨Â·ìƒí™œìŠµê´€ ì „ë¶€ ìƒì„± â€” í•˜ë‚˜ë¼ë„ ë¶€ì í•©í•˜ë©´ ì „ì²´ ì¬ìƒì„± |
| ì‘ë‹µ ë¶ˆê· í˜• | ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ì—ì„œ ì—¬ëŸ¬ ì„¹ì…˜ì„ ìƒì„±í•˜ë©´ ì¼ë¶€ ì„¹ì…˜ì´ ì§§ê±°ë‚˜ ì–•ì•„ì§ |
| ë£° ë¯¸ì ìš© | `rule_based_prompts`ì— ì´ë¯¸ êµ¬í˜„ëœ Health forbid/require, BodyType ë£°, EXERCISE_TYPE_RULES ë“±ì´ í˜„ì¬ ê·¸ë˜í”„ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ |
| ì†ë„ | ë‹¨ì¼ ì¥ë¬¸ ì‘ë‹µ ìƒì„±(max_tokens ë†’ìŒ)ì´ ë¶„ë¦¬ëœ ë‹¨ë¬¸ ì‘ë‹µë³´ë‹¤ ëŠë¦¼ |

---

## 3. rule_based_promptsì˜ 4í˜¸ì¶œ êµ¬ì¡°

`src/llm/llm_prompt_test_sk/rule_based_prompts.py`ì˜ í˜„ì¬ êµ¬ì¡°:

| # | í•¨ìˆ˜ | ì—­í•  | í”„ë¡¬í”„íŠ¸ í•µì‹¬ ë‚´ìš© |
|---|------|------|--------------------|
| 1 | `create_summary_prompt` | ì£¼ê°„ ëª©í‘œ ìš”ì•½ | ì „ì²´ ë£° ì¢…í•© â†’ í•µì‹¬ ì „ëµ 3ê°€ì§€ |
| 2 | `create_workout_prompt` | ìš”ì¼ë³„ ìš´ë™ ê³„íš | Health forbid + WORKOUT RULES + EXERCISE_TYPE_RULES í™•ì¥ |
| 3 | `create_diet_prompt` | ì‹ë‹¨ ê³„íš | DIET RULES + ê¸°ì´ˆëŒ€ì‚¬ëŸ‰/ê¶Œì¥ì—´ëŸ‰ |
| 4 | `create_lifestyle_prompt` | ìƒí™œ ìŠµê´€ íŒ | COACH TONE + ë™ê¸°ë¶€ì—¬ |

ê³µí†µ ì¸í„°í˜ì´ìŠ¤:
```python
def create_*_prompt(
    goal_input: GoalPlanInput,
    measurements: InBodyMeasurements,
    rag_context: str = "",
    user_profile: Optional[Dict[str, Any]] = None,
) -> Tuple[str, str]:  # (system_prompt, user_prompt)
```

4ê°œ í”„ë¡¬í”„íŠ¸ëŠ” **ì™„ì „íˆ ë…ë¦½** â€” ì„œë¡œ ì°¸ì¡°í•˜ì§€ ì•ŠìŒ. ì´ê²ƒì´ ë³‘ë ¬ í˜¸ì¶œì˜ ê·¼ê±°ì…ë‹ˆë‹¤.

`user_profile`ì— í•„ìš”í•œ í‚¤:
```python
{
    "body_type1": str,          # BODY_TYPE1_RULES í‚¤
    "body_type2": str,          # BODY_TYPE2_RULES í‚¤
    "goal_type": str,           # comma-separated (ë‹¤ì¤‘ì„ íƒ): "ê°ëŸ‰, ì¬í™œ"
    "health_specifics": str,    # comma-separated (ë‹¤ì¤‘ì„ íƒ): "í—ˆë¦¬ ë””ìŠ¤í¬, ê³ í˜ˆì••"
    "preferences": str,         # "í™œë™ë ˆë²¨: ë³´í†µ, ìœ ì‚°ì†Œ, ì›¨ì´íŠ¸, ..."
}
```

---

## 4. í†µí•© ê°€ëŠ¥ì„± ë¶„ì„

| ì¡°ê±´ | í˜„ì¬ ìƒíƒœ | í†µí•© ê°€ëŠ¥? |
|------|-----------|-----------|
| 4ê°œ í”„ë¡¬í”„íŠ¸ì˜ ë…ë¦½ì„± | ì„œë¡œ ì°¸ì¡° ì—†ìŒ | âœ… ë³‘ë ¬ í˜¸ì¶œ ì í•© |
| LangGraph async node | `async def` node ì§€ì›, `ainvoke()` ì œê³µ | âœ… |
| OpenAI async í´ë¼ì´ì–¸íŠ¸ | í˜„ì¬ `OpenAI` (sync) only | âš ï¸ `AsyncOpenAI` ì¶”ê°€ í•„ìš” |
| Q&A ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ | messagesì— ì¢…í•© ì‘ë‹µì„ ì €ì¥í•˜ë©´ Q&A ìë™ ì°¸ì¡° | âœ… ë³€ê²½ ë¶ˆí•„ìš” |
| user_profile ê³µê¸‰ | `GoalPlanInput`ì— `health_specifics`, `preferences` ì—†ìŒ | âš ï¸ ì„œë¹„ìŠ¤ì—ì„œ DB ì¡°íšŒ í›„ Stateì— ì¶”ê°€ í•„ìš” |
| ê¸°ì¡´ Q&A ë…¸ë“œ | messages íˆìŠ¤í† ë¦¬ ê¸°ë°˜ â€” node ë‚´ë¶€ ë³€ê²½ ì—†ìŒ | âœ… |

**ê²°ë¡ : í†µí•© ê°€ëŠ¥. `initial_plan` nodeë¥¼ async 4í˜¸ì¶œ nodeë¡œ êµì²´í•˜ë©´ ë¨.**
Q&A ë…¸ë“œ, ë¼ìš°íŒ…, interrupt êµ¬ì¡°ëŠ” ëª¨ë‘ ìœ ì§€.

---

## 5. í†µí•© ì„¤ê³„ â€” ë³€ê²½ ë‚´ìš©

### 5.1 ë³€ê²½ íŒŒì¼ ëª©ë¡

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `llm_clients.py` | `AsyncOpenAIClient` í´ë˜ìŠ¤ ì¶”ê°€ |
| `weekly_plan_graph_rag.py` | State í™•ì¥, `initial_plan` â†’ `generate_rule_based_plan` (async) êµì²´, node ë“±ë¡ëª… ë³€ê²½ |
| `llm_service_rag.py` | `user_profile` DB ì¡°íšŒ í›„ State ì „ë‹¬, `invoke` â†’ `ainvoke` |
| `rule_based_prompts.py` | ë³€ê²½ ì—†ìŒ (import ê²½ë¡œë§Œ ë°±ì—”ë“œ ì¸¡ì—ì„œ ë§ì¶”ê¸°) |
| `rules.py` | ë³€ê²½ ì—†ìŒ |

### 5.2 State í™•ì¥

```python
# weekly_plan_graph_rag.py

class PlanStateRAG(TypedDict):
    plan_input:   GoalPlanInput
    messages:     Annotated[list, add_messages]
    rag_context:  Optional[str]
    # --- ì¶”ê°€ ---
    user_profile: Optional[Dict[str, Any]]   # DBì—ì„œ ì¡°íšŒí•œ ê±´ê°•/ì„ í˜¸ ì •ë³´
    plan_results: Optional[Dict[str, str]]   # {summary, workout, diet, lifestyle} ê°œë³„ ì‘ë‹µ ì €ì¥
```

### 5.3 AsyncOpenAIClient ì¶”ê°€

```python
# llm_clients.py
from openai import AsyncOpenAI

class AsyncOpenAIClient:
    """asyncio.gatherìš© async OpenAI í´ë¼ì´ì–¸íŠ¸"""
    def __init__(self, model: str = "gpt-4o-mini"):
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model

    async def generate_chat(self, system_prompt: str, user_prompt: str) -> str:
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,
        )
        return response.choices[0].message.content
```

### 5.4 async Node â€” í•µì‹¬ ë³€ê²½

ê¸°ì¡´ `generate_initial_plan` (sync, ë‹¨ì¼ í˜¸ì¶œ)ì„ ì•„ë˜ë¡œ êµì²´:

```python
# weekly_plan_graph_rag.py
import asyncio
from services.llm.llm_clients import AsyncOpenAIClient
# rule_based_promptsëŠ” shared ê²½ë¡œë¡œ ì´ë™ í›„ import (Â§7 ì°¸ì¡°)
from <shared_path>.rule_based_prompts import (
    create_summary_prompt,
    create_workout_prompt,
    create_diet_prompt,
    create_lifestyle_prompt,
)

async_llm = AsyncOpenAIClient()

# â”€â”€ node ì •ì˜ (create_weekly_plan_agent_with_rag ë‚´ë¶€) â”€â”€
async def generate_rule_based_plan(state: PlanStateRAG) -> dict:
    """Node 1: RAG ê²€ìƒ‰ + rule_based 4í˜¸ì¶œ (async ë³‘ë ¬)"""
    plan_input  = state["plan_input"]
    user_profile = state.get("user_profile") or {}
    measurements = InBodyMeasurements(**plan_input.measurements)

    # â”€â”€ 1. RAG ê²€ìƒ‰ (ê¸°ì¡´ ë™ì¼) â”€â”€
    rag_context = ""
    if use_rag and rag_retriever:
        try:
            query   = _generate_rag_query_from_goal(plan_input, measurements)
            papers  = rag_retriever.retrieve_relevant_papers(query=query, top_k=5, lang="ko")
            if papers:
                rag_context = rag_retriever.format_papers_for_prompt(papers)
        except Exception as e:
            print(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    # â”€â”€ 2. 4ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„± (sync, ê³„ì‚° ë¶€ë¶„ì€ ë¹ ë¦„) â”€â”€
    prompt_fns = {
        "summary":   create_summary_prompt,
        "workout":   create_workout_prompt,
        "diet":      create_diet_prompt,
        "lifestyle": create_lifestyle_prompt,
    }
    prompts = {
        key: fn(
            goal_input=plan_input,
            measurements=measurements,
            rag_context=rag_context,
            user_profile=user_profile,
        )
        for key, fn in prompt_fns.items()
    }

    # â”€â”€ 3. async 4í˜¸ì¶œ (ë³‘ë ¬) â”€â”€
    async def _call(key: str, system_prompt: str, user_prompt: str) -> tuple[str, str]:
        text = await async_llm.generate_chat(system_prompt, user_prompt)
        return key, text

    results = dict(await asyncio.gather(
        _call("summary",   *prompts["summary"]),
        _call("workout",   *prompts["workout"]),
        _call("diet",      *prompts["diet"]),
        _call("lifestyle", *prompts["lifestyle"]),
        return_exceptions=True,          # ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ ë°˜í™˜
    ))

    # â”€â”€ 4. ì‹¤íŒ¨ í•­ëª© ì²˜ë¦¬ â”€â”€
    for key, val in results.items():
        if isinstance(val, Exception):
            results[key] = f"[{key} ìƒì„± ì‹¤íŒ¨: {val}]"

    # â”€â”€ 5. messagesë¡œ ì¢…í•© (Q&A ì»¨í…ìŠ¤íŠ¸ìš©) â”€â”€
    combined = (
        f"---\nğŸ¯ ì£¼ê°„ ëª©í‘œ ìš”ì•½\n{results['summary']}\n\n"
        f"---\nğŸ‹ï¸ ìš´ë™ ê³„íš\n{results['workout']}\n\n"
        f"---\nğŸ½ ì‹ë‹¨ ê³„íš\n{results['diet']}\n\n"
        f"---\nğŸ’¡ ìƒí™œ ìŠµê´€\n{results['lifestyle']}"
    )

    return {
        "messages":    [("human", "ì£¼ê°„ ê³„íš ìƒì„± ìš”ì²­"), ("ai", combined)],
        "rag_context": rag_context,
        "plan_results": results,
    }

# â”€â”€ ê·¸ë˜í”„ êµ¬ì„± â”€â”€
workflow.add_node("initial_plan", generate_rule_based_plan)  # ë“±ë¡ëª… ìœ ì§€ â†’ interrupt_after ë“± ë³€ê²½ ë¶ˆí•„ìš”
```

> `return_exceptions=True`ë¥¼ ì‚¬ìš©í•˜ë©´ 4ê°œ ì¤‘ ì¼ë¶€ê°€ íƒ€ì„ì•„ì›ƒ/ì‹¤íŒ¨í•´ë„ ë‚˜ë¨¸ì§€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
> `asyncio.gather`ì˜ ë°˜í™˜ê°’ì€ ìˆœì„œëŒ€ë¡œ íŠœí”Œì´ë¯€ë¡œ, `isinstance(val, Exception)` ì²´í¬ë¡œ ì‹¤íŒ¨ í•­ëª©ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.

### 5.5 ì„œë¹„ìŠ¤ ë ˆì´ì–´ â€” user_profile ê³µê¸‰ ë° ainvoke

```python
# llm_service_rag.py

async def call_goal_plan_llm(self, plan_input: GoalPlanInput, db: Session) -> Dict[str, Any]:
    thread_id = f"plan_rag_{plan_input.user_id}_{plan_input.record_id}_{datetime.now().timestamp()}"
    config = {"configurable": {"thread_id": thread_id}}

    # â”€â”€ user_profile: UserDetailì—ì„œ ì¡°íšŒ â”€â”€
    active_detail = UserDetailRepository.get_active_detail(db, plan_input.user_id)
    user_profile = {
        "body_type1":      plan_input.body_type1 or "",
        "body_type2":      plan_input.body_type2 or "",
        "goal_type":       active_detail.goal_type       if active_detail else "",
        "health_specifics": active_detail.health_specifics if active_detail else "",
        "preferences":     active_detail.preferences     if active_detail else "",
    }

    # â”€â”€ ainvoke (async nodeì´ë¯€ë¡œ ë°˜ë“œì‹œ ainvoke ì‚¬ìš©) â”€â”€
    initial_state = await self.weekly_plan_agent.ainvoke(
        {
            "plan_input":    plan_input,
            "messages":      [],
            "rag_context":   None,
            "user_profile":  user_profile,
            "plan_results":  None,
        },
        config=config,
    )

    return {
        "plan_text":    initial_state["messages"][-1].content,
        "plan_results": initial_state.get("plan_results"),
        "thread_id":    thread_id,
        "rag_context":  initial_state.get("rag_context", ""),
    }
```

### 5.6 Q&A ë…¸ë“œ â€” ë³€ê²½ ë¶ˆí•„ìš”

ê¸°ì¡´ Q&A ë…¸ë“œë“¤ì€ `state["messages"]` ì „ì²´ë¥¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
`generate_rule_based_plan`ì´ 4ê°œ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¨ì¼ AI messageë¡œ ì €ì¥í•˜ë©´
Q&Aì—ì„œ ìë™ìœ¼ë¡œ ì „ì²´ ê³„íšì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê°€ì§‘ë‹ˆë‹¤.

ë¼ìš°íŒ…(`route_qa`), interrupt ëª©ë¡, `finalize_plan` ëª¨ë‘ ê¸°ì¡´ê³¼ ë™ì¼.

---

## 6. ê·¸ë˜í”„ ë‹¤ì´ì–´ê·¸ë¨ (ë³€ê²½ ì „Â·í›„)

### ë³€ê²½ ì „

```
[START]
  â†“
[initial_plan]                sync, LLM 1íšŒ í˜¸ì¶œ (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ â†’ ì „ì²´ ê³„íš)
  â”œâ”€â”€ interrupt
  â†“
route_qa â†’ [qa_*] â”€â”€â†’ interrupt (ë£¨í”„)
  â†“
[finalize_plan] â†’ [END]
```

### ë³€ê²½ í›„

```
[START]
  â†“
[initial_plan]                async, LLM 4íšŒ ë³‘ë ¬ í˜¸ì¶œ
  â”‚  â”Œâ”€ summary   â”€â”
  â”‚  â”œâ”€ workout   â”€â”¤  asyncio.gather (ë™ì‹œ ì‹¤í–‰)
  â”‚  â”œâ”€ diet      â”€â”¤
  â”‚  â””â”€ lifestyle â”€â”˜
  â”‚  â†’ 4ê°œ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ messagesì— ì €ì¥
  â”œâ”€â”€ interrupt              í”„ë¡ íŠ¸ì— ì¢…í•© ê²°ê³¼ í‘œì‹œ
  â†“
route_qa â†’ [qa_*] â”€â”€â†’ interrupt (ë£¨í”„)   â† ì¢…í•© ê²°ê³¼ ì „ì²´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ê°€ì§
  â†“
[finalize_plan] â†’ [END]
```

---

## 7. ì£¼ì˜ì‚¬í•­ ë° ê²°ì •ì´ í•„ìš”í•œ í¬ì¸íŠ¸

### 7.1 rule_based_prompts import ê²½ë¡œ

í˜„ì¬ `rule_based_prompts.py`ì™€ `rules.py`ëŠ” `src/llm/llm_prompt_test_sk/` ì•ˆì— ìˆìŠµë‹ˆë‹¤.
ë°±ì—”ë“œ(`backend/services/llm/`)ì—ì„œ ì§ì ‘ importí•˜ë ¤ë©´ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤:

- **ì˜µì…˜ A**: `src/llm/shared/` ë“± ê³µí†µ ê²½ë¡œë¡œ ì´ë™ í›„ ì–‘ì¸¡ì—ì„œ import
- **ì˜µì…˜ B**: `backend/services/llm/` ë‚´ë¶€ì— ë³µì‚¬ë³¸ ìœ ì§€ (ë¹ ë¥´ì§€ë§Œ ë™ê¸°í™” ë¶€ë‹´)
- **ì˜µì…˜ C**: `rules.py`ëŠ” í–¥í›„ DBë¡œ êµì²´ë  ê²ƒì´ë¯€ë¡œ, `rule_based_prompts.py`ë§Œ ì´ë™í•˜ê³  `rules.py`ëŠ” DB ì¡°íšŒë¡œ ëŒ€ì²´í•˜ëŠ” ì‹œì ì— ì •ë¦¬

### 7.2 ainvoke vs invoke

LangGraph nodeê°€ `async def`ì´ë©´ ë°˜ë“œì‹œ `graph.ainvoke()`ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
`invoke()`ë¡œ í˜¸ì¶œí•˜ë©´ async nodeì˜ ë‚´ë¶€ `await`ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

`chat_with_plan()` (Q&A ì¬ê°œ)ë„ ë™ì¼í•˜ê²Œ `ainvoke`ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.
Q&A ë…¸ë“œ ìì²´ëŠ” syncì´ì§€ë§Œ, async nodeì™€ ê°™ì€ ê·¸ë˜í”„ ë‚´ì—ì„œ `ainvoke`ë¡œ ì‹¤í–‰í•˜ë©´ sync ë…¸ë“œë„ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.

### 7.3 temperature í†µì¼

| ìœ„ì¹˜ | í˜„ì¬ temperature |
|------|-----------------|
| `test_llm_call.py` (í…ŒìŠ¤íŠ¸) | 1.0 |
| `OpenAIClient` (ë°±ì—”ë“œ) | 0.7 |

ê³„íšì„± ì‘ë‹µì´ë¯€ë¡œ **0.7 ê¶Œì¥**. `AsyncOpenAIClient`ì—ë„ 0.7ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

### 7.4 MemorySaverì˜ async ì§€ì›

í˜„ì¬ `MemorySaver()`ëŠ” ì¸ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„°ë¡œ async í˜¸í™˜ë©ë‹ˆë‹¤.
í”„ë¡œë•ì…˜ìœ¼ë¡œ ë„˜ì–´ê°„ë‹¤ë©´ `PostgresSaver`ë¡œ êµì²´í•˜ë©´ `ainvoke` + ì˜ì† ì €ì¥ ëª¨ë‘ ì§€ì›ë©ë‹ˆë‹¤.

### 7.5 GoalPlanInput í™•ì¥ ê°€ëŠ¥ì„±

í˜„ì¬ ì„¤ê³„ì—ì„œëŠ” `user_profile`ì„ ë³„ë„ State í‚¤ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ì ‘ê·¼ìœ¼ë¡œ, `GoalPlanInput` ìŠ¤í‚¤ë§ˆì— `health_specifics`, `preferences`ë¥¼ ì§ì ‘ ì¶”ê°€í•˜ë©´
`user_profile` State í‚¤ê°€ ë¶ˆí•„ìš”í•˜ì—¬ ë‹¨ìˆœí™”ë©ë‹ˆë‹¤.
ë‹¤ë§Œ ì´ëŠ” ë°±ì—”ë“œ ìŠ¤í‚¤ë§ˆ ë³€ê²½ì„ ìˆ˜ë°˜í•˜ë¯€ë¡œ, í˜„ì¬ ë‹¨ê³„ì—ì„œëŠ” State í‚¤ ë°©ì‹ì´ ì•ˆì „í•©ë‹ˆë‹¤.

### 7.6 í”„ë¡ íŠ¸ì—”ë“œ ì‘ë‹µ êµ¬ì¡°

í˜„ì¬ `call_goal_plan_llm`ì˜ ë°˜í™˜ê°’ì€ `plan_text: str` (ë‹¨ì¼ ë¬¸ìì—´)ì…ë‹ˆë‹¤.
4ê°œ ê²°ê³¼ë¥¼ ê°œë³„ì ìœ¼ë¡œ í”„ë¡ íŠ¸ì— í‘œì‹œí•˜ë ¤ë©´ `plan_results: Dict[str, str]`ë„ ë°˜í™˜ì— í¬í•¨ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤.
ì¢…í•© ë¬¸ìì—´(`plan_text`)ì€ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•©ë‹ˆë‹¤.
