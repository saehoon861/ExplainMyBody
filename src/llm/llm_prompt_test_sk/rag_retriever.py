"""
Simple Embedding-based RAG Retriever (í…ŒìŠ¤íŠ¸ìš©)
backend/services/llm/rag_retriever.pyì™€ ë™ì¼í•˜ì§€ë§Œ ë…ë¦½ì ì¸ DB ì—°ê²°
"""

from typing import List, Dict, Any, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.orm import Session, sessionmaker
import os
from dotenv import load_dotenv

from llm_clients import OpenAIClient

load_dotenv()


class SimpleRAGRetriever:
    """
    Simple Embedding-based RAG Retriever
    - Vector ìœ ì‚¬ë„ ê²€ìƒ‰ë§Œ ì‚¬ìš© (pgvector)
    - OpenAI text-embedding-3-small (1536D)
    """

    def __init__(self):
        """ì´ˆê¸°í™”"""
        # OpenAI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸
        self.embedding_client = OpenAIClient()
        self.embedding_dim = 1536

        # PostgreSQL ì—°ê²° (ë…ë¦½ì )
        db_url = os.getenv("DATABASE_URL")
        if not db_url:
            raise ValueError("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.engine = create_engine(db_url)
        self.SessionLocal = sessionmaker(bind=self.engine)
        self.session: Optional[Session] = None

    def _get_session(self) -> Session:
        """PostgreSQL ì„¸ì…˜ lazy ì´ˆê¸°í™”"""
        if not self.session:
            self.session = self.SessionLocal()
        return self.session

    def retrieve_relevant_papers(
        self,
        query: str,
        top_k: int = 5,
        lang: str = "ko",
    ) -> List[Dict[str, Any]]:
        """
        ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ (Vector ìœ ì‚¬ë„ë§Œ)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ìì—°ì–´)
            top_k: ìµœì¢… ê²°ê³¼ ê°œìˆ˜
            lang: ì–¸ì–´ í•„í„° ("ko" ë˜ëŠ” "en")

        Returns:
            ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ê¸°ë°˜)
        """
        try:
            print(f"\nğŸ” RAG ê²€ìƒ‰ ì¤‘...")
            print(f"  ì¿¼ë¦¬: {query}")

            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_client.create_embedding(text=query)
            print(f"  âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ ({len(query_embedding)}D)")

            # 2. Vector ê²€ìƒ‰ (pgvector)
            session = self._get_session()
            papers = self._search_similar_papers(
                session=session,
                query_embedding=query_embedding,
                top_k=top_k,
                lang=lang,
            )

            print(f"  âœ“ {len(papers)}ê°œ ë…¼ë¬¸ ê²€ìƒ‰ ì™„ë£Œ\n")
            return papers

        except Exception as e:
            print(f"  âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _search_similar_papers(
        self,
        session: Session,
        query_embedding: List[float],
        top_k: int,
        lang: str,
    ) -> List[Dict[str, Any]]:
        """
        Vector ìœ ì‚¬ë„ ê²€ìƒ‰ (pgvector)

        Args:
            session: DB ì„¸ì…˜
            query_embedding: ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°
            top_k: ê²°ê³¼ ê°œìˆ˜
            lang: ì–¸ì–´ í•„í„°

        Returns:
            ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        # pgvector ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ (<=> ì—°ì‚°ì)
        # embedding_ko_openai ì‚¬ìš© (í•œêµ­ì–´ ìš”ì•½ì— ëŒ€í•œ ì„ë² ë”©)
        query_sql = text("""
            SELECT
                paper_id,
                title,
                chunk_text,
                chunk_ko_summary,
                year,
                source,
                pmid,
                doi,
                lang,
                1 - (embedding_ko_openai <=> :query_embedding) as similarity
            FROM paper_nodes
            WHERE embedding_ko_openai IS NOT NULL
              AND chunk_ko_summary IS NOT NULL
              AND chunk_ko_summary != ''
            ORDER BY embedding_ko_openai <=> :query_embedding
            LIMIT :top_k
        """)

        # ì¿¼ë¦¬ ì„ë² ë”©ì„ PostgreSQL array í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        embedding_str = "[" + ",".join(str(x) for x in query_embedding) + "]"

        result = session.execute(
            query_sql,
            {
                "query_embedding": embedding_str,
                "top_k": top_k,
            }
        )

        papers = []
        for row in result:
            papers.append({
                'paper_id': row[0],
                'title': row[1] or 'N/A',
                'chunk_text': row[2] or '',
                'chunk_ko_summary': row[3] or '',
                'year': row[4],
                'source': row[5] or 'Unknown',
                'pmid': row[6],
                'doi': row[7],
                'lang': row[8] or 'unknown',
                'similarity': float(row[9]) if row[9] else 0.0,
            })

        return papers

    def format_papers_for_prompt(self, papers: List[Dict[str, Any]]) -> str:
        """
        ë…¼ë¬¸ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•  í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        - ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì œê±°, í•µì‹¬ ë‚´ìš©ë§Œ ì „ë‹¬

        Args:
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            í¬ë§·ëœ ë¬¸ìì—´
        """
        if not papers:
            return ""

        formatted_text = "\n\n## ì°¸ê³  ìë£Œ\n\n"

        for i, paper in enumerate(papers, 1):
            chunk_ko_summary = paper.get('chunk_ko_summary', '')
            # í•œêµ­ì–´ ìš”ì•½ ìš°ì„  ì‚¬ìš©
            content = chunk_ko_summary if chunk_ko_summary else paper.get('chunk_text', '')[:300]

            if content:
                formatted_text += f"{content}\n\n"

        return formatted_text

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.session:
            self.session.close()
            self.session = None

    def __del__(self):
        """ì†Œë©¸ì"""
        self.close()
