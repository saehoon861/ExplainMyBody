"""
ì£¼ê°„ ê³„íš ìƒì„±ì„ ìœ„í•œ ë³‘ë ¬ ì²˜ë¦¬ LangGraph ë…¸ë“œ
- 4ê°œì˜ LLM í˜¸ì¶œ(ìš”ì•½, ìš´ë™, ì‹ë‹¨, ìƒí™œ)ì„ ë¹„ë™ê¸° ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì´ˆê¸° ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
from pathlib import Path
from typing import TypedDict, Annotated

# --- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€ ---
# backendì™€ src ëª¨ë“ˆì„ ëª¨ë‘ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨
# ì´ íŒŒì¼ì˜ ìœ„ì¹˜: backend/services/llm/initial_plan_node.py
project_root = Path(__file__).parent.parent.parent.parent
src_path = project_root / "src"

if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))
# -----------------------------------------

from langgraph.graph.message import add_messages

from backend.schemas.inbody import InBodyData as InBodyMeasurements
from backend.schemas.llm import GoalPlanInput
# `llm.rule_based_prompts`ëŠ” `src` ë””ë ‰í† ë¦¬ ì•„ë˜ì— ìˆìŠµë‹ˆë‹¤.
from llm.rule_based_prompts import (
    create_summary_prompt,
    create_workout_prompt,
    create_diet_prompt,
    create_lifestyle_prompt,
)


# --- 1. ìƒíƒœ ì •ì˜ (weekly_plan_graph.pyì™€ ë™ì¼í•˜ê²Œ ìœ ì§€) ---
class PlanState(TypedDict):
    """LLM2 (ì£¼ê°„ ê³„íš / Q&A) ì—ì´ì „íŠ¸ì˜ ìƒíƒœ"""
    plan_input: GoalPlanInput
    messages: Annotated[list, add_messages]


# --- 2. ìƒˆë¡œìš´ ë¹„ë™ê¸° ë…¸ë“œ ì •ì˜ ---
async def generate_initial_plan_concurrently(state: PlanState, llm_client) -> dict:
    """
    Node: ì£¼ê°„ ê³„íš ì´ˆì•ˆ ë³‘ë ¬ ìƒì„±
    4ê°œì˜ LLM Call(ìš”ì•½, ìš´ë™, ì‹ë‹¨, ë¼ì´í”„ìŠ¤íƒ€ì¼)ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì·¨í•©í•©ë‹ˆë‹¤.
    """
    print("--- LLM2: ì£¼ê°„ ê³„íš ë³‘ë ¬ ìƒì„± ì‹œì‘ ---")
    plan_input = state["plan_input"]

    # InBody ë°ì´í„° ëª¨ë¸ ë³€í™˜
    measurements = InBodyMeasurements(**plan_input.measurements)
    # ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ (test_llm_call.pyì˜ profile_dataì™€ ìœ ì‚¬)
    # GoalPlanInputì— user_profileì´ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    # ë§Œì•½ ì—†ë‹¤ë©´, PlanStateì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
    user_profile = plan_input.user_profile if hasattr(plan_input, 'user_profile') else {}

    # --- 4ê°€ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ---
    prompts = {
        "summary": create_summary_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "workout": create_workout_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "diet": create_diet_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
        "lifestyle": create_lifestyle_prompt(
            goal_input=plan_input, measurements=measurements, rag_context="", user_profile=user_profile
        ),
    }

    # --- LLM ë¹„ë™ê¸° í˜¸ì¶œ íƒœìŠ¤í¬ ìƒì„± ---
    # llm_clientì— `agenerate_chat`ê³¼ ê°™ì€ ë¹„ë™ê¸° ë©”ì„œë“œê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    tasks = []
    for key, (system_prompt, user_prompt) in prompts.items():
        # llm_clientì˜ ë¹„ë™ê¸° ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # (ì˜ˆ: agenerate_chat, generate_chat_async ë“±)
        task = llm_client.agenerate_chat(system_prompt, user_prompt, key)
        tasks.append(task)

    # --- ëª¨ë“  LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ ---
    print("--- LLM2: 4ê°œ ê³„íš ë™ì‹œ ìƒì„± ì¤‘... ---")
    results = await asyncio.gather(*tasks)
    
    # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì¬êµ¬ì„±
    plan_results = {res['key']: res['content'] for res in results}
    summary_result = plan_results.get("summary", "ì£¼ê°„ ëª©í‘œ ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    workout_result = plan_results.get("workout", "ìš´ë™ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    diet_result = plan_results.get("diet", "ì‹ë‹¨ ê³„íš ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    lifestyle_result = plan_results.get("lifestyle", "ìƒí™œ ìŠµê´€ ë° ë™ê¸°ë¶€ì—¬ ë©”ì‹œì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # --- ìµœì¢… ê²°ê³¼ í¬ë§·íŒ… ---
    combined_response = f"""### ğŸ“ ì£¼ê°„ ëª©í‘œ í•µì‹¬ ì „ëµ
{summary_result}

### ğŸ‹ï¸â€â™€ï¸ ìš”ì¼ë³„ ìš´ë™ ê³„íš
{workout_result}

### ğŸ½ï¸ ì¼ì¼ ì‹ë‹¨ ê³„íš
{diet_result}

### ğŸ’¡ ìƒí™œ ìŠµê´€ ë° ë™ê¸°ë¶€ì—¬
{lifestyle_result}

---
ìœ„ ê³„íšì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆê±°ë‚˜ ìˆ˜ì •ì„ ì›í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”!
"""
    print("--- LLM2: ì£¼ê°„ ê³„íš ë³‘ë ¬ ìƒì„± ì™„ë£Œ ---")

    # --- ìƒíƒœ ì—…ë°ì´íŠ¸ ---
    # weekly_plan_graph.pyì˜ ê¸°ì¡´ ë…¸ë“œì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    # ì´ˆê¸° ì‚¬ìš©ì ì§ˆë¬¸ì„ "human" ë©”ì‹œì§€ë¡œ ì¶”ê°€
    initial_user_message = state["messages"][-1].content if state["messages"] and state["messages"][-1].type == "human" else "ì£¼ê°„ ê³„íšì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."

    return {"messages": [("human", initial_user_message), ("ai", combined_response)]}
