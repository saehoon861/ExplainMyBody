"""
ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (GPT-4o-mini)
- ìƒ˜í”Œ ë°ì´í„°ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
- OpenAI API í˜¸ì¶œ
- ì‹¤ì œ ì‘ë‹µ í™•ì¸
"""

import os
import time
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°)
env_path = Path(__file__).parent.parent.parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… .env íŒŒì¼ ë¡œë“œ: {env_path}")
else:
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œë„ ì°¾ê¸°
    load_dotenv()
    print("âš ï¸  .env íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•´ì£¼ì„¸ìš”.")
from sample_data import SAMPLE_USER, SAMPLE_PROFILES, SAMPLE_MEASUREMENTS, SAMPLE_GOAL
from schemas_inbody import InBodyData
from schemas import GoalPlanInput
from prompt_generator_rag import (
    create_weekly_plan_summary_prompt_with_rag,
    create_workout_plan_prompt_with_rag,
    create_diet_plan_prompt_with_rag,
    create_lifestyle_motivation_prompt_with_rag
)


def test_single_profile_with_llm(profile_name: str, profile_data: dict):
    """ë‹¨ì¼ í”„ë¡œí•„ë¡œ ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 80)
    print(f"ğŸ¤– LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸: {profile_name}")
    print("=" * 80)
    print(f"ì²´í˜•: {profile_data['body_type1']} / {profile_data['body_type2']}")
    print(f"ì¥ì†Œ: {profile_data['workout_place']}")
    if profile_data.get('preferred_sport'):
        print(f"ìŠ¤í¬ì¸ : {profile_data['preferred_sport']}")
    print()

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # ë°ì´í„° ë³€í™˜
    measurements = InBodyData(**SAMPLE_MEASUREMENTS)
    goal_input = GoalPlanInput(**SAMPLE_GOAL)

    # ========================================================================
    # Prompt 1: ì£¼ê°„ ëª©í‘œ ìš”ì•½
    # ========================================================================
    print("-" * 80)
    print("ğŸ¯ Prompt 1: ì£¼ê°„ ëª©í‘œ ìš”ì•½ (3ê°€ì§€ í•µì‹¬ ì „ëµ)")
    print("-" * 80)

    system_prompt_1, user_prompt_1 = create_weekly_plan_summary_prompt_with_rag(
        goal_input=goal_input,
        measurements=measurements,
        rag_context="",
        user_profile=profile_data
    )

    print("\n[LLM í˜¸ì¶œ ì¤‘...]")
    time_1_start = time.time()

    try:
        response_1 = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt_1},
                {"role": "user", "content": user_prompt_1}
            ],
            temperature=1,
            max_tokens=3000
        )

        time_1 = time.time() - time_1_start
        summary_result = response_1.choices[0].message.content

        print("\n[LLM ì‘ë‹µ]")
        print(summary_result)
        print(f"\nì‚¬ìš© í† í°: {response_1.usage.total_tokens} | ì†Œìš” ì‹œê°„: {time_1:.2f}s")

    except Exception as e:
        time_1 = time.time() - time_1_start
        print(f"\nâŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} ({time_1:.2f}s)")
        summary_result = None

    # ========================================================================
    # Prompt 2: ìš”ì¼ë³„ ìš´ë™ ê³„íš
    # ========================================================================
    print("\n" + "-" * 80)
    print("ğŸ‹ï¸ Prompt 2: ìš”ì¼ë³„ ìš´ë™ ê³„íš")
    print("-" * 80)

    system_prompt_2_workout, user_prompt_2_workout = create_workout_plan_prompt_with_rag(
        goal_input=goal_input,
        measurements=measurements,
        rag_context="",
        user_profile=profile_data
    )

    # ìš´ë™ ê³„íšì—ë§Œ ì§‘ì¤‘í•˜ë„ë¡ ìˆ˜ì •
    system_prompt_2_workout = system_prompt_2_workout + "\n\n**ì´ë²ˆ ì‘ë‹µì€ ìš”ì¼ë³„ ìš´ë™ ê³„íšì—ë§Œ ì§‘ì¤‘í•´ì£¼ì„¸ìš”. ì‹ë‹¨ì´ë‚˜ ìƒí™œìŠµê´€ì€ ì œì™¸í•˜ê³  ìš´ë™ ë‚´ìš©ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.**"

    print("\n[LLM í˜¸ì¶œ ì¤‘...]")
    time_2_start = time.time()

    try:
        response_2 = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt_2_workout},
                {"role": "user", "content": user_prompt_2_workout}
            ],
            temperature=1,
            max_tokens=4000
        )

        time_2 = time.time() - time_2_start
        workout_result = response_2.choices[0].message.content

        print("\n[LLM ì‘ë‹µ]")
        print(workout_result)
        print(f"\nì‚¬ìš© í† í°: {response_2.usage.total_tokens} | ì†Œìš” ì‹œê°„: {time_2:.2f}s")

    except Exception as e:
        time_2 = time.time() - time_2_start
        print(f"\nâŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} ({time_2:.2f}s)")
        workout_result = None

    # ========================================================================
    # Prompt 3: ì‹ë‹¨ ê³„íš
    # ========================================================================
    print("\n" + "-" * 80)
    print("ğŸ½ï¸ Prompt 3: ì‹ë‹¨ ê³„íš")
    print("-" * 80)

    system_prompt_3_diet, user_prompt_3_diet = create_diet_plan_prompt_with_rag(
        goal_input=goal_input,
        measurements=measurements,
        rag_context="",
        user_profile=profile_data
    )

    # ì‹ë‹¨ ê³„íšì—ë§Œ ì§‘ì¤‘í•˜ë„ë¡ ìˆ˜ì •
    system_prompt_3_diet = system_prompt_3_diet + "\n\n**ì´ë²ˆ ì‘ë‹µì€ ì‹ë‹¨ ê³„íšì—ë§Œ ì§‘ì¤‘í•´ì£¼ì„¸ìš”. ìš´ë™ì´ë‚˜ ìƒí™œìŠµê´€ì€ ì œì™¸í•˜ê³  ì‹ë‹¨ ë‚´ìš©ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.**"

    print("\n[LLM í˜¸ì¶œ ì¤‘...]")
    time_3_start = time.time()

    try:
        response_3 = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt_3_diet},
                {"role": "user", "content": user_prompt_3_diet}
            ],
            temperature=1,
            max_tokens=4000
        )

        time_3 = time.time() - time_3_start
        diet_result = response_3.choices[0].message.content

        print("\n[LLM ì‘ë‹µ]")
        print(diet_result)
        print(f"\nì‚¬ìš© í† í°: {response_3.usage.total_tokens} | ì†Œìš” ì‹œê°„: {time_3:.2f}s")

    except Exception as e:
        time_3 = time.time() - time_3_start
        print(f"\nâŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} ({time_3:.2f}s)")
        diet_result = None

    # ========================================================================
    # Prompt 4: ìƒí™œ ìŠµê´€ íŒ ë° ë™ê¸°ë¶€ì—¬
    # ========================================================================
    print("\n" + "-" * 80)
    print("ğŸ’¡ Prompt 4: ìƒí™œ ìŠµê´€ íŒ ë° ë™ê¸°ë¶€ì—¬")
    print("-" * 80)

    system_prompt_4_lifestyle, user_prompt_4_lifestyle = create_lifestyle_motivation_prompt_with_rag(
        goal_input=goal_input,
        measurements=measurements,
        rag_context="",
        user_profile=profile_data
    )

    # ìƒí™œ ìŠµê´€ ë° ë™ê¸°ë¶€ì—¬ì—ë§Œ ì§‘ì¤‘í•˜ë„ë¡ ìˆ˜ì •
    system_prompt_4_lifestyle = system_prompt_4_lifestyle + "\n\n**ì´ë²ˆ ì‘ë‹µì€ ìƒí™œ ìŠµê´€ ê°œì„  íŒê³¼ ë™ê¸°ë¶€ì—¬ ë¬¸ì¥ì—ë§Œ ì§‘ì¤‘í•´ì£¼ì„¸ìš”. ìš´ë™ì´ë‚˜ ì‹ë‹¨ì€ ì œì™¸í•˜ê³  ì¼ìƒ ê´€ë¦¬ì™€ ë™ê¸°ë¶€ì—¬ ë‚´ìš©ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.**"

    print("\n[LLM í˜¸ì¶œ ì¤‘...]")
    time_4_start = time.time()

    try:
        response_4 = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt_4_lifestyle},
                {"role": "user", "content": user_prompt_4_lifestyle}
            ],
            temperature=1,
            max_tokens=3000
        )

        time_4 = time.time() - time_4_start
        lifestyle_result = response_4.choices[0].message.content

        print("\n[LLM ì‘ë‹µ]")
        print(lifestyle_result)
        print(f"\nì‚¬ìš© í† í°: {response_4.usage.total_tokens} | ì†Œìš” ì‹œê°„: {time_4:.2f}s")

    except Exception as e:
        time_4 = time.time() - time_4_start
        print(f"\nâŒ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e} ({time_4:.2f}s)")
        lifestyle_result = None

    # ========================================================================
    # ì†Œìš” ì‹œê°„ ìš”ì•½
    # ========================================================================
    total_time = time_1 + time_2 + time_3 + time_4
    print("\n" + "-" * 80)
    print("â±ï¸  ì†Œìš” ì‹œê°„ ìš”ì•½")
    print("-" * 80)
    print(f"  Call 1 (ì£¼ê°„ ëª©í‘œ ìš”ì•½):        {time_1:.2f}s")
    print(f"  Call 2 (ìš”ì¼ë³„ ìš´ë™ ê³„íš):      {time_2:.2f}s")
    print(f"  Call 3 (ì‹ë‹¨ ê³„íš):            {time_3:.2f}s")
    print(f"  Call 4 (ìƒí™œ ìŠµê´€ íŒ ë° ë™ê¸°ë¶€ì—¬): {time_4:.2f}s")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ì´ ì†Œìš” ì‹œê°„:                  {total_time:.2f}s")

    # ========================================================================
    # ê²°ê³¼ ì €ì¥
    # ========================================================================
    if summary_result and workout_result and diet_result and lifestyle_result:
        from pathlib import Path
        import json
        from datetime import datetime

        # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def json_serial(obj):
            if isinstance(obj, datetime):
                return obj.isoformat()
            raise TypeError(f"Type {type(obj)} not serializable")

        output_dir = Path(__file__).parent / "output"
        output_dir.mkdir(exist_ok=True)

        # profile_dataë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
        profile_serializable = {
            k: v.isoformat() if isinstance(v, datetime) else v
            for k, v in profile_data.items()
        }

        output_file = output_dir / f"llm_result_{profile_name}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "profile": profile_serializable,
                "summary": summary_result,
                "workout": workout_result,
                "diet": diet_result,
                "lifestyle": lifestyle_result,
                "tokens_summary": response_1.usage.total_tokens,
                "tokens_workout": response_2.usage.total_tokens,
                "tokens_diet": response_3.usage.total_tokens,
                "tokens_lifestyle": response_4.usage.total_tokens,
                "tokens_total": (response_1.usage.total_tokens +
                                response_2.usage.total_tokens +
                                response_3.usage.total_tokens +
                                response_4.usage.total_tokens)
            }, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file.name}")

    return summary_result, workout_result, diet_result, lifestyle_result


def test_all_profiles_with_llm():
    """ëª¨ë“  ìƒ˜í”Œ í”„ë¡œí•„ë¡œ LLM í˜¸ì¶œ"""

    print("\n" + "=" * 80)
    print("ğŸ§ª ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (GPT-4o-mini)")
    print("=" * 80)

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì„¤ì • ë°©ë²•:")
        print("  export OPENAI_API_KEY=your-api-key")
        return

    print("\nâœ… OpenAI API í‚¤ í™•ì¸ë¨")
    print("âš ï¸  ì£¼ì˜: ì‹¤ì œ API í˜¸ì¶œì´ ì´ë£¨ì–´ì§€ë©° ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.")

    # ì‚¬ìš©ì í™•ì¸
    confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if confirm.lower() != 'y':
        print("ì·¨ì†Œë¨")
        return

    # ê¸°ë³¸ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸
    test_single_profile_with_llm("SAMPLE_USER", SAMPLE_USER)

    # ì¶”ê°€ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸ ì—¬ë¶€
    print("\n" + "=" * 80)
    confirm = input("ë‹¤ë¥¸ í”„ë¡œí•„ë„ í…ŒìŠ¤íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if confirm.lower() == 'y':
        for name, profile in SAMPLE_PROFILES.items():
            test_single_profile_with_llm(name, profile)


def test_quick_single():
    """ë¹ ë¥¸ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ (SAMPLE_USERë§Œ)"""

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì„¤ì • ë°©ë²•:")
        print("  export OPENAI_API_KEY='your-api-key'")
        return

    print("ğŸš€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (SAMPLE_USER)")
    test_single_profile_with_llm("SAMPLE_USER", SAMPLE_USER)


def test_random_profiles(count: int = 1):
    """
    ëœë¤ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸

    Args:
        count: í…ŒìŠ¤íŠ¸í•  í”„ë¡œí•„ ê°œìˆ˜ (ê¸°ë³¸: 1)
    """
    import random

    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\nì„¤ì • ë°©ë²•:")
        print("  export OPENAI_API_KEY='your-api-key'")
        return

    print("\n" + "=" * 80)
    print(f"ğŸ² ëœë¤ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸ ({count}ê°œ)")
    print("=" * 80)
    print(f"\nì „ì²´ í”„ë¡œí•„: {len(SAMPLE_PROFILES)}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: {count}ê°œ (ëœë¤ ì„ íƒ)")

    # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œí•„ ëª©ë¡
    all_profiles = list(SAMPLE_PROFILES.items())

    # countê°€ ì „ì²´ë³´ë‹¤ í¬ë©´ ì „ì²´ ê°œìˆ˜ë¡œ ì œí•œ
    count = min(count, len(all_profiles))

    # ëœë¤ ìƒ˜í”Œë§
    selected = random.sample(all_profiles, count)

    print("\nì„ íƒëœ í”„ë¡œí•„:")
    for i, (name, _) in enumerate(selected, 1):
        print(f"  {i}. {name}")

    # ì‚¬ìš©ì í™•ì¸
    print(f"\nâš ï¸  ì£¼ì˜: {count}ê°œ í”„ë¡œí•„ Ã— 4ê°œ í”„ë¡¬í”„íŠ¸ = {count*4}íšŒ API í˜¸ì¶œ")
    print(f"ì˜ˆìƒ ë¹„ìš©: ì•½ ${count * 0.006:.4f} (~{int(count * 0.006 * 1300)}ì›)")

    confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if confirm.lower() != 'y':
        print("ì·¨ì†Œë¨")
        return

    # ì„ íƒëœ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸
    results = []
    for i, (name, profile) in enumerate(selected, 1):
        print(f"\n{'='*80}")
        print(f"[{i}/{count}] {name}")
        print(f"{'='*80}")

        summary, workout, diet, lifestyle = test_single_profile_with_llm(name, profile)
        results.append({
            "name": name,
            "profile": profile,
            "success": all([summary, workout, diet, lifestyle])
        })

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)

    success_count = sum(1 for r in results if r["success"])
    print(f"\nì„±ê³µ: {success_count}/{count}")
    print(f"ì‹¤íŒ¨: {count - success_count}/{count}")

    print("\nê°œë³„ ê²°ê³¼:")
    for i, result in enumerate(results, 1):
        status = "âœ…" if result["success"] else "âŒ"
        print(f"  {i}. {status} {result['name']}")

    return results


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        arg = sys.argv[1]

        if arg == "--quick":
            # ë¹ ë¥¸ ëª¨ë“œ: SAMPLE_USERë§Œ í…ŒìŠ¤íŠ¸
            test_quick_single()

        elif arg.startswith("--random"):
            # ëœë¤ ëª¨ë“œ: --random ë˜ëŠ” --random=N
            if "=" in arg:
                count = int(arg.split("=")[1])
            else:
                # --random N í˜•ì‹
                count = int(sys.argv[2]) if len(sys.argv) > 2 else 1

            test_random_profiles(count)

        else:
            print("ì‚¬ìš©ë²•:")
            print("  python test_llm_call.py              # ì „ì²´ í”„ë¡œí•„ í…ŒìŠ¤íŠ¸")
            print("  python test_llm_call.py --quick      # SAMPLE_USERë§Œ í…ŒìŠ¤íŠ¸")
            print("  python test_llm_call.py --random     # ëœë¤ 1ê°œ í…ŒìŠ¤íŠ¸")
            print("  python test_llm_call.py --random=3   # ëœë¤ 3ê°œ í…ŒìŠ¤íŠ¸")
            print("  python test_llm_call.py --random 2   # ëœë¤ 2ê°œ í…ŒìŠ¤íŠ¸")
            sys.exit(1)
    else:
        # ì „ì²´ ëª¨ë“œ: ëª¨ë“  í”„ë¡œí•„ í…ŒìŠ¤íŠ¸
        test_all_profiles_with_llm()

    print("\n" + "=" * 80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 80)
    print("\nê²°ê³¼ íŒŒì¼ í™•ì¸:")
    print("  - output/llm_result_*.json")
    print()
