"""
Graph RAG Retriever - Hybrid Search (Vector + Graph)
- Vector ìœ ì‚¬ë„ ê²€ìƒ‰ (PostgreSQL pgvector) â†’ ì´ˆê¸° í›„ë³´ ë…¼ë¬¸ íƒìƒ‰
- Graph íƒìƒ‰ (Neo4j) â†’ ê°œë… ê¸°ë°˜ ê´€ë ¨ ë…¼ë¬¸ í™•ì¥
- Reranking â†’ ìµœì¢… ê²°ê³¼ ì •ë ¬
- í•­ìƒ OpenAI text-embedding-3-small ì‚¬ìš© (1536D)
"""

from typing import List, Dict, Any, Optional
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))
# backend í´ë”ë„ ì¶”ê°€ (backend ë‚´ë¶€ì˜ ìƒëŒ€ ê²½ë¡œ importë¥¼ ìœ„í•´)
sys.path.insert(0, str(project_root / "backend"))

from sqlalchemy.orm import Session
from backend.database import SessionLocal
from backend.repositories.paper_repository import PaperRepository
from backend.repositories.neo4j_repository import Neo4jRepository
from shared.llm_clients import OpenAIClient


class GraphRAGRetriever:
    """
    Graph RAG ê²€ìƒ‰ê¸° (Hybrid: Vector + Graph)
    - Vector Search: ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë…¼ë¬¸ ê²€ìƒ‰ (pgvector)
    - Graph Expansion: ê°œë… ê¸°ë°˜ ê´€ë ¨ ë…¼ë¬¸ í™•ì¥ (Neo4j)
    - Reranking: ì‹œê°„, ìœ ì‚¬ë„, ì‹ ë¢°ë„ ê¸°ë°˜ ì¬ì •ë ¬
    """

    def __init__(self, use_neo4j: bool = True):
        """
        Args:
            use_neo4j: Neo4j ê·¸ë˜í”„ íƒìƒ‰ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
        """
        self.use_neo4j = use_neo4j

        # OpenAI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ (í•­ìƒ text-embedding-3-small ì‚¬ìš©)
        self.embedding_client = OpenAIClient()
        self.embedding_dim = 1536

        # PostgreSQL ì„¸ì…˜ ë° Repository
        self.session: Optional[Session] = None
        self.paper_repo: Optional[PaperRepository] = None

        # Neo4j Repository
        self.neo4j_repo: Optional[Neo4jRepository] = None
        if use_neo4j:
            try:
                self.neo4j_repo = Neo4jRepository()
                if not self.neo4j_repo.driver:
                    print("  âš ï¸  Neo4j ì—°ê²° ì‹¤íŒ¨. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    self.use_neo4j = False
            except Exception as e:
                print(f"  âš ï¸  Neo4j ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.use_neo4j = False

        print(f"  ğŸ”§ Graph RAG Embedder: OpenAI text-embedding-3-small (1536D)")
        print(f"  ğŸ”§ Neo4j Graph: {'âœ… Enabled' if self.use_neo4j else 'âŒ Disabled'}")

    def _get_session(self) -> Session:
        """PostgreSQL ì„¸ì…˜ lazy ì´ˆê¸°í™”"""
        if not self.session:
            self.session = SessionLocal()
            self.paper_repo = PaperRepository(self.session)
        return self.session

    def retrieve_relevant_papers(
        self,
        query: str,
        concepts: Optional[List[str]] = None,
        top_k: int = 10,
        domain: Optional[str] = None,
        lang: str = "ko",
    ) -> List[Dict[str, Any]]:
        """
        ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ (Hybrid: Vector + Graph)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ìì—°ì–´)
            concepts: í•µì‹¬ ê°œë… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["muscle_hypertrophy", "protein_intake"])
            top_k: ìµœì¢… ê²°ê³¼ ê°œìˆ˜
            domain: ë„ë©”ì¸ í•„í„° (ì˜ˆ: "protein_hypertrophy")
            lang: ì–¸ì–´ í•„í„° ("ko" ë˜ëŠ” "en")

        Returns:
            ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ + ê·¸ë˜í”„ ê¸°ë°˜)
        """
        print(f"\nğŸ” Graph RAG ê²€ìƒ‰ ì¤‘ (top_k={top_k})...")
        print(f"  - ì¿¼ë¦¬: '{query[:50]}...'")
        if concepts:
            print(f"  - ê°œë…: {concepts}")

        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (OpenAI text-embedding-3-small)
            print(f"\n  ğŸ“Š 1ë‹¨ê³„: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embedding = self.embedding_client.create_embedding(text=query)
            print(f"    âœ“ ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: {len(query_embedding)})")

            # 2. Vector ê²€ìƒ‰ (pgvector)
            print(f"\n  ğŸ” 2ë‹¨ê³„: Vector ìœ ì‚¬ë„ ê²€ìƒ‰ (PostgreSQL)...")
            session = self._get_session()

            # í•­ìƒ embedding_ko_openai ì‚¬ìš© (ëª¨ë“  ë…¼ë¬¸ì— ëŒ€í•´ í•œêµ­ì–´ ì„ë² ë”© ìƒì„±í–ˆìŒ)
            use_ko_embedding = True

            vector_papers = self.paper_repo.search_similar_papers(
                query_embedding=query_embedding,
                top_k=top_k * 2,  # í›„ë³´ í™•ì¥ (ë‚˜ì¤‘ì— í•„í„°ë§)
                lang=lang,
                domain=domain,
                use_ko_embedding=use_ko_embedding,
            )

            print(f"    âœ“ {len(vector_papers)}ê°œ í›„ë³´ ë…¼ë¬¸ ê²€ìƒ‰ ì™„ë£Œ")

            # 3. Graph íƒìƒ‰ (Neo4j) - ê°œë… ê¸°ë°˜ í™•ì¥
            graph_papers = []
            if self.use_neo4j and concepts:
                print(f"\n  ğŸ”· 3ë‹¨ê³„: Graph íƒìƒ‰ (Neo4j)...")
                graph_papers = self._expand_by_concepts(concepts, limit=top_k)
                print(f"    âœ“ {len(graph_papers)}ê°œ ê·¸ë˜í”„ ê¸°ë°˜ ë…¼ë¬¸ ë°œê²¬")

            # 4. ê²°ê³¼ ë³‘í•© ë° Reranking
            print(f"\n  ğŸ¯ 4ë‹¨ê³„: ê²°ê³¼ ë³‘í•© ë° Reranking...")
            merged_papers = self._merge_and_rerank(
                vector_papers=vector_papers,
                graph_papers=graph_papers,
                top_k=top_k,
            )

            print(f"    âœ“ ìµœì¢… {len(merged_papers)}ê°œ ë…¼ë¬¸ ì„ ì •\n")

            # ê²°ê³¼ ì¶œë ¥
            for i, paper in enumerate(merged_papers, 1):
                source = paper.get('source_type', 'unknown')
                score = paper.get('final_score', 0)
                print(f"    {i}. [{source}] Score: {score:.3f} - {paper.get('title', 'N/A')[:60]}...")

            return merged_papers

        except Exception as e:
            print(f"  âŒ Graph RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _expand_by_concepts(
        self, concepts: List[str], limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ê°œë… ê¸°ë°˜ ê·¸ë˜í”„ íƒìƒ‰ (Neo4j)

        Args:
            concepts: ê°œë… ID ë¦¬ìŠ¤íŠ¸
            limit: ê°œë…ë‹¹ ë…¼ë¬¸ ê°œìˆ˜

        Returns:
            ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        if not self.neo4j_repo:
            return []

        graph_papers = []

        for concept_id in concepts:
            # ê°œë…ê³¼ ì—°ê²°ëœ ë…¼ë¬¸ ì¡°íšŒ
            papers = self.neo4j_repo.get_papers_by_concept_graph(
                concept_id=concept_id,
                relation_types=['MENTIONS', 'INCREASES', 'SUPPORTS'],
                limit=limit,
            )

            for paper in papers:
                graph_papers.append({
                    'paper_id': paper['paper_id'],
                    'title': paper['title'],
                    'relation_type': paper['relation_type'],
                    'confidence': paper['confidence'],
                    'source_type': 'graph',
                    'concept_id': concept_id,
                })

        return graph_papers

    def _merge_and_rerank(
        self,
        vector_papers: List[Dict[str, Any]],
        graph_papers: List[Dict[str, Any]],
        top_k: int,
    ) -> List[Dict[str, Any]]:
        """
        Vector ê²€ìƒ‰ + Graph ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë° Reranking

        Args:
            vector_papers: Vector ê²€ìƒ‰ ê²°ê³¼
            graph_papers: Graph ê²€ìƒ‰ ê²°ê³¼
            top_k: ìµœì¢… ê²°ê³¼ ê°œìˆ˜

        Returns:
            ë³‘í•© ë° ì¬ì •ë ¬ëœ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        # paper_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë…¼ë¬¸ ë”•ì…”ë„ˆë¦¬
        paper_map = {}

        # 1. Vector ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (similarity ê¸°ë°˜)
        for paper in vector_papers:
            paper_id = paper.get('paper_id')
            if not paper_id:
                continue

            paper_map[paper_id] = {
                **paper,
                'vector_score': paper.get('similarity', 0.0),
                'graph_score': 0.0,
                'source_type': 'vector',
            }

        # 2. Graph ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (confidence ê¸°ë°˜)
        for paper in graph_papers:
            paper_id = paper.get('paper_id')
            if not paper_id:
                continue

            confidence = paper.get('confidence', 0.0)

            if paper_id in paper_map:
                # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° graph_score ì¶”ê°€
                paper_map[paper_id]['graph_score'] = max(
                    paper_map[paper_id]['graph_score'],
                    confidence
                )
                paper_map[paper_id]['source_type'] = 'hybrid'
            else:
                # ìƒˆë¡œìš´ ë…¼ë¬¸ ì¶”ê°€ (PostgreSQLì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ í•„ìš”)
                paper_map[paper_id] = {
                    'paper_id': paper_id,
                    'title': paper.get('title', ''),
                    'vector_score': 0.0,
                    'graph_score': confidence,
                    'source_type': 'graph',
                    'relation_type': paper.get('relation_type'),
                }

        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
        VECTOR_WEIGHT = 0.7  # Vector ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0.6 â†’ 0.7 ì¦ê°€)
        GRAPH_WEIGHT = 0.3   # Graph ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0.4 â†’ 0.3 ê°ì†Œ)

        for paper_id, paper in paper_map.items():
            vector_score = paper.get('vector_score', 0.0)
            graph_score = paper.get('graph_score', 0.0)

            # ìµœì¢… ì ìˆ˜ = ê°€ì¤‘ í‰ê· 
            final_score = (
                VECTOR_WEIGHT * vector_score +
                GRAPH_WEIGHT * graph_score
            )

            paper['final_score'] = final_score

        # 4. PostgreSQLì—ì„œ ìƒì„¸ ì •ë³´ ë³´ê°• (graph-only ë…¼ë¬¸)
        self._enrich_papers_from_postgresql(list(paper_map.values()))

        # 5. ì ìˆ˜ ì •ê·œí™” (ì„ íƒ)
        all_papers = list(paper_map.values())
        if all_papers:
            # ìµœê³ /ìµœì € ì ìˆ˜ ì°¾ê¸°
            max_score = max(p.get('final_score', 0.0) for p in all_papers)
            min_score = min(p.get('final_score', 0.0) for p in all_papers)

            # ì •ê·œí™” (0.0-1.0 ë²”ìœ„ë¡œ)
            if max_score > min_score:
                for paper in all_papers:
                    original_score = paper.get('final_score', 0.0)
                    normalized_score = (original_score - min_score) / (max_score - min_score)
                    paper['final_score'] = normalized_score
                    paper['original_score'] = original_score  # ì›ë³¸ ì ìˆ˜ ë³´ì¡´

        # 6. ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ ë° ìƒìœ„ Kê°œ ì„ íƒ
        sorted_papers = sorted(
            all_papers,
            key=lambda x: x.get('final_score', 0.0),
            reverse=True
        )

        return sorted_papers[:top_k]

    def _enrich_papers_from_postgresql(self, papers: List[Dict[str, Any]]):
        """
        PostgreSQLì—ì„œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ ì¡°íšŒí•˜ì—¬ ë³´ê°•

        Args:
            papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ (in-place ì—…ë°ì´íŠ¸)
        """
        if not self.session or not papers:
            return

        from sqlalchemy import text

        # paper_id ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        paper_ids = [p['paper_id'] for p in papers if 'paper_id' in p]
        if not paper_ids:
            return

        # PostgreSQLì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        query = text("""
            SELECT paper_id, title, chunk_text, lang, source, year, pmid, doi
            FROM paper_nodes
            WHERE paper_id = ANY(:paper_ids)
        """)

        results = self.session.execute(query, {'paper_ids': paper_ids}).fetchall()

        # paper_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë§µ ìƒì„±
        db_paper_map = {
            str(row[0]): {
                'title': row[1],
                'chunk_text': row[2],
                'lang': row[3],
                'source': row[4],
                'year': row[5],
                'pmid': row[6],
                'doi': row[7],
            }
            for row in results
        }

        # ë…¼ë¬¸ ì •ë³´ ë³´ê°•
        for paper in papers:
            paper_id = str(paper.get('paper_id', ''))
            if paper_id in db_paper_map:
                # PostgreSQL ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë°ì´í„°ëŠ” ìœ ì§€)
                db_data = db_paper_map[paper_id]
                for key, value in db_data.items():
                    if key not in paper or not paper[key]:
                        paper[key] = value

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.session:
            self.session.close()
            self.session = None

        if self.neo4j_repo:
            self.neo4j_repo.close()
            self.neo4j_repo = None

    def __del__(self):
        """ì†Œë©¸ì"""
        self.close()
