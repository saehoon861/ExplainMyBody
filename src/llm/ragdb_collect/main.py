#!/usr/bin/env python3
"""
RAG ì½”í¼ìŠ¤ ìˆ˜ì§‘ ë©”ì¸ íŒŒì´í”„ë¼ì¸
4ê°œ ì¶• ë™ë“± ë¶„ë°°: ë‹¨ë°±ì§ˆ/ê·¼ìœ¡, ê°ëŸ‰, í•œì‹, ì²´í˜•
"""

import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import List

from models import PaperMetadata, CollectionStats
from pubmed_collector import PubMedCollector
from kci_collector import KCICollector
import config


def collect_all_domains(
    email: str,
    api_key: str = None,
    output_dir: str = "outputs",
) -> List[PaperMetadata]:
    """
    ëª¨ë“  ë„ë©”ì¸ ìˆ˜ì§‘

    Args:
        email: PubMed API ì´ë©”ì¼
        api_key: PubMed API Key (ì„ íƒ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ì „ì²´ PaperMetadata ë¦¬ìŠ¤íŠ¸
    """
    all_papers = []
    stats = CollectionStats()

    # PubMed Collector ì´ˆê¸°í™”
    pubmed = PubMedCollector(email=email, api_key=api_key)

    # ========== 1. ë‹¨ë°±ì§ˆ/ê·¼ìœ¡ ì¦ê°€ ==========
    print("\n" + "=" * 80)
    print("1ï¸âƒ£  ë‹¨ë°±ì§ˆ/ê·¼ìœ¡ ì¦ê°€ ë„ë©”ì¸ ìˆ˜ì§‘")
    print("=" * 80)

    protein_papers = pubmed.collect_domain(
        domain="protein_hypertrophy",
        queries=config.PROTEIN_HYPERTROPHY_QUERIES,
        target_count=config.PROTEIN_HYPERTROPHY_TARGET,
        results_per_query=config.PUBMED_RESULTS_PER_QUERY,
    )
    all_papers.extend(protein_papers)
    stats.by_domain["protein_hypertrophy"] = len(protein_papers)

    # ========== 2. ì²´ì§€ë°© ê°ëŸ‰/ë‹¤ì´ì–´íŠ¸ ==========
    print("\n" + "=" * 80)
    print("2ï¸âƒ£  ì²´ì§€ë°© ê°ëŸ‰/ë‹¤ì´ì–´íŠ¸ ë„ë©”ì¸ ìˆ˜ì§‘")
    print("=" * 80)

    fatloss_papers = pubmed.collect_domain(
        domain="fat_loss",
        queries=config.FAT_LOSS_QUERIES,
        target_count=config.FAT_LOSS_TARGET,
        results_per_query=config.PUBMED_RESULTS_PER_QUERY,
    )
    all_papers.extend(fatloss_papers)
    stats.by_domain["fat_loss"] = len(fatloss_papers)

    # ========== 3. í•œêµ­í˜• ì‹ë‹¨/í•œì‹ (ì˜ì–´ ë…¼ë¬¸ë§Œ PubMedì—ì„œ) ==========
    print("\n" + "=" * 80)
    print("3ï¸âƒ£  í•œêµ­í˜• ì‹ë‹¨/í•œì‹ ë„ë©”ì¸ ìˆ˜ì§‘ (ì˜ì–´ ë…¼ë¬¸)")
    print("=" * 80)

    korean_diet_papers_en = pubmed.collect_domain(
        domain="korean_diet",
        queries=config.KOREAN_DIET_QUERIES_EN,
        target_count=config.KOREAN_DIET_TARGET // 2,  # ì ˆë°˜ë§Œ ì˜ì–´
        results_per_query=config.PUBMED_RESULTS_PER_QUERY,
    )
    all_papers.extend(korean_diet_papers_en)

    # í•œêµ­ì–´ ë…¼ë¬¸ì€ ìˆ˜ë™ ìˆ˜ì§‘ (KCI)
    print("\nğŸ“Œ í•œêµ­ì–´ ë…¼ë¬¸ì€ ìˆ˜ë™ ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    print("   ê°€ì´ë“œ: kci_collector.py ì°¸ê³ ")
    stats.by_domain["korean_diet"] = len(korean_diet_papers_en)

    # ========== 4. ì²´í˜• ë¶„ì„/ì¸ë°”ë”” ==========
    print("\n" + "=" * 80)
    print("4ï¸âƒ£  ì²´í˜• ë¶„ì„/ì¸ë°”ë”” ë„ë©”ì¸ ìˆ˜ì§‘ (ì˜ì–´ ë…¼ë¬¸)")
    print("=" * 80)

    body_comp_papers_en = pubmed.collect_domain(
        domain="body_composition",
        queries=config.BODY_COMPOSITION_QUERIES_EN,
        target_count=config.BODY_COMPOSITION_TARGET // 2,  # ì ˆë°˜ë§Œ ì˜ì–´
        results_per_query=config.PUBMED_RESULTS_PER_QUERY,
    )
    all_papers.extend(body_comp_papers_en)

    # í•œêµ­ì–´ ë…¼ë¬¸ì€ ìˆ˜ë™ ìˆ˜ì§‘ (KCI)
    print("\nğŸ“Œ í•œêµ­ì–´ ë…¼ë¬¸ì€ ìˆ˜ë™ ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    stats.by_domain["body_composition"] = len(body_comp_papers_en)

    # ========== í†µê³„ ==========
    stats.total_collected = len(all_papers)
    stats.by_language = {"en": len([p for p in all_papers if p.language == "en"])}
    stats.by_source = {"PubMed": len(all_papers)}

    return all_papers, stats


def save_results(
    papers: List[PaperMetadata],
    stats: CollectionStats,
    output_dir: str = "outputs",
):
    """
    ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥

    Args:
        papers: ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        stats: í†µê³„
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. ì „ì²´ JSON ì €ì¥
    all_json_path = output_path / f"{config.OUTPUT_FILE_PREFIX}_{timestamp}.json"
    with open(all_json_path, "w", encoding="utf-8") as f:
        json.dump(
            [p.model_dump() for p in papers], f, ensure_ascii=False, indent=2
        )
    print(f"\nâœ… ì „ì²´ JSON ì €ì¥: {all_json_path}")

    # 2. ë„ë©”ì¸ë³„ ë¶„í•  ì €ì¥
    for domain in stats.by_domain.keys():
        domain_papers = [p for p in papers if p.domain == domain]
        domain_path = output_path / f"{domain}_{timestamp}.json"
        with open(domain_path, "w", encoding="utf-8") as f:
            json.dump(
                [p.model_dump() for p in domain_papers],
                f,
                ensure_ascii=False,
                indent=2,
            )
        print(f"  - {domain}: {domain_path} ({len(domain_papers)}ê°œ)")

    # 3. í†µê³„ ì €ì¥
    stats_path = output_path / f"stats_{timestamp}.json"
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats.model_dump(), f, ensure_ascii=False, indent=2)
    print(f"  - í†µê³„: {stats_path}")

    # 4. í†µê³„ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š ìˆ˜ì§‘ í†µê³„")
    print("=" * 80)
    print(f"ì´ ìˆ˜ì§‘: {stats.total_collected}ê°œ")
    print(f"\në„ë©”ì¸ë³„:")
    for domain, count in stats.by_domain.items():
        print(f"  - {domain}: {count}ê°œ")
    print(f"\nì–¸ì–´ë³„:")
    for lang, count in stats.by_language.items():
        print(f"  - {lang}: {count}ê°œ")


def main():
    parser = argparse.ArgumentParser(
        description="RAG ì½”í¼ìŠ¤ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ (4ê°œ ì¶• ë™ë“± ë¶„ë°°)"
    )

    parser.add_argument(
        "--email",
        type=str,
        required=True,
        help="PubMed API ì´ë©”ì¼ (NCBI ìš”êµ¬ì‚¬í•­)",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="PubMed API Key (ì„ íƒ, ì†ë„ í–¥ìƒ)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="outputs",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: outputs)",
    )

    args = parser.parse_args()

    print("\n" + "=" * 80)
    print("ğŸš€ RAG ì½”í¼ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 80)
    print(f"ì´ë©”ì¼: {args.email}")
    print(f"API Key: {'ìˆìŒ' if args.api_key else 'ì—†ìŒ (ì†ë„ ì œí•œ ìˆìŒ)'}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")

    # ìˆ˜ì§‘ ì‹¤í–‰
    papers, stats = collect_all_domains(
        email=args.email,
        api_key=args.api_key,
        output_dir=args.output_dir,
    )

    # ê²°ê³¼ ì €ì¥
    save_results(papers, stats, output_dir=args.output_dir)

    print("\n" + "=" * 80)
    print("âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
    print("=" * 80)

    # KCI ìˆ˜ë™ ìˆ˜ì§‘ ê°€ì´ë“œ
    kci = KCICollector()
    print("\n" + kci.create_manual_guide())

    # í…œí”Œë¦¿ ì €ì¥
    template_path = Path(args.output_dir) / "kci_template.json"
    kci.save_template(str(template_path))


if __name__ == "__main__":
    main()
