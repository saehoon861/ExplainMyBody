#!/usr/bin/env python3
"""
InBody ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ íŒŒì¼ (Graph RAG ì ìš©)
- í•­ìƒ gpt-4o-mini ë° text-embedding-3-small ì‚¬ìš©
- Graph RAG (Vector + Graph Traversal) ìë™ ì ìš©
- Database í´ë˜ìŠ¤ ì˜ì¡´ì„± ì œê±°
"""

import sys
import argparse
import json
from pathlib import Path
from dotenv import load_dotenv

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from shared.llm_clients import create_llm_client
from shared.models import InBodyMeasurements, InBodyAnalysisResponse

from pipeline_inbody_analysis_rag.analyzer import InBodyAnalyzerGraphRAG

load_dotenv()


def run_inbody_analysis_with_graph_rag(
    user_id: int,
    measurements_dict: dict,
    use_neo4j: bool = True,
) -> InBodyAnalysisResponse:
    """
    ì¸ë°”ë”” ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Graph RAG ì ìš©)

    Args:
        user_id: ì‚¬ìš©ì ID
        measurements_dict: InBody ì¸¡ì • ë°ì´í„° (dict)
        use_neo4j: Neo4j ê·¸ë˜í”„ íƒìƒ‰ ì‚¬ìš© ì—¬ë¶€

    Returns:
        InBodyAnalysisResponse
    """
    try:
        # 1. Pydantic ëª¨ë¸ ê²€ì¦
        measurements = InBodyMeasurements(**measurements_dict)

        # 2. LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í•­ìƒ gpt-4o-mini)
        model = "gpt-4o-mini"
        llm_client = create_llm_client(model)

        print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ¤– LLM ëª¨ë¸: {model} (ê³ ì •)")
        print(f"ğŸ“Š Embedding: text-embedding-3-small (ê³ ì •)")

        # 3. InBody ë¶„ì„ ìˆ˜í–‰ (Graph RAG ìë™ ì ìš©)
        analyzer = InBodyAnalyzerGraphRAG(
            llm_client=llm_client,
            model_version=model,
            use_graph_rag=True,  # í•­ìƒ Graph RAG ì‚¬ìš©
            use_neo4j=use_neo4j,
        )
        result = analyzer.analyze(user_id, measurements, source="manual")

        # 4. ì„±ê³µ ì‘ë‹µ
        return InBodyAnalysisResponse(
            success=True,
            record_id=result["record_id"],
            analysis_id=result["analysis_id"],
            analysis_text=result["analysis_text"],
        )

    except Exception as e:
        # ì—ëŸ¬ ì‘ë‹µ
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()

        return InBodyAnalysisResponse(success=False, error=str(e))


def main():
    parser = argparse.ArgumentParser(description="InBody ë¶„ì„ íŒŒì´í”„ë¼ì¸ (Graph RAG)")

    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--user-id", type=int, required=True, help="ì‚¬ìš©ì ID")

    # ì¸¡ì • ë°ì´í„° ì…ë ¥ ë°©ë²•
    parser.add_argument("--measurements-json", type=str, help="ì¸¡ì • ë°ì´í„° JSON ë¬¸ìì—´")
    parser.add_argument("--measurements-file", type=str, help="ì¸¡ì • ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ")

    # ì„ íƒì  ì¸ì
    parser.add_argument("--output-file", type=str, help="ê²°ê³¼ë¥¼ ì €ì¥í•  TXT íŒŒì¼ ê²½ë¡œ")
    parser.add_argument(
        "--no-neo4j",
        action="store_true",
        help="Neo4j ê·¸ë˜í”„ íƒìƒ‰ ë¹„í™œì„±í™” (Vectorë§Œ ì‚¬ìš©)",
    )

    args = parser.parse_args()

    # ì¸¡ì • ë°ì´í„° ë¡œë“œ
    if args.measurements_json:
        measurements_dict = json.loads(args.measurements_json)
    elif args.measurements_file:
        with open(args.measurements_file, "r", encoding="utf-8") as f:
            measurements_dict = json.load(f)
    else:
        print("ì˜¤ë¥˜: --measurements-json ë˜ëŠ” --measurements-file ì¤‘ í•˜ë‚˜ í•„ìˆ˜")
        sys.exit(1)

    # ë¶„ì„ ì‹¤í–‰ (Graph RAG ìë™ ì ìš©)
    response = run_inbody_analysis_with_graph_rag(
        user_id=args.user_id,
        measurements_dict=measurements_dict,
        use_neo4j=not args.no_neo4j,
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ ë¶„ì„ ê²°ê³¼ (Graph RAG)")
    print("=" * 60)

    if response.success:
        print(f"âœ… ì„±ê³µ!")
        print(f"   - Record ID: {response.record_id}")
        print(f"   - Analysis ID: {response.analysis_id}")
        print(f"   - ëª¨ë¸: gpt-4o-mini")
        print(f"   - Embedding: text-embedding-3-small")
        print(f"   - Graph RAG: âœ… ì ìš©ë¨")
        print(f"\n{response.analysis_text}")
    else:
        print(f"âŒ ì‹¤íŒ¨: {response.error}")

    # íŒŒì¼ë¡œ ì €ì¥ (ì„±ê³µ ì‹œì—ë§Œ ì €ì¥)
    if args.output_file and response.success:
        try:
            output_path = Path(args.output_file)
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # TXT íŒŒì¼ë¡œ ì €ì¥ (ë¶„ì„ í…ìŠ¤íŠ¸ë§Œ)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write("InBody ë¶„ì„ ê²°ê³¼ (Graph RAG ì ìš©)\n")
                f.write("=" * 80 + "\n\n")
                f.write(f"Record ID: {response.record_id}\n")
                f.write(f"Analysis ID: {response.analysis_id}\n")
                f.write(f"ëª¨ë¸: gpt-4o-mini\n")
                f.write(f"Embedding: text-embedding-3-small\n")
                f.write(f"Graph RAG: âœ… ì ìš©ë¨\n\n")
                f.write("-" * 80 + "\n\n")
                f.write(response.analysis_text)

            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path.absolute()}")
        except Exception as e:
            print(f"\nâš ï¸  íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback

            traceback.print_exc()

    if not response.success:
        sys.exit(1)


if __name__ == "__main__":
    main()
