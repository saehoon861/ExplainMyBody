"""
Multi-Call ìì—°ì–´ ê¸°ë°˜ InBody ë¶„ì„ê¸°
- Call1: ì²´í˜• íŒì • (ìì—°ì–´)
- Call2: Router (concept_id ì¶”ì¶œ) + Graph RAG ê²€ìƒ‰
- Call3: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
"""

from typing import Dict, Any, List, Optional
import sys
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

from shared.models import InBodyMeasurements
from shared.llm_clients import BaseLLMClient
from backend.database import SessionLocal
from backend.repositories.common.health_record_repository import HealthRecordRepository
from backend.repositories.llm.analysis_report_repository import AnalysisReportRepository
from backend.schemas.common import HealthRecordCreate
from backend.schemas.llm import AnalysisReportCreate
from pipeline_inbody_analysis_rag.prompts_multi_call import (
    create_body_assessment_prompt,
    create_concept_router_prompt,
    create_final_report_prompt
)
from pipeline_weekly_plan_rag.graph_rag_retriever import GraphRAGRetriever
from pipeline_inbody_analysis_rag.concept_definitions import get_concept_name


class InBodyAnalyzerMultiCall:
    """
    Multi-Call ìì—°ì–´ ê¸°ë°˜ InBody ë¶„ì„ê¸°

    Flow:
    1. Tool0: DBì—ì„œ measurements ë¶ˆëŸ¬ì˜¤ê¸° (ì„ íƒ)
    2. Call1: ì²´í˜• íŒì • ìì—°ì–´ ìƒì„±
    3. Call2-1 Router: ìì—°ì–´ â†’ concept_id[] ì¶”ì¶œ
    4. Call2-2 Tool: Graph RAG ê²€ìƒ‰
    5. Call3: ìµœì¢… ë¦¬í¬íŠ¸ (Evidence í†µí•©)
    """

    def __init__(
        self,
        llm_client: BaseLLMClient,
        model_version: str = "gpt-4o-mini",
        use_graph_rag: bool = True,
        use_neo4j: bool = True
    ):
        """
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
            model_version: ëª¨ë¸ ë²„ì „
            use_graph_rag: Graph RAG ì‚¬ìš© ì—¬ë¶€
            use_neo4j: Neo4j ê·¸ë˜í”„ íƒìƒ‰ ì‚¬ìš© ì—¬ë¶€
        """
        self.llm_client = llm_client
        self.model_version = model_version
        self.use_graph_rag = use_graph_rag

        # Graph RAG ì´ˆê¸°í™”
        self.graph_rag = None
        if use_graph_rag:
            try:
                self.graph_rag = GraphRAGRetriever(
                    embedder_type="openai",
                    use_neo4j=use_neo4j
                )
                print("  âœ… Graph RAG Analyzer (Multi-Call) ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"  âš ï¸  Graph RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.graph_rag = None

    def analyze(
        self,
        user_id: int,
        measurements: InBodyMeasurements,
        source: str = "manual"
    ) -> Dict[str, Any]:
        """
        Multi-Call ê¸°ë°˜ InBody ë¶„ì„ ì‹¤í–‰

        Args:
            user_id: ì‚¬ìš©ì ID
            measurements: InBody ì¸¡ì • ë°ì´í„°
            source: ë°ì´í„° ì†ŒìŠ¤

        Returns:
            {
                "record_id": int,
                "analysis_id": int,
                "analysis_text": str,
                "call1_assessment": str,
                "call2_concept_ids": List[str],
                "call3_report": str
            }
        """
        output_lines = []

        def print_and_capture(*args, **kwargs):
            """print ì¶œë ¥ì„ ìº¡ì²˜í•˜ë©´ì„œ ë™ì‹œì— ì½˜ì†”ì—ë„ ì¶œë ¥"""
            message = " ".join(str(arg) for arg in args)
            output_lines.append(message)
            print(*args, **kwargs)

        print_and_capture("=" * 60)
        print_and_capture(f"InBody Multi-Call ë¶„ì„ ì‹œì‘ (User ID: {user_id})")
        print_and_capture(f"  ğŸ”§ ëª¨ë¸: {self.model_version}")
        print_and_capture(
            f"  ğŸ”§ Graph RAG: {'âœ… Enabled' if self.use_graph_rag else 'âŒ Disabled'}"
        )
        print_and_capture("=" * 60)

        # ==================== CALL 1: ì²´í˜• íŒì • ====================
        print_and_capture("\nğŸ“Š CALL 1: ì²´í˜• íŒì • (ìì—°ì–´ ìƒì„±)...")

        try:
            system_prompt, user_prompt = create_body_assessment_prompt(measurements)
            call1_assessment = self.llm_client.generate_chat(system_prompt, user_prompt)
            print_and_capture(f"  âœ… ì²´í˜• íŒì • ì™„ë£Œ ({len(call1_assessment)} ê¸€ì)")
            print_and_capture(f"\n{call1_assessment}\n")
        except Exception as e:
            print_and_capture(f"  âŒ Call1 ì‹¤íŒ¨: {e}")
            raise e

        # ==================== CALL 2: Router + Graph RAG ====================
        concept_ids = []
        evidence_chunks = []

        if self.use_graph_rag and self.graph_rag:
            print_and_capture("\nğŸ” CALL 2-1: Concept Router (ìì—°ì–´ â†’ concept_id)...")

            try:
                system_prompt, user_prompt = create_concept_router_prompt(call1_assessment)
                router_output = self.llm_client.generate_chat(system_prompt, user_prompt)

                # JSON íŒŒì‹±
                router_output = router_output.strip()
                if router_output.startswith("```"):
                    # ì½”ë“œ ë¸”ë¡ ì œê±°
                    router_output = router_output.split("```")[1]
                    if router_output.startswith("json"):
                        router_output = router_output[4:]
                    router_output = router_output.strip()

                concept_ids = json.loads(router_output)
                print_and_capture(f"  âœ… ì¶”ì¶œëœ concept_ids: {concept_ids}")

            except Exception as e:
                print_and_capture(f"  âš ï¸  Router ì‹¤íŒ¨: {e}, ê¸°ë³¸ concept ì‚¬ìš©")
                # Fallback: ê¸°ë³¸ concept
                concept_ids = ["body_composition", "skeletal_muscle_mass", "body_fat_percentage"]

            print_and_capture("\nğŸ” CALL 2-2: Graph RAG ê²€ìƒ‰...")

            try:
                # Graph RAGë¡œ ë…¼ë¬¸ ê²€ìƒ‰
                papers = self.graph_rag.hybrid_search(
                    query="ì¸ë°”ë”” ì²´ì„±ë¶„ ë¶„ì„",  # ë”ë¯¸ ì¿¼ë¦¬ (concept ê¸°ë°˜ ê²€ìƒ‰)
                    concept_ids=concept_ids,
                    top_k=5
                )

                print_and_capture(f"  âœ… ê²€ìƒ‰ëœ ë…¼ë¬¸: {len(papers)}ê°œ")

                # Evidence í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                for paper in papers:
                    for cid in concept_ids:
                        evidence_chunks.append({
                            "concept_id": cid,
                            "chunk_text": paper.get("chunk_text", ""),
                            "chunk_ko_summary": paper.get("chunk_ko_summary", ""),
                            "title": paper.get("title", ""),
                            "final_score": paper.get("final_score", 0.0)
                        })

                # Top 5ê°œë§Œ ìœ ì§€
                evidence_chunks = evidence_chunks[:5]

            except Exception as e:
                print_and_capture(f"  âš ï¸  Graph RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                evidence_chunks = []

        # ==================== DB ì €ì¥: health_records ====================
        print_and_capture("\nğŸ’¾ 3ë‹¨ê³„: ì¸¡ì • ë°ì´í„° ì €ì¥...")
        db_session = SessionLocal()
        try:
            m = measurements.model_dump()
            health_record_data = HealthRecordCreate(
                measurements=m,
                source=source,
                measured_at=None
            )
            record = HealthRecordRepository.create(db_session, user_id, health_record_data)
            record_id = record.id
            print_and_capture(f"  âœ“ Record ID: {record_id}")
        except Exception as e:
            db_session.rollback()
            raise e

        # ==================== CALL 3: ìµœì¢… ë¦¬í¬íŠ¸ ====================
        print_and_capture("\nğŸ“ CALL 3: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Evidence í†µí•©)...")

        try:
            system_prompt, user_prompt = create_final_report_prompt(
                body_assessment_text=call1_assessment,
                evidence_chunks=evidence_chunks,
                previous_record=None  # TODO: ì´ì „ ê¸°ë¡ ì¡°íšŒ
            )
            call3_report = self.llm_client.generate_chat(system_prompt, user_prompt)
            print_and_capture(f"  âœ… ìµœì¢… ë¦¬í¬íŠ¸ ì™„ë£Œ ({len(call3_report)} ê¸€ì)")

        except Exception as e:
            print_and_capture(f"  âŒ Call3 ì‹¤íŒ¨: {e}")
            raise e

        # ==================== DB ì €ì¥: analysis_reports ====================
        print_and_capture("\nğŸ’¾ 6ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ì €ì¥...")
        try:
            # ì „ì²´ ë¶„ì„ í…ìŠ¤íŠ¸ ê²°í•©
            full_analysis_text = "\n".join(output_lines) + "\n\n" + call3_report

            analysis_data = AnalysisReportCreate(
                record_id=record_id,
                llm_output=full_analysis_text,
                model_version=self.model_version,
                analysis_type="inbody_multi_call_rag"
            )
            analysis_report = AnalysisReportRepository.create(db_session, analysis_data)
            analysis_id = analysis_report.id
            print_and_capture(f"  âœ“ Analysis ID: {analysis_id}")

            db_session.commit()
        except Exception as e:
            db_session.rollback()
            raise e
        finally:
            db_session.close()

        print_and_capture("\n" + "=" * 60)
        print_and_capture("âœ¨ InBody Multi-Call ë¶„ì„ ì™„ë£Œ!")
        print_and_capture("=" * 60)

        return {
            "record_id": record_id,
            "analysis_id": analysis_id,
            "analysis_text": "\n".join(output_lines),
            "call1_assessment": call1_assessment,
            "call2_concept_ids": concept_ids,
            "call3_report": call3_report
        }
