"""
Graph Expansion Pipeline í…ŒìŠ¤íŠ¸

ì™„ì „ Deterministic Pipeline:
1. Rule-based Seed Extraction (LLM ì—†ìŒ)
2. Graph Expansion Retriever (SQL Hop)
3. LLM Report Writer (ê¸€ì“°ê¸°ë§Œ)
"""

import sys
import json
import argparse
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).resolve().parents[3]
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))
sys.path.insert(0, str(project_root / "src" / "llm"))

load_dotenv(project_root / ".env")

# ë¡œì»¬ ì„í¬íŠ¸
from llm_clients import create_llm_client

# Graph Expansion Pipeline
try:
    from pipeline_inbody_analysis_rag.analyzer_graph_expansion import InBodyAnalyzerGraphExpansion
    GRAPH_EXPANSION_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  Graph Expansion ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    GRAPH_EXPANSION_AVAILABLE = False

# Backend ìŠ¤í‚¤ë§ˆ
try:
    from schemas.inbody import InBodyData
    from shared.models import InBodyMeasurements
    BACKEND_SCHEMA_AVAILABLE = True
except ImportError:
    print("âš ï¸  InBody ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸ ì‹¤íŒ¨")
    BACKEND_SCHEMA_AVAILABLE = False
    InBodyData = None
    InBodyMeasurements = None


def convert_inbody_data_to_measurements(data: InBodyData) -> InBodyMeasurements:
    """InBodyData (nested) â†’ InBodyMeasurements (flat) ë³€í™˜"""
    return InBodyMeasurements(
        ì„±ë³„=data.ê¸°ë³¸ì •ë³´.ì„±ë³„,
        ë‚˜ì´=data.ê¸°ë³¸ì •ë³´.ì—°ë ¹,
        ì‹ ì¥=data.ê¸°ë³¸ì •ë³´.ì‹ ì¥,
        ì²´ì¤‘=data.ì²´ì¤‘ê´€ë¦¬.ì²´ì¤‘,
        ë¬´ê¸°ì§ˆ=data.ì²´ì„±ë¶„.ë¬´ê¸°ì§ˆ,
        ì²´ìˆ˜ë¶„=data.ì²´ì„±ë¶„.ì²´ìˆ˜ë¶„,
        ë‹¨ë°±ì§ˆ=data.ì²´ì„±ë¶„.ë‹¨ë°±ì§ˆ,
        ì²´ì§€ë°©=data.ì²´ì„±ë¶„.ì²´ì§€ë°©,
        ê³¨ê²©ê·¼ëŸ‰=data.ì²´ì¤‘ê´€ë¦¬.ê³¨ê²©ê·¼ëŸ‰,
        BMI=data.ë¹„ë§Œë¶„ì„.BMI,
        ì²´ì§€ë°©ë¥ =data.ë¹„ë§Œë¶„ì„.ì²´ì§€ë°©ë¥ ,
        ë³µë¶€ì§€ë°©ë¥ =data.ë¹„ë§Œë¶„ì„.ë³µë¶€ì§€ë°©ë¥ ,
        ë‚´ì¥ì§€ë°©ë ˆë²¨=data.ë¹„ë§Œë¶„ì„.ë‚´ì¥ì§€ë°©ë ˆë²¨,
        ë¹„ë§Œë„=data.ë¹„ë§Œë¶„ì„.ë¹„ë§Œë„,
        ê¸°ì´ˆëŒ€ì‚¬ëŸ‰=data.ì—°êµ¬í•­ëª©.ê¸°ì´ˆëŒ€ì‚¬ëŸ‰,
        ì ì •ì²´ì¤‘=data.ì²´ì¤‘ê´€ë¦¬.ì ì •ì²´ì¤‘,
        ê¶Œì¥ì„­ì·¨ì—´ëŸ‰=data.ì—°êµ¬í•­ëª©.ê¶Œì¥ì„­ì·¨ì—´ëŸ‰,
        ì²´ì¤‘ì¡°ì ˆ=data.ì²´ì¤‘ê´€ë¦¬.ì²´ì¤‘ì¡°ì ˆ,
        ì§€ë°©ì¡°ì ˆ=data.ì²´ì¤‘ê´€ë¦¬.ì§€ë°©ì¡°ì ˆ,
        ê·¼ìœ¡ì¡°ì ˆ=data.ì²´ì¤‘ê´€ë¦¬.ê·¼ìœ¡ì¡°ì ˆ,
        ê·¼ìœ¡_ë¶€ìœ„ë³„ë“±ê¸‰={
            "ì™¼íŒ”": data.ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„.ì™¼ìª½íŒ”,
            "ì˜¤ë¥¸íŒ”": data.ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„.ì˜¤ë¥¸ìª½íŒ”,
            "ëª¸í†µ": data.ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„.ë³µë¶€,
            "ì™¼ë‹¤ë¦¬": data.ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„.ì™¼ìª½í•˜ì²´,
            "ì˜¤ë¥¸ë‹¤ë¦¬": data.ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„.ì˜¤ë¥¸ìª½í•˜ì²´,
        },
        ì²´ì§€ë°©_ë¶€ìœ„ë³„ë“±ê¸‰={
            "ì™¼íŒ”": data.ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„.ì™¼ìª½íŒ”,
            "ì˜¤ë¥¸íŒ”": data.ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„.ì˜¤ë¥¸ìª½íŒ”,
            "ëª¸í†µ": data.ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„.ë³µë¶€,
            "ì™¼ë‹¤ë¦¬": data.ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„.ì™¼ìª½í•˜ì²´,
            "ì˜¤ë¥¸ë‹¤ë¦¬": data.ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„.ì˜¤ë¥¸ìª½í•˜ì²´,
        },
        body_type1=data.body_type1,
        body_type2=data.body_type2,
    )


class GraphExpansionTester:
    """Graph Expansion Pipeline í…ŒìŠ¤í„°"""

    def __init__(
        self,
        model: str = "gpt-4o-mini",
        use_graph_expansion: bool = True
    ):
        self.model = model
        self.use_graph_expansion = use_graph_expansion

        print("=" * 70)
        print("ğŸ§ª Graph Expansion Pipeline í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™”")
        print("=" * 70)
        print(f"  ğŸ”§ ëª¨ë¸: {self.model}")
        print(f"  ğŸ”§ Pipeline: Deterministic (Rule + Graph + LLM)")
        print(f"  ğŸ”§ Graph Expansion: {'âœ… Enabled' if use_graph_expansion else 'âŒ Disabled'}")
        print()

        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.llm_client = create_llm_client(self.model)

        # Analyzer ì´ˆê¸°í™”
        self.analyzer = None
        if GRAPH_EXPANSION_AVAILABLE:
            try:
                self.analyzer = InBodyAnalyzerGraphExpansion(
                    llm_client=self.llm_client,
                    model_version=self.model,
                    use_graph_expansion=use_graph_expansion
                )
            except Exception as e:
                print(f"âŒ Analyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.analyzer = None

        print("=" * 70)
        print()

    def load_sample_data(self, sample_name: str = "default") -> InBodyData:
        """ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"""
        pipeline_dir = project_root / "src" / "llm" / "pipeline_inbody_analysis_rag"

        sample_files = {
            "default": "sample_inbody_data.json",
            "gymnast": "sample_inbody_gymnast.json",
            "obese": "sample_inbody_obese.json",
            "skinnyfat": "sample_inbody_skinnyfat.json",
            "juggernaut": "sample_inbody_juggernaut.json",
        }

        filename = sample_files.get(sample_name, sample_files["default"])
        filepath = pipeline_dir / filename

        print(f"ğŸ“‚ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ: {filename}")

        if not filepath.exists():
            print(f"âŒ ìƒ˜í”Œ íŒŒì¼ ì—†ìŒ: {filepath}")
            sys.exit(1)

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data_dict = json.load(f)

            inbody_data = InBodyData(**data_dict)
            print("  âœ… InBodyData ê°ì²´ ìƒì„± ì™„ë£Œ")
            print()

            return inbody_data

        except Exception as e:
            print(f"âŒ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            sys.exit(1)

    def test_graph_expansion(
        self,
        measurements: InBodyMeasurements,
        user_id: int = 999
    ) -> dict:
        """Graph Expansion Pipeline í…ŒìŠ¤íŠ¸"""

        if not self.analyzer:
            print("âŒ Analyzerê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        # InBodyData â†’ InBodyMeasurements ë³€í™˜
        if isinstance(measurements, InBodyData):
            measurements = convert_inbody_data_to_measurements(measurements)

        print("=" * 70)
        print("ğŸ“ Graph Expansion Pipeline ì‹¤í–‰")
        print("=" * 70)
        print()

        try:
            result = self.analyzer.analyze(
                user_id=user_id,
                measurements=measurements,
                source="test"
            )

            print()
            print("=" * 70)
            print("âœ… ë¶„ì„ ì™„ë£Œ")
            print("=" * 70)
            print()

            # ê²°ê³¼ ì¶œë ¥
            print("ğŸ“Š ê²°ê³¼ ìš”ì•½:")
            print("-" * 70)
            print(f"\nSeeds: {result.get('seed_concepts', [])}")
            print(f"\nRisk Concepts: {len(result.get('risk_concepts', []))}ê°œ")
            print(f"Intervention Concepts: {len(result.get('intervention_concepts', []))}ê°œ")
            print(f"Evidence Chunks: {result.get('evidence_count', 0)}ê°œ")
            print(f"\n[ìµœì¢… ë¦¬í¬íŠ¸]\n")
            print(result.get("final_report", "N/A"))

            return {
                "record_id": result["record_id"],
                "analysis_id": result["analysis_id"],
                "analysis_text": result["analysis_text"],
                "model_version": self.model,
                "graph_expansion_used": True
            }

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {}


def main():
    parser = argparse.ArgumentParser(description="Graph Expansion Pipeline í…ŒìŠ¤íŠ¸")
    parser.add_argument("--sample", default="default", help="ìƒ˜í”Œ ë°ì´í„° ì„ íƒ")
    parser.add_argument("--model", default="gpt-4o-mini", help="LLM ëª¨ë¸")
    parser.add_argument("--no-expansion", action="store_true", help="Graph Expansion ë¹„í™œì„±í™”")
    parser.add_argument("--output", default="test_graph_expansion_result.json", help="ê²°ê³¼ íŒŒì¼ëª…")

    args = parser.parse_args()

    # Tester ì´ˆê¸°í™”
    tester = GraphExpansionTester(
        model=args.model,
        use_graph_expansion=not args.no_expansion
    )

    # ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
    inbody_data = tester.load_sample_data(args.sample)

    # ë¶„ì„ ì‹¤í–‰
    result = tester.test_graph_expansion(inbody_data)

    # ê²°ê³¼ ì €ì¥
    if result:
        output_path = Path(__file__).parent / args.output
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    print()
    print("=" * 70)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)


if __name__ == "__main__":
    main()
