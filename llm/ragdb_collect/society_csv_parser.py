"""
í•™ìˆ ì§€ CSV/Excel íŒŒì„œ

ëŒ€í•œì˜ì–‘í•™íšŒ, í•œêµ­ì²´ìœ¡í•™íšŒ ë“± í•™ìˆ ë‹¨ì²´ì—ì„œ ì œê³µí•˜ëŠ”
ë…¼ë¬¸ ëª©ë¡ CSV/Excel íŒŒì¼ì„ PaperMetadataë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import json
import csv
from typing import List, Optional, Dict
from pathlib import Path
from datetime import datetime

try:
    import pandas as pd
except ImportError:
    print("âŒ pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install pandas openpyxl")
    exit(1)

from models import PaperMetadata


class SocietyCSVParser:
    """í•™ìˆ ì§€ CSV/Excel íŒŒì„œ"""

    # ì»¬ëŸ¼ ë§¤í•‘ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    COLUMN_MAPPINGS = {
        'title': ['ì œëª©', 'title', 'ë…¼ë¬¸ëª…', 'ë…¼ë¬¸ì œëª©', 'Title', 'Article Title'],
        'abstract': ['ì´ˆë¡', 'abstract', 'ìš”ì•½', 'Abstract', 'Summary'],
        'keywords': ['í‚¤ì›Œë“œ', 'keywords', 'Keyword', 'Keywords', 'ì£¼ì œì–´'],
        'year': ['ë°œí–‰ë…„ë„', 'year', 'ì—°ë„', 'Year', 'Publication Year'],
        'authors': ['ì €ì', 'author', 'authors', 'Author', 'Authors'],
        'journal': ['í•™ìˆ ì§€', 'journal', 'Journal', 'ì €ë„', 'í•™íšŒì§€']
    }

    def __init__(self):
        pass

    def find_column(self, df: pd.DataFrame, field: str) -> Optional[str]:
        """
        DataFrameì—ì„œ í•„ë“œì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ëª… ì°¾ê¸°

        Args:
            df: pandas DataFrame
            field: ì°¾ì„ í•„ë“œ (title, abstract, etc.)

        Returns:
            ì‹¤ì œ ì»¬ëŸ¼ëª… (ì—†ìœ¼ë©´ None)
        """
        possible_names = self.COLUMN_MAPPINGS.get(field, [])

        for col in df.columns:
            if col in possible_names:
                return col

        return None

    def parse_csv(
        self,
        csv_path: str,
        domain: str,
        source: str = "í•™ìˆ ì§€",
        encoding: str = "utf-8"
    ) -> List[PaperMetadata]:
        """
        CSV íŒŒì¼ì—ì„œ PaperMetadata ë¦¬ìŠ¤íŠ¸ ìƒì„±

        Args:
            csv_path: CSV íŒŒì¼ ê²½ë¡œ
            domain: ë„ë©”ì¸ ë¶„ë¥˜
            source: ì¶œì²˜ (í•™íšŒëª… ë“±)
            encoding: íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸: utf-8, í•œêµ­ì–´ íŒŒì¼ì€ cp949 ì‹œë„)

        Returns:
            PaperMetadata ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {csv_path}")

        try:
            # CSV ì½ê¸° (ì¸ì½”ë”© ìë™ ê°ì§€)
            try:
                df = pd.read_csv(csv_path, encoding=encoding)
            except UnicodeDecodeError:
                # cp949 ì‹œë„
                df = pd.read_csv(csv_path, encoding='cp949')

        except Exception as e:
            print(f"  âŒ CSV ì½ê¸° ì‹¤íŒ¨: {e}")
            return []

        # ì»¬ëŸ¼ ë§¤í•‘
        title_col = self.find_column(df, 'title')
        abstract_col = self.find_column(df, 'abstract')
        keywords_col = self.find_column(df, 'keywords')
        year_col = self.find_column(df, 'year')
        authors_col = self.find_column(df, 'authors')
        journal_col = self.find_column(df, 'journal')

        if not title_col:
            print(f"  âŒ 'ì œëª©' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            print(f"     ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            return []

        papers = []

        # ê° í–‰ ì²˜ë¦¬
        for idx, row in df.iterrows():
            try:
                # ì œëª© í•„ìˆ˜
                title = str(row[title_col]).strip()
                if not title or title == 'nan':
                    continue

                # ì´ˆë¡ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
                abstract = ""
                if abstract_col and abstract_col in row:
                    abstract = str(row[abstract_col]).strip()
                    if abstract == 'nan':
                        abstract = ""

                # ì´ˆë¡ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
                if len(abstract) < 100:
                    print(f"  âš ï¸ ì´ˆë¡ì´ ë„ˆë¬´ ì§§ì•„ ìŠ¤í‚µ: {title[:30]}...")
                    continue

                # í‚¤ì›Œë“œ íŒŒì‹±
                keywords = []
                if keywords_col and keywords_col in row:
                    kw_str = str(row[keywords_col]).strip()
                    if kw_str and kw_str != 'nan':
                        # ì„¸ë¯¸ì½œë¡ , ì‰¼í‘œ, ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„
                        keywords = [k.strip() for k in kw_str.replace(';', ',').replace('/', ',').split(',')]
                        keywords = [k for k in keywords if k]

                # ì—°ë„ íŒŒì‹±
                year = None
                if year_col and year_col in row:
                    try:
                        year = int(row[year_col])
                    except:
                        pass

                # ì €ì íŒŒì‹±
                authors = []
                if authors_col and authors_col in row:
                    authors_str = str(row[authors_col]).strip()
                    if authors_str and authors_str != 'nan':
                        # ì„¸ë¯¸ì½œë¡ , ì‰¼í‘œë¡œ êµ¬ë¶„
                        authors = [a.strip() for a in authors_str.replace(';', ',').split(',')]
                        authors = [a for a in authors if a][:5]  # ìµœëŒ€ 5ëª…

                # ì €ë„ëª…
                journal = source
                if journal_col and journal_col in row:
                    journal_name = str(row[journal_col]).strip()
                    if journal_name and journal_name != 'nan':
                        journal = journal_name

                # PaperMetadata ìƒì„±
                paper = PaperMetadata(
                    domain=domain,
                    language='ko',
                    title=title,
                    abstract=abstract,
                    keywords=keywords,
                    source=source,
                    year=year,
                    pmid=None,
                    doi=None,
                    authors=authors,
                    journal=journal
                )

                papers.append(paper)

            except Exception as e:
                print(f"  âš ï¸ í–‰ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue

        print(f"  âœ… {len(papers)}ê°œ ë…¼ë¬¸ íŒŒì‹± ì™„ë£Œ")
        return papers

    def parse_excel(
        self,
        excel_path: str,
        domain: str,
        source: str = "í•™ìˆ ì§€",
        sheet_name: int = 0
    ) -> List[PaperMetadata]:
        """
        Excel íŒŒì¼ì—ì„œ PaperMetadata ë¦¬ìŠ¤íŠ¸ ìƒì„±

        Args:
            excel_path: Excel íŒŒì¼ ê²½ë¡œ
            domain: ë„ë©”ì¸ ë¶„ë¥˜
            source: ì¶œì²˜
            sheet_name: ì‹œíŠ¸ ë²ˆí˜¸ ë˜ëŠ” ì´ë¦„ (ê¸°ë³¸: ì²« ë²ˆì§¸ ì‹œíŠ¸)

        Returns:
            PaperMetadata ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ“Š ì²˜ë¦¬ ì¤‘: {excel_path}")

        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name)
        except Exception as e:
            print(f"  âŒ Excel ì½ê¸° ì‹¤íŒ¨: {e}")
            return []

        # CSVì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
        # (DataFrameìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
        return self._parse_dataframe(df, domain, source)

    def _parse_dataframe(self, df: pd.DataFrame, domain: str, source: str) -> List[PaperMetadata]:
        """DataFrameì„ PaperMetadata ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë‚´ë¶€ ë©”ì„œë“œ)"""

        # ì»¬ëŸ¼ ë§¤í•‘
        title_col = self.find_column(df, 'title')
        abstract_col = self.find_column(df, 'abstract')
        keywords_col = self.find_column(df, 'keywords')
        year_col = self.find_column(df, 'year')
        authors_col = self.find_column(df, 'authors')
        journal_col = self.find_column(df, 'journal')

        if not title_col:
            print(f"  âŒ 'ì œëª©' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []

        papers = []

        for idx, row in df.iterrows():
            try:
                title = str(row[title_col]).strip()
                if not title or title == 'nan':
                    continue

                abstract = ""
                if abstract_col:
                    abstract = str(row[abstract_col]).strip()
                    if abstract == 'nan':
                        abstract = ""

                if len(abstract) < 100:
                    continue

                keywords = []
                if keywords_col:
                    kw_str = str(row[keywords_col]).strip()
                    if kw_str != 'nan':
                        keywords = [k.strip() for k in kw_str.replace(';', ',').split(',')]

                year = None
                if year_col:
                    try:
                        year = int(row[year_col])
                    except:
                        pass

                authors = []
                if authors_col:
                    authors_str = str(row[authors_col]).strip()
                    if authors_str != 'nan':
                        authors = [a.strip() for a in authors_str.replace(';', ',').split(',')][:5]

                journal = source
                if journal_col:
                    j = str(row[journal_col]).strip()
                    if j != 'nan':
                        journal = j

                paper = PaperMetadata(
                    domain=domain,
                    language='ko',
                    title=title,
                    abstract=abstract,
                    keywords=keywords,
                    source=source,
                    year=year,
                    pmid=None,
                    doi=None,
                    authors=authors,
                    journal=journal
                )

                papers.append(paper)

            except Exception as e:
                continue

        print(f"  âœ… {len(papers)}ê°œ ë…¼ë¬¸ íŒŒì‹± ì™„ë£Œ")
        return papers


def create_template():
    """CSV í…œí”Œë¦¿ ìƒì„±"""

    template_data = [
        {
            "ì œëª©": "í•œêµ­ ì„±ì¸ì˜ ë‹¨ë°±ì§ˆ ì„­ì·¨ì™€ ê·¼ìœ¡ëŸ‰ì˜ ê´€ê³„",
            "ì´ˆë¡": "ë³¸ ì—°êµ¬ëŠ” í•œêµ­ ì„±ì¸ 1000ëª…ì„ ëŒ€ìƒìœ¼ë¡œ ë‹¨ë°±ì§ˆ ì„­ì·¨ëŸ‰ê³¼ ê·¼ìœ¡ëŸ‰ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ì˜€ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì²´ì¤‘ 1kgë‹¹ 1.2g ì´ìƒì˜ ë‹¨ë°±ì§ˆì„ ì„­ì·¨í•œ ê·¸ë£¹ì—ì„œ ìœ ì˜ë¯¸í•˜ê²Œ ë†’ì€ ê·¼ìœ¡ëŸ‰ì„ ë³´ì˜€ë‹¤.",
            "í‚¤ì›Œë“œ": "ë‹¨ë°±ì§ˆ, ê·¼ìœ¡ëŸ‰, í•œêµ­ì¸, ì˜ì–‘ì„­ì·¨",
            "ë°œí–‰ë…„ë„": 2022,
            "ì €ì": "ê¹€ì˜í¬, ë°•ì² ìˆ˜, ì´ë¯¼ì§€",
            "í•™ìˆ ì§€": "ëŒ€í•œì˜ì–‘í•™íšŒì§€"
        },
        {
            "ì œëª©": "ê¹€ì¹˜ ì„­ì·¨ê°€ ì¥ë‚´ ë¯¸ìƒë¬¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥",
            "ì´ˆë¡": "ë°œíš¨ì‹í’ˆì¸ ê¹€ì¹˜ì˜ ì„­ì·¨ê°€ ì¥ë‚´ ë¯¸ìƒë¬¼ ë‹¤ì–‘ì„±ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ ì—°êµ¬. 12ì£¼ê°„ ë§¤ì¼ ê¹€ì¹˜ë¥¼ ì„­ì·¨í•œ ê·¸ë£¹ì€ ìœ ìµê· ì´ ì¦ê°€í•˜ê³  ìœ í•´ê· ì´ ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ë‹¤.",
            "í‚¤ì›Œë“œ": "ê¹€ì¹˜, ë°œíš¨ì‹í’ˆ, ì¥ë‚´ë¯¸ìƒë¬¼, í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤",
            "ë°œí–‰ë…„ë„": 2021,
            "ì €ì": "ì´ìˆ˜ì§„, ìµœë™ìš±",
            "í•™ìˆ ì§€": "í•œêµ­ì‹í’ˆì˜ì–‘ê³¼í•™íšŒì§€"
        }
    ]

    output_dir = Path("outputs")
    output_dir.mkdir(exist_ok=True)

    template_path = output_dir / "society_papers_template.csv"

    # CSVë¡œ ì €ì¥
    df = pd.DataFrame(template_data)
    df.to_csv(template_path, index=False, encoding='utf-8-sig')

    print(f"âœ… CSV í…œí”Œë¦¿ ìƒì„±: {template_path}")
    print("\nğŸ“‹ ì‚¬ìš© ë°©ë²•:")
    print("1. í•™ìˆ ì§€ ì‚¬ì´íŠ¸ì—ì„œ ë…¼ë¬¸ ëª©ë¡ ë‹¤ìš´ë¡œë“œ (CSV ë˜ëŠ” Excel)")
    print("2. ì»¬ëŸ¼ëª…ì„ í…œí”Œë¦¿ê³¼ ìœ ì‚¬í•˜ê²Œ ë§ì¶”ê¸° (ì œëª©, ì´ˆë¡, í‚¤ì›Œë“œ ë“±)")
    print("3. python society_csv_parser.py --process [íŒŒì¼ê²½ë¡œ] ì‹¤í–‰")

    return str(template_path)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    template_path = create_template()

    print("\n" + "=" * 60)
    print("ğŸ“š í•™ìˆ ì§€ ë…¼ë¬¸ ìˆ˜ì§‘ ê°€ì´ë“œ")
    print("=" * 60)

    print("\nğŸ”— ì¶”ì²œ í•™ìˆ ì§€:")
    print("  1. ëŒ€í•œì˜ì–‘í•™íšŒ: http://www.kns.or.kr/")
    print("     - í•œêµ­ì˜ì–‘í•™íšŒì§€ (ë¬´ë£Œ ë…¼ë¬¸ å¤š)")
    print("")
    print("  2. í•œêµ­ì²´ìœ¡í•™íšŒ: http://www.koreasportscience.org/")
    print("     - ìš´ë™ì˜ì–‘í•™íšŒì§€")
    print("")
    print("  3. í•œêµ­ì‹í’ˆì˜ì–‘ê³¼í•™íšŒ: http://www.kosfost.or.kr/")
    print("     - ë°œíš¨ì‹í’ˆ, í•œì‹ ì—°êµ¬")
    print("")
    print("  4. ëŒ€í•œë¹„ë§Œí•™íšŒ: http://www.kosso.or.kr/")
    print("     - ì²´ì§€ë°©, ì²´ì„±ë¶„ ì—°êµ¬")
    print("")
    print("  5. ëŒ€í•œë…¸ì¸ë³‘í•™íšŒ: http://www.geriatrics.or.kr/")
    print("     - ê·¼ê°ì†Œì¦, ë…¸í™” ì—°êµ¬")

    print("\nğŸ“¥ ìˆ˜ì§‘ ë°©ë²•:")
    print("  1. í•™íšŒ ì‚¬ì´íŠ¸ ì ‘ì†")
    print("  2. ê²€ìƒ‰ ë˜ëŠ” ìµœì‹  ë…¼ë¬¸ ëª©ë¡")
    print("  3. Excel/CSV ë‹¤ìš´ë¡œë“œ (ëŒ€ë¶€ë¶„ ë¬´ë£Œ ì œê³µ)")
    print("  4. ì´ˆë¡ì´ í¬í•¨ëœ ë…¼ë¬¸ë§Œ ì„ íƒ")

    print("\nğŸ“Š ì˜ˆìƒ ìˆ˜ì§‘ëŸ‰:")
    print("  - ì˜ì–‘í•™íšŒ: 50-100ê°œ")
    print("  - ì²´ìœ¡í•™íšŒ: 30-50ê°œ")
    print("  - ì‹í’ˆí•™íšŒ: 30-50ê°œ")
    print("  - ë¹„ë§Œí•™íšŒ: 20-30ê°œ")
    print("  - ì´ 130-230ê°œ")

    # --process ì˜µì…˜ì´ ìˆìœ¼ë©´ ì‹¤ì œ ì²˜ë¦¬
    import sys
    if '--process' in sys.argv and len(sys.argv) > 2:
        csv_path = sys.argv[2]

        if not Path(csv_path).exists():
            print(f"\nâŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
            return

        parser = SocietyCSVParser()

        # ë„ë©”ì¸ ì„ íƒ
        print("\në„ë©”ì¸ ì„ íƒ:")
        print("  1. protein_hypertrophy (ë‹¨ë°±ì§ˆ/ê·¼ìœ¡)")
        print("  2. fat_loss (ì²´ì§€ë°© ê°ëŸ‰)")
        print("  3. korean_diet (í•œêµ­ ì‹ë‹¨)")
        print("  4. body_composition (ì²´ì„±ë¶„ ë¶„ì„)")
        domain_input = input("ë²ˆí˜¸ ì…ë ¥ (ê¸°ë³¸: 3): ").strip() or "3"

        domain_map = {
            "1": "protein_hypertrophy",
            "2": "fat_loss",
            "3": "korean_diet",
            "4": "body_composition"
        }
        domain = domain_map.get(domain_input, "korean_diet")

        # ì¶œì²˜ ì…ë ¥
        source = input("ì¶œì²˜ ì…ë ¥ (ì˜ˆ: ëŒ€í•œì˜ì–‘í•™íšŒ): ").strip() or "í•™ìˆ ì§€"

        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì²˜ë¦¬
        if csv_path.endswith('.csv'):
            papers = parser.parse_csv(csv_path, domain, source)
        elif csv_path.endswith(('.xlsx', '.xls')):
            papers = parser.parse_excel(csv_path, domain, source)
        else:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return

        if papers:
            # ê²°ê³¼ ì €ì¥
            output_dir = Path("outputs")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            output_path = output_dir / f"society_papers_{timestamp}.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump([p.model_dump() for p in papers], f, ensure_ascii=False, indent=2)

            print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(papers)}ê°œ ë…¼ë¬¸")
            print(f"   ì €ì¥ ê²½ë¡œ: {output_path}")
        else:
            print("\nâš ï¸ íŒŒì‹±ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
