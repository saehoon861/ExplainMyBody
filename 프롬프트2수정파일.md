ì¶”ê°€ëœ íŒŒì¼ ë° ìœ„ì¹˜

backend/services/llm/rule_based_prompts.py
backend/services/llm/rules.py
backend/services/llm/weekly_plan_graph.py


  ğŸ“„ ìˆ˜ì •ëœ íŒŒì¼ ë° ìœ„ì¹˜

  ---
  1. backend/services/llm/llm_clients.py

  ì¶”ê°€ 1: BaseLLMClient ì¶”ìƒ ë©”ì„œë“œ (line 20-23)

  @abstractmethod
  async def agenerate_chat(self, system_prompt: str, user_prompt: str, key: str) -> dict:
      """ë¹„ë™ê¸° ì±„íŒ… ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
      pass

  ì¶”ê°€ 2: OpenAIClient êµ¬í˜„ (line 67-80)

  async def agenerate_chat(self, system_prompt: str, user_prompt: str, key: str) -> dict:
      """ë¹„ë™ê¸° ì±„íŒ… ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
      response = await self.async_client.chat.completions.create(
          model=self.model,
          messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt}
          ],
          temperature=0.7,
      )
      return {
          "key": key,
          "content": response.choices[0].message.content
      }

  ê¸°ëŠ¥:
  - weekly_plan_graph.pyì˜ 4ê°œ í”„ë¡¬í”„íŠ¸ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¹„ë™ê¸° ë©”ì„œë“œ
  - ë°˜í™˜ í˜•ì‹: {'key': str, 'content': str}

  ---
  2. backend/schemas/llm.py

  ìˆ˜ì •: GoalPlanInput í´ë˜ìŠ¤ (line 137-154)

  class GoalPlanInput(BaseModel):
      """LLM2: ì£¼ê°„ ê³„íš ìƒì„± ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
      # ... ê¸°ì¡´ í•„ë“œë“¤ ...
      user_profile: Optional[Dict[str, Any]] = None  # rule_based_promptsìš© í”„ë¡œí•„ ì •ë³´
      available_days_per_week: Optional[int] = 5  # ì£¼ë‹¹ ìš´ë™ ê°€ëŠ¥ ì¼ìˆ˜
      available_time_per_session: Optional[int] = 60  # íšŒë‹¹ ìš´ë™ ì‹œê°„ (ë¶„)

  ì¶”ê°€ëœ í•„ë“œ:
  - user_profile: rule_based_promptsì—ì„œ body_type1, body_type2, health_specifics, preferences ì „ë‹¬ìš©
  - available_days_per_week: ìš´ë™ ê³„íš ìƒì„± ì‹œ ì£¼ë‹¹ ê°€ëŠ¥ ì¼ìˆ˜
  - available_time_per_session: ìš´ë™ ê³„íš ìƒì„± ì‹œ íšŒë‹¹ ì‹œê°„

  ---
  âœ… ì •ìƒ ë™ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸

  ì´ì œ weekly_plan_graph.pyê°€ ì •ìƒ ë™ì‘í•˜ê¸° ìœ„í•œ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì´ ì¶©ì¡±ë˜ì—ˆìŠµë‹ˆë‹¤:

  - âœ… llm_client.agenerate_chat() ë©”ì„œë“œ êµ¬í˜„ ì™„ë£Œ
  - âœ… llm_client.generate_chat_with_history() ë©”ì„œë“œ ì¡´ì¬ (ê¸°ì¡´)
  - âœ… GoalPlanInput.user_profile í•„ë“œ ì¶”ê°€ ì™„ë£Œ
  - âœ… GoalPlanInput.available_days_per_week í•„ë“œ ì¶”ê°€ ì™„ë£Œ
  - âœ… GoalPlanInput.available_time_per_session í•„ë“œ ì¶”ê°€ ì™„ë£Œ
  - âœ… schemas.inbody.InBodyData ì¡´ì¬ í™•ì¸ë¨
  - âœ… rule_based_prompts 4ê°œ í•¨ìˆ˜ ì¡´ì¬ í™•ì¸ë¨

  ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ë©´ ì •ìƒ ë™ì‘í•  ê²ƒì…ë‹ˆë‹¤!



  backend/services/llm/llm_service.py (line 384-387)

  weekly_plan_graph.pyì˜ generate_initial_plan_concurrentlyëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ì¸ë°, invoke() ëŒ€ì‹  **ainvoke()**ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

  ìˆ˜ì • ì™„ë£Œ

  # âŒ ìˆ˜ì • ì „
  initial_state = self.weekly_plan_agent.invoke(
      {"plan_input": input_data},
      config=config
  )

  # âœ… ìˆ˜ì • í›„
  initial_state = await self.weekly_plan_agent.ainvoke(
      {"plan_input": input_data},
      config=config
  )


  ìˆ˜ì •

â— Update(~/projects/ExplainMyBody/backend/services/common/health_service.py)
  â¿ Â Added 11 lines
      147              status_analysis_result = status_analysis.llm_output
      148              status_analysis_id = status_analysis.id
      149
      150 +        # user_profile ìƒì„± (rule_based_promptsì—ì„œ ì‚¬ìš©)


      151 +        user_profile = {
      152 +            "body_type1": health_record.measurements.get('body_type1', 'ì•Œ ìˆ˜ ì—†ìŒ'),


      153 +            "body_type2": health_record.measurements.get('body_type2', 'í‘œì¤€í˜•'),

      154 +            "health_specifics": "",  # ì¶”í›„ user_details í…Œì´ë¸”ì—ì„œ ê°€ì ¸ì˜¤ê¸°


      155 +            "preferences": ""  # ì¶”í›„ user_details í…Œì´ë¸”ì—ì„œ ê°€ì ¸ì˜¤ê¸°


      156 +        }
      157 +
      158          # LLM input ë°ì´í„° ì¤€ë¹„


      159          input_data = self.llm_service.prepare_goal_plan_input(
      160              user_goal_type=user_goal_type,
     ...
      159              status_analysis_id=status_analysis_id
      160          )
      161
      162 +        # user_profile ì¶”ê°€
      163 +        input_data["user_profile"] = user_profile
      164 +
      165          return GoalPlanPrepareResponse(
      166              success=True,
      167              message="LLM input ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. í”„ë¡ íŠ¸ì—”ë“œì—ì„œ LLM APIë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.",


